{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 48, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16262 train samples and 84 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 12)
  (Dcell): RNNCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 198620.93069267273 total train Value loss.

	TESTING: 3128.595703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.768765   0.95099366 1.0062536  0.8272985  1.1556197  0.92400587
 1.0819705  1.0041674  1.0724725  1.0125118  1.0539432  1.0403098
 1.0404997  1.0416789  1.0424082  1.0426723  1.0403109  1.0432786
 1.0413202  1.0421848  1.0417044  1.0422146  1.041765   1.0419897
 1.04196    1.0419332  1.0419378  1.0419453  1.0419539  1.0419296
 1.0419519  1.0419407  1.0419449  1.0419414  1.0419455  1.0419427
 1.0419433  1.0419439  1.0419436  1.0419432  1.0419437  1.0419436
 1.0419436  1.0419436  1.0419436  1.0419434  1.0419436  1.0419436 ]


TIME OF ONE EPOCH: 19.685535430908203 seconds and 0.3280922571818034 minutes
Epoch 2
	TRAINING: 13269.792054891586 total train Value loss.

	TESTING: 2481.057861328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8187326 1.0148932 1.0152575 0.9550633 1.1219007 1.035118  1.0882562
 1.0699807 1.0983361 1.0702534 1.0886337 1.0844609 1.0844812 1.0831703
 1.0855556 1.0845622 1.0840576 1.0848125 1.0845945 1.0845013 1.0844965
 1.0846585 1.0845116 1.0845528 1.0845679 1.0845658 1.0845457 1.0845627
 1.0845613 1.0845554 1.0845579 1.0845596 1.084558  1.0845578 1.0845585
 1.0845581 1.0845582 1.0845584 1.0845584 1.0845582 1.0845581 1.0845585
 1.0845581 1.0845584 1.0845584 1.0845581 1.0845585 1.0845581]


TIME OF ONE EPOCH: 17.990756511688232 seconds and 0.29984594186147057 minutes
Epoch 3
	TRAINING: 7609.291729211807 total train Value loss.

	TESTING: 2170.193359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8721194 1.040505  1.046369  1.0203218 1.1276158 1.0867002 1.1117208
 1.1059424 1.1211308 1.1072074 1.115468  1.1143038 1.1143532 1.1133865
 1.1146555 1.1142434 1.1140337 1.1142452 1.1142659 1.1141859 1.114185
 1.1142414 1.1142049 1.1142056 1.1142132 1.1142154 1.1142079 1.1142116
 1.1142125 1.1142112 1.1142112 1.1142118 1.1142116 1.1142112 1.1142117
 1.1142118 1.1142117 1.1142114 1.1142117 1.1142117 1.1142116 1.1142116
 1.1142117 1.1142116 1.1142116 1.1142116 1.1142116 1.1142116]


TIME OF ONE EPOCH: 17.659370183944702 seconds and 0.29432283639907836 minutes
Epoch 4
	TRAINING: 5145.448527097702 total train Value loss.

	TESTING: 1967.61083984375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.93082166 1.0634047  1.0814421  1.0671731  1.1484317  1.1236024
 1.1398184  1.1368904  1.1468129  1.1387599  1.1432308  1.1428244
 1.1429206  1.1423086  1.1429821  1.1428156  1.1427035  1.1427796
 1.1428119  1.1427735  1.1427679  1.1427921  1.142781   1.1427788
 1.1427816  1.1427833  1.1427805  1.1427814  1.1427819  1.1427814
 1.1427811  1.1427814  1.1427815  1.1427811  1.1427815  1.1427814
 1.1427814  1.1427813  1.1427814  1.1427814  1.1427814  1.1427814
 1.1427814  1.1427814  1.1427814  1.1427814  1.1427814  1.1427814 ]


TIME OF ONE EPOCH: 18.637118577957153 seconds and 0.31061864296595254 minutes
Epoch 5
	TRAINING: 3789.232485920191 total train Value loss.

	TESTING: 1849.3416748046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.98311776 1.0825036  1.1080401  1.0994648  1.166858   1.1485869
 1.1608258  1.1593177  1.1665063  1.1611165  1.1640123  1.163911
 1.1639459  1.1635503  1.163971   1.163892   1.163812   1.1638548
 1.1638792  1.163857   1.1638516  1.1638658  1.1638609  1.1638587
 1.1638601  1.1638614  1.16386    1.1638603  1.1638604  1.1638604
 1.1638604  1.1638603  1.1638603  1.1638603  1.1638602  1.1638602
 1.1638602  1.1638603  1.1638603  1.1638602  1.1638602  1.1638604
 1.1638603  1.1638602  1.1638602  1.1638602  1.1638604  1.1638602 ]


TIME OF ONE EPOCH: 19.045058727264404 seconds and 0.31741764545440676 minutes
Epoch 6
	TRAINING: 2951.7205283641815 total train Value loss.

	TESTING: 1780.27978515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0265303 1.0991815 1.1279286 1.1228198 1.1815603 1.166465  1.1762284
 1.1758611 1.1813619 1.1773646 1.1794727 1.1795607 1.1795126 1.1792449
 1.1795485 1.1795069 1.1794372 1.179471  1.1794901 1.1794739 1.1794695
 1.1794797 1.1794767 1.1794748 1.1794758 1.1794767 1.1794758 1.1794758
 1.1794761 1.1794759 1.1794759 1.179476  1.179476  1.179476  1.179476
 1.179476  1.1794759 1.179476  1.179476  1.179476  1.1794761 1.179476
 1.179476  1.1794759 1.179476  1.179476  1.179476  1.1794761]


TIME OF ONE EPOCH: 19.430333852767944 seconds and 0.32383889754613243 minutes
Epoch 7
	TRAINING: 2368.225074440241 total train Value loss.

	TESTING: 1736.306396484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0601794 1.113005  1.1415461 1.1388179 1.1913781 1.1780393 1.1859468
 1.1865224 1.190845  1.1876628 1.1893185 1.189533  1.18941   1.1892222
 1.1894656 1.18944   1.1893743 1.1894063 1.1894224 1.1894083 1.1894044
 1.1894132 1.1894108 1.1894089 1.1894096 1.1894107 1.18941   1.1894099
 1.18941   1.1894099 1.18941   1.18941   1.18941   1.1894101 1.18941
 1.1894101 1.1894101 1.18941   1.18941   1.18941   1.18941   1.18941
 1.18941   1.18941   1.18941   1.18941   1.18941   1.18941  ]


TIME OF ONE EPOCH: 19.514524698257446 seconds and 0.32524207830429075 minutes
Epoch 8
	TRAINING: 1935.3092474341393 total train Value loss.

	TESTING: 1701.4859619140625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0846313 1.1232057 1.1494063 1.1482604 1.196009  1.1837711 1.1901927
 1.1914934 1.1949519 1.1922829 1.1936531 1.1939505 1.1937686 1.1936325
 1.1938423 1.193824  1.1937605 1.1937914 1.1938062 1.1937926 1.1937894
 1.1937975 1.1937953 1.1937932 1.1937945 1.193795  1.1937943 1.1937943
 1.1937947 1.1937945 1.1937944 1.1937947 1.1937946 1.1937945 1.1937945
 1.1937945 1.1937945 1.1937945 1.1937945 1.1937945 1.1937945 1.1937946
 1.1937945 1.1937945 1.1937945 1.1937945 1.1937945 1.1937945]


TIME OF ONE EPOCH: 19.886951208114624 seconds and 0.3314491868019104 minutes
Epoch 9
	TRAINING: 1602.6461216658354 total train Value loss.

	TESTING: 1667.972900390625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1025661 1.1311085 1.1541827 1.1540828 1.1978106 1.1864569 1.1916336
 1.1934632 1.19628   1.1939614 1.1951299 1.1954813 1.1952595 1.1951553
 1.1953446 1.1953295 1.1952677 1.1952984 1.1953118 1.1952986 1.1952962
 1.1953032 1.1953017 1.1952999 1.1953007 1.195301  1.1953006 1.1953005
 1.1953007 1.1953008 1.1953006 1.1953008 1.1953007 1.1953006 1.1953007
 1.1953007 1.1953006 1.1953007 1.1953006 1.1953006 1.1953007 1.1953006
 1.1953006 1.1953008 1.1953006 1.1953007 1.1953006 1.1953008]


TIME OF ONE EPOCH: 19.829307556152344 seconds and 0.3304884592692057 minutes
Epoch 10
	TRAINING: 1346.2849394381046 total train Value loss.

	TESTING: 1635.916259765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1177499 1.1389508 1.1590451 1.1596408 1.1997788 1.1892612 1.1933954
 1.1955624 1.1978726 1.1958362 1.196837  1.1972165 1.1969737 1.196891
 1.1970631 1.1970495 1.1969911 1.1970202 1.1970328 1.1970198 1.1970181
 1.1970247 1.1970228 1.1970211 1.1970224 1.1970227 1.1970223 1.1970222
 1.1970224 1.1970223 1.1970221 1.1970227 1.1970223 1.1970223 1.1970224
 1.1970223 1.1970224 1.1970223 1.1970223 1.1970222 1.1970223 1.1970222
 1.1970223 1.1970223 1.1970224 1.1970223 1.1970223 1.1970222]


TIME OF ONE EPOCH: 20.112663745880127 seconds and 0.33521106243133547 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 805.8112409379747 and inf%

TIME ELAPSED: 195.98133277893066 seconds OR 3.266355546315511 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 48, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16262 train samples and 84 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 24)
  (Dcell): RNNCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 89677.2680106163 total train Value loss.

	TESTING: 1942.6026611328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1183819  0.85318786 1.0761553  0.987408   1.1172733  1.0986453
 1.1384982  1.0966735  1.1280631  1.1292065  1.1442682  1.1331748
 1.1332996  1.1315542  1.134258   1.1327076  1.132725   1.1326108
 1.1334769  1.1334723  1.1332902  1.1330801  1.1331613  1.1332073
 1.1332016  1.1331637  1.1331761  1.1331997  1.1332036  1.1331911
 1.1331848  1.133188   1.1331917  1.1331906  1.1331892  1.1331893
 1.1331906  1.1331904  1.1331899  1.1331897  1.1331899  1.1331898
 1.13319    1.1331897  1.1331898  1.13319    1.13319    1.13319   ]


TIME OF ONE EPOCH: 20.958473443984985 seconds and 0.3493078907330831 minutes
Epoch 2
	TRAINING: 5617.442775726318 total train Value loss.

	TESTING: 1300.94140625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3453084 1.1589419 1.1866983 1.101937  1.2338995 1.2253867 1.2587494
 1.222446  1.2393827 1.2397358 1.2484695 1.2419496 1.2417032 1.2411325
 1.2426318 1.2421297 1.2419299 1.2418326 1.2421107 1.2421594 1.242084
 1.2420256 1.2420409 1.2420698 1.2420657 1.2420564 1.2420535 1.24206
 1.2420614 1.24206   1.2420578 1.2420585 1.2420591 1.2420594 1.2420589
 1.2420589 1.2420588 1.242059  1.242059  1.2420589 1.242059  1.242059
 1.242059  1.242059  1.2420591 1.2420589 1.2420591 1.2420589]


TIME OF ONE EPOCH: 22.25836420059204 seconds and 0.370972736676534 minutes
Epoch 3
	TRAINING: 2798.808971107006 total train Value loss.

	TESTING: 1047.88330078125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4379519 1.2962353 1.2640257 1.195733  1.3163271 1.3110887 1.340766
 1.3105192 1.3213761 1.3221014 1.3276511 1.3236157 1.3230665 1.3229516
 1.3237774 1.3236059 1.3233938 1.3233792 1.3234997 1.3235508 1.3234967
 1.3234751 1.3234764 1.3234955 1.3234913 1.3234885 1.3234862 1.3234893
 1.3234893 1.3234892 1.323488  1.3234886 1.3234888 1.3234885 1.3234886
 1.3234884 1.3234886 1.3234885 1.3234884 1.3234885 1.3234884 1.3234887
 1.3234885 1.3234885 1.3234886 1.3234884 1.3234887 1.3234884]


TIME OF ONE EPOCH: 21.745147466659546 seconds and 0.3624191244443258 minutes
Epoch 4
	TRAINING: 1794.3738090395927 total train Value loss.

	TESTING: 916.62548828125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4611886 1.3496782 1.3054849 1.2519665 1.3575691 1.3493421 1.3762386
 1.3517874 1.3600087 1.3603824 1.3640838 1.361404  1.3609214 1.360929
 1.3613937 1.361329  1.3611734 1.3611923 1.3612502 1.3612866 1.3612487
 1.3612405 1.3612392 1.3612509 1.3612474 1.3612467 1.3612449 1.3612467
 1.361247  1.3612468 1.3612465 1.3612465 1.3612463 1.361247  1.3612466
 1.3612465 1.3612466 1.3612467 1.3612467 1.3612466 1.3612465 1.3612466
 1.3612467 1.3612465 1.361247  1.3612467 1.3612466 1.3612466]


TIME OF ONE EPOCH: 22.1961190700531 seconds and 0.36993531783421835 minutes
Epoch 5
	TRAINING: 1275.331513673067 total train Value loss.

	TESTING: 840.3257446289062 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4698032 1.3757237 1.3331242 1.291441  1.383837  1.3725961 1.3964112
 1.3768508 1.3833177 1.3834507 1.3858964 1.3841279 1.3837184 1.3837825
 1.3840234 1.3840168 1.3839043 1.3839375 1.3839608 1.3839873 1.3839601
 1.3839588 1.383956  1.3839636 1.3839608 1.3839611 1.3839601 1.3839612
 1.383961  1.3839613 1.3839607 1.383961  1.3839607 1.3839608 1.3839606
 1.3839608 1.3839606 1.3839605 1.3839606 1.3839605 1.3839608 1.3839605
 1.3839611 1.3839607 1.3839611 1.3839606 1.3839606 1.3839608]


TIME OF ONE EPOCH: 22.468815803527832 seconds and 0.37448026339213053 minutes
Epoch 6
	TRAINING: 971.2816091179848 total train Value loss.

	TESTING: 788.123291015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4764013 1.3928624 1.3548672 1.323002  1.4045978 1.3917643 1.4122227
 1.396564  1.4016118 1.4017607 1.4033278 1.4021966 1.4018171 1.4019212
 1.4020231 1.4020513 1.4019645 1.4020026 1.4020079 1.4020283 1.4020083
 1.4020103 1.4020071 1.402012  1.40201   1.4020104 1.4020096 1.4020103
 1.4020101 1.4020103 1.40201   1.4020103 1.4020098 1.4020102 1.4020102
 1.40201   1.40201   1.4020101 1.40201   1.4020101 1.40201   1.40201
 1.4020101 1.40201   1.4020102 1.4020101 1.4020101 1.40201  ]


TIME OF ONE EPOCH: 21.777827501296997 seconds and 0.3629637916882833 minutes
Epoch 7
	TRAINING: 775.2938992083073 total train Value loss.

	TESTING: 749.6358642578125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4819099 1.4051538 1.37165   1.3478206 1.4207165 1.4074947 1.4247553
 1.4120909 1.4159893 1.4162596 1.4172469 1.4165406 1.4161812 1.4163009
 1.4163262 1.4163711 1.4163024 1.4163387 1.4163358 1.4163519 1.4163371
 1.4163395 1.4163368 1.4163401 1.4163387 1.4163395 1.416339  1.416339
 1.416339  1.4163394 1.4163392 1.4163392 1.416339  1.4163392 1.4163394
 1.4163389 1.416339  1.4163392 1.4163392 1.4163392 1.4163392 1.4163389
 1.4163392 1.4163392 1.4163389 1.416339  1.4163392 1.4163392]


TIME OF ONE EPOCH: 22.00075674057007 seconds and 0.36667927900950115 minutes
Epoch 8
	TRAINING: 632.1243903040886 total train Value loss.

	TESTING: 714.5883178710938 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4853625 1.4135971 1.3842462 1.3664082 1.4323592 1.419463  1.4339181
 1.4234916 1.4265125 1.4269122 1.427546  1.4271053 1.4267701 1.4268856
 1.4268754 1.4269232 1.4268701 1.4269007 1.426895  1.4269073 1.4268973
 1.4268991 1.4268969 1.4268993 1.4268982 1.4268987 1.4268985 1.4268985
 1.4268985 1.4268982 1.4268982 1.4268984 1.4268985 1.4268985 1.4268985
 1.4268984 1.4268985 1.4268982 1.4268984 1.4268982 1.4268982 1.4268985
 1.4268985 1.4268985 1.4268982 1.4268982 1.4268982 1.4268985]


TIME OF ONE EPOCH: 22.14242720603943 seconds and 0.3690404534339905 minutes
Epoch 9
	TRAINING: 521.8207420110703 total train Value loss.

	TESTING: 676.669677734375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4860064 1.4178772 1.3921239 1.3785926 1.4388082 1.4265141 1.438551
 1.4298465 1.4322221 1.4327261 1.433143  1.4328643 1.4325595 1.4326614
 1.4326372 1.4326814 1.4326407 1.4326649 1.4326594 1.4326687 1.4326614
 1.4326632 1.4326612 1.4326627 1.4326621 1.4326625 1.4326621 1.4326624
 1.4326622 1.4326621 1.4326622 1.4326622 1.4326622 1.4326624 1.4326621
 1.4326622 1.4326624 1.4326622 1.4326622 1.4326622 1.4326624 1.4326622
 1.4326622 1.4326621 1.4326625 1.4326624 1.4326621 1.4326622]


TIME OF ONE EPOCH: 22.153411388397217 seconds and 0.3692235231399536 minutes
Epoch 10
	TRAINING: 442.0581193268299 total train Value loss.

	TESTING: 646.2412719726562 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4887538 1.4238572 1.4011143 1.3908305 1.4461926 1.4348221 1.4447749
 1.4374559 1.4393233 1.4398944 1.4401718 1.4399931 1.4397223 1.4398078
 1.4397801 1.4398183 1.4397879 1.4398065 1.4398016 1.4398087 1.4398034
 1.4398044 1.4398034 1.4398042 1.4398042 1.4398044 1.439804  1.4398042
 1.4398042 1.4398041 1.4398041 1.4398042 1.439804  1.4398042 1.4398042
 1.4398044 1.4398042 1.4398042 1.4398042 1.4398043 1.4398042 1.4398042
 1.4398042 1.4398043 1.4398042 1.4398041 1.4398043 1.4398042]


TIME OF ONE EPOCH: 22.239062547683716 seconds and 0.37065104246139524 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 930.9549183921208 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 220.39657473564148 seconds OR 3.6732762455940247 minutes

End of run




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 48, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16262 train samples and 84 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 48)
  (Dcell): RNNCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 31059.851333498955 total train Value loss.

	TESTING: 988.4512939453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6593767 1.5447761 1.5382956 1.3691521 1.6005578 1.5191368 1.5255895
 1.471932  1.5131375 1.5007222 1.5129781 1.4974384 1.5075059 1.5025138
 1.5020741 1.5017163 1.5018044 1.5004945 1.5015919 1.5012555 1.5016307
 1.5012077 1.5015112 1.5013318 1.5013292 1.5014641 1.5014312 1.5013926
 1.5014379 1.5014012 1.5014029 1.5014118 1.5014155 1.5014105 1.5014126
 1.5014118 1.5014088 1.5014095 1.5014114 1.5014105 1.5014108 1.5014107
 1.5014104 1.5014104 1.5014105 1.5014105 1.5014106 1.5014107]


TIME OF ONE EPOCH: 26.167959690093994 seconds and 0.43613266150156654 minutes
Epoch 2
	TRAINING: 2528.337137043476 total train Value loss.

	TESTING: 855.5218505859375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6245593 1.5392065 1.5444903 1.4070636 1.5785785 1.5265508 1.5331502
 1.5047597 1.527815  1.5104119 1.5192963 1.5126004 1.5184871 1.5174762
 1.5169793 1.515359  1.5155003 1.5147432 1.5150249 1.5152261 1.5154891
 1.5151119 1.5152481 1.51517   1.5151172 1.5152115 1.5152304 1.5152012
 1.5152119 1.5151997 1.5151924 1.5151948 1.5152029 1.5152012 1.5152007
 1.5152007 1.515199  1.5151985 1.5151997 1.5151998 1.5151995 1.5151999
 1.5151999 1.5151997 1.5151997 1.5151997 1.5151997 1.5151995]


TIME OF ONE EPOCH: 28.241824626922607 seconds and 0.4706970771153768 minutes
Epoch 3
	TRAINING: 1245.7817055583 total train Value loss.

	TESTING: 781.6798095703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.605597  1.5505744 1.5746684 1.4518737 1.5890409 1.5556186 1.5592194
 1.5374734 1.5560303 1.5415934 1.5461354 1.5435464 1.5473022 1.5467458
 1.5468745 1.5453423 1.5454088 1.5449091 1.5449039 1.5450859 1.5452666
 1.5450165 1.5450926 1.545068  1.5450187 1.5450684 1.5450877 1.5450702
 1.5450732 1.5450715 1.5450665 1.5450656 1.5450706 1.5450696 1.5450685
 1.5450691 1.5450687 1.5450681 1.5450683 1.5450687 1.5450687 1.5450685
 1.5450686 1.5450685 1.5450686 1.5450686 1.5450685 1.5450686]


TIME OF ONE EPOCH: 28.631394147872925 seconds and 0.47718990246454873 minutes
Epoch 4
	TRAINING: 812.1310426443815 total train Value loss.

	TESTING: 742.793212890625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5943071 1.557534  1.5891322 1.4711337 1.5889174 1.567193  1.5670273
 1.548679  1.5660255 1.5539378 1.5561562 1.5552619 1.5577277 1.5574499
 1.5577974 1.5565336 1.5565635 1.5562043 1.5561007 1.5562313 1.5563556
 1.5561874 1.5562347 1.5562327 1.5561908 1.5562198 1.5562351 1.5562227
 1.556224  1.5562258 1.5562227 1.5562208 1.5562238 1.5562233 1.5562223
 1.5562232 1.5562232 1.5562228 1.5562229 1.5562229 1.5562228 1.5562227
 1.5562229 1.5562228 1.556223  1.5562229 1.5562229 1.5562228]


TIME OF ONE EPOCH: 29.02104377746582 seconds and 0.48368406295776367 minutes
Epoch 5
	TRAINING: 619.0877447426319 total train Value loss.

	TESTING: 713.1004638671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.590425  1.5652814 1.6040349 1.4917952 1.5959041 1.581668  1.5784057
 1.5623887 1.5786697 1.5684375 1.569508  1.569217  1.5710309 1.5710074
 1.5714447 1.570404  1.5704428 1.5701606 1.5700204 1.5701191 1.570208
 1.5700847 1.5701184 1.5701245 1.5700898 1.5701087 1.5701197 1.570111
 1.5701112 1.570114  1.5701118 1.5701101 1.5701127 1.5701125 1.5701114
 1.5701116 1.5701121 1.5701116 1.5701119 1.5701115 1.5701114 1.5701116
 1.5701118 1.5701113 1.5701116 1.5701116 1.5701119 1.570112 ]


TIME OF ONE EPOCH: 30.721822261810303 seconds and 0.5120303710301717 minutes
Epoch 6
	TRAINING: 500.56835417449474 total train Value loss.

	TESTING: 678.356201171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5969678 1.5810449 1.6235296 1.5184444 1.6115282 1.6020188 1.5975447
 1.583633  1.598731  1.5898055 1.5903895 1.5902774 1.5916278 1.5918039
 1.5922551 1.5913616 1.5914143 1.5911827 1.5910314 1.5911024 1.5911695
 1.5910752 1.591099  1.591109  1.5910808 1.5910928 1.5911015 1.5910951
 1.5910952 1.5910977 1.5910963 1.5910949 1.5910963 1.5910966 1.5910956
 1.5910959 1.5910962 1.5910958 1.591096  1.5910958 1.5910959 1.5910959
 1.591096  1.591096  1.5910959 1.591096  1.591096  1.5910959]


TIME OF ONE EPOCH: 30.162149906158447 seconds and 0.5027024984359741 minutes
Epoch 7
	TRAINING: 417.7205301299691 total train Value loss.

	TESTING: 647.14208984375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5948254 1.5838047 1.6257199 1.527574  1.6110393 1.6036721 1.5985863
 1.5866021 1.6002264 1.5921166 1.5926127 1.592439  1.5934836 1.5938219
 1.5942248 1.5934405 1.593507  1.5933061 1.5931562 1.5932083 1.5932596
 1.5931836 1.5932008 1.5932124 1.593189  1.5931973 1.5932045 1.5931994
 1.593199  1.5932014 1.5932002 1.593199  1.5932004 1.5932002 1.5931996
 1.5932002 1.5932006 1.5931998 1.5932002 1.5932004 1.5932002 1.5932001
 1.5932001 1.5932001 1.5932001 1.5932    1.5932002 1.5932001]


TIME OF ONE EPOCH: 29.934420585632324 seconds and 0.49890700976053876 minutes
Epoch 8
	TRAINING: 354.79088394343853 total train Value loss.

	TESTING: 618.755859375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5929329 1.5840353 1.6245191 1.5331372 1.6087401 1.602538  1.5975701
 1.5874696 1.5997249 1.5922644 1.5928321 1.5925087 1.5933306 1.5937663
 1.5941119 1.5934167 1.5934997 1.5933216 1.5931765 1.5932156 1.593255
 1.5931892 1.5932037 1.5932155 1.5931958 1.5932013 1.5932078 1.5932033
 1.5932024 1.5932049 1.5932043 1.5932032 1.5932043 1.5932041 1.5932038
 1.593204  1.5932041 1.5932039 1.5932041 1.5932038 1.5932043 1.5932039
 1.5932041 1.5932038 1.593204  1.593204  1.593204  1.593204 ]


TIME OF ONE EPOCH: 29.797464847564697 seconds and 0.4966244141260783 minutes
Epoch 9
	TRAINING: 292.7126872166991 total train Value loss.

	TESTING: 612.9202880859375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.593255  1.5846359 1.6243784 1.5394437 1.6080878 1.6024785 1.5982984
 1.5895209 1.6006263 1.5937003 1.5943428 1.5938097 1.5945115 1.5950149
 1.5953305 1.594713  1.5948175 1.5946523 1.5945083 1.594537  1.5945674
 1.5945082 1.5945209 1.5945336 1.5945162 1.5945207 1.5945264 1.5945226
 1.5945213 1.5945235 1.5945232 1.5945221 1.5945233 1.594523  1.5945226
 1.5945231 1.5945227 1.5945227 1.5945228 1.5945231 1.5945228 1.5945228
 1.5945228 1.594523  1.5945228 1.5945228 1.5945228 1.594523 ]


TIME OF ONE EPOCH: 30.255658864974976 seconds and 0.5042609810829163 minutes
Epoch 10
	TRAINING: 235.15862880274653 total train Value loss.

	TESTING: 600.550537109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5946597 1.5879092 1.6263481 1.5477532 1.6104277 1.6053253 1.6016353
 1.5941178 1.604176  1.5976615 1.5984135 1.5977268 1.5983127 1.5988672
 1.5991541 1.5985986 1.5987164 1.5985647 1.5984223 1.59844   1.5984652
 1.59841   1.5984211 1.5984339 1.5984184 1.5984213 1.5984278 1.5984238
 1.5984224 1.5984248 1.5984241 1.5984229 1.5984243 1.5984243 1.5984237
 1.598424  1.5984242 1.5984238 1.598424  1.5984238 1.5984241 1.5984238
 1.5984242 1.598424  1.5984238 1.5984238 1.5984241 1.5984238]


TIME OF ONE EPOCH: 33.143261432647705 seconds and 0.5523876905441284 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 929.0853279053218 and inf%

TIME ELAPSED: 296.5068709850311 seconds OR 4.941781183083852 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 96, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16214 train samples and 83 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 12)
  (Dcell): RNNCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 182808.7850341797 total train Value loss.

	TESTING: 3126.88525390625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.90531474 0.9607243  1.1316782  0.887986   1.2615665  0.9941402
 1.2012057  1.0834298  1.1755342  1.1087955  1.152468   1.1364279
 1.138577   1.1409885  1.1381112  1.1420598  1.1372507  1.141796
 1.1384397  1.1406295  1.1391774  1.1401906  1.1395429  1.1398667
 1.1397656  1.1397603  1.1398026  1.1397458  1.1398098  1.1397483
 1.1397982  1.1397628  1.1397866  1.1397707  1.1397808  1.1397755
 1.1397774  1.1397772  1.1397766  1.1397775  1.1397766  1.1397774
 1.1397767  1.1397774  1.1397768  1.1397772  1.1397771  1.139777  ]


TIME OF ONE EPOCH: 30.81327199935913 seconds and 0.5135545333226522 minutes
Epoch 2
	TRAINING: 10171.404174804688 total train Value loss.

	TESTING: 2702.68603515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9551413 1.0355371 1.1142861 1.0257119 1.2167752 1.1107489 1.1937077
 1.1554897 1.1923305 1.1638933 1.1832207 1.1760448 1.1785628 1.1770725
 1.178394  1.1780846 1.1775999 1.1782461 1.1778327 1.1780734 1.1778697
 1.1780638 1.177921  1.1779991 1.1779611 1.1779852 1.1779674 1.1779772
 1.1779745 1.1779737 1.1779748 1.177974  1.177975  1.1779737 1.177975
 1.1779742 1.1779747 1.1779743 1.1779746 1.1779742 1.1779747 1.1779742
 1.1779747 1.1779742 1.1779747 1.1779742 1.1779747 1.1779742]


TIME OF ONE EPOCH: 28.162126302719116 seconds and 0.46936877171198527 minutes
Epoch 3
	TRAINING: 6222.966241836548 total train Value loss.

	TESTING: 2438.443115234375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9921807 1.061201  1.1266172 1.0868487 1.2141496 1.1567397 1.2043363
 1.1863184 1.2056253 1.1916898 1.2010893 1.197774  1.1991545 1.198224
 1.199011  1.1987414 1.1986715 1.1988093 1.1987385 1.1987768 1.1987326
 1.1987803 1.1987467 1.198764  1.1987549 1.1987616 1.1987565 1.1987594
 1.1987582 1.1987586 1.1987586 1.1987586 1.1987584 1.1987586 1.1987584
 1.1987584 1.1987586 1.1987584 1.1987586 1.1987584 1.1987587 1.1987584
 1.1987587 1.1987584 1.1987586 1.1987584 1.1987584 1.1987584]


TIME OF ONE EPOCH: 27.607694625854492 seconds and 0.46012824376424155 minutes
Epoch 4
	TRAINING: 4380.760026931763 total train Value loss.

	TESTING: 2234.771484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0260202 1.0782236 1.1446959 1.1275651 1.2242575 1.1868322 1.2197578
 1.2089475 1.220888  1.2130486 1.2183216 1.2164979 1.2173125 1.216795
 1.2172022 1.2170609 1.2170492 1.2170916 1.2170726 1.2170842 1.2170684
 1.217085  1.2170742 1.2170794 1.2170763 1.2170787 1.2170769 1.2170779
 1.2170776 1.2170776 1.2170775 1.2170777 1.2170777 1.2170777 1.2170775
 1.2170776 1.2170776 1.2170777 1.2170776 1.2170777 1.2170774 1.2170776
 1.2170776 1.2170777 1.2170776 1.2170777 1.2170776 1.2170777]


TIME OF ONE EPOCH: 29.093711614608765 seconds and 0.48489519357681277 minutes
Epoch 5
	TRAINING: 3281.5196952819824 total train Value loss.

	TESTING: 2076.7197265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0551109 1.0913634 1.1582112 1.1544607 1.2331569 1.2055287 1.2303362
 1.2232382 1.231199  1.2263367 1.2296262 1.2285271 1.2290008 1.228724
 1.228939  1.228867  1.2288606 1.2288823 1.2288723 1.2288785 1.2288709
 1.2288783 1.2288737 1.2288759 1.2288749 1.2288756 1.2288749 1.2288754
 1.2288749 1.2288752 1.2288749 1.2288752 1.2288749 1.2288752 1.2288749
 1.2288749 1.2288749 1.2288749 1.2288749 1.2288749 1.2288749 1.2288749
 1.2288749 1.2288749 1.2288749 1.2288749 1.2288749 1.2288749]


TIME OF ONE EPOCH: 28.46871280670166 seconds and 0.474478546778361 minutes
Epoch 6
	TRAINING: 2561.1018962860107 total train Value loss.

	TESTING: 1972.1480712890625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0806541 1.0998628 1.1669087 1.1714046 1.238522  1.2165699 1.2364132
 1.2317202 1.2374632 1.2341383 1.236434  1.2357271 1.2360139 1.2358546
 1.2359872 1.235945  1.2359381 1.2359533 1.2359467 1.2359505 1.2359462
 1.23595   1.2359476 1.235949  1.2359481 1.2359488 1.2359481 1.2359486
 1.2359483 1.2359483 1.2359486 1.2359483 1.2359488 1.2359486 1.2359486
 1.2359486 1.2359486 1.2359486 1.2359486 1.2359483 1.2359486 1.2359486
 1.2359486 1.2359486 1.2359486 1.2359486 1.2359486 1.2359486]


TIME OF ONE EPOCH: 27.845327377319336 seconds and 0.4640887896219889 minutes
Epoch 7
	TRAINING: 2056.0207929611206 total train Value loss.

	TESTING: 1907.920166015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1018049 1.1054649 1.1720922 1.1817508 1.2404909 1.2224679 1.238829
 1.2359209 1.2402664 1.2378671 1.2395791 1.2391235 1.2392952 1.2392012
 1.2392925 1.2392659 1.2392588 1.2392708 1.2392659 1.2392685 1.2392656
 1.2392683 1.2392666 1.2392673 1.2392671 1.2392672 1.2392671 1.2392672
 1.239267  1.2392672 1.239267  1.2392675 1.239267  1.2392672 1.239267
 1.2392673 1.2392673 1.239267  1.2392673 1.239267  1.2392672 1.239267
 1.2392672 1.2392671 1.2392673 1.2392671 1.2392675 1.239267 ]


TIME OF ONE EPOCH: 30.327885627746582 seconds and 0.505464760462443 minutes
Epoch 8
	TRAINING: 1683.0732073783875 total train Value loss.

	TESTING: 1852.656982421875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.118314  1.1113143 1.1755526 1.1885998 1.2406497 1.2254364 1.2391412
 1.2374494 1.2407658 1.2390065 1.2403126 1.2400241 1.2401149 1.240067
 1.2401288 1.240113  1.2401047 1.2401154 1.2401118 1.2401133 1.2401114
 1.240113  1.2401123 1.2401125 1.2401123 1.2401128 1.2401123 1.2401125
 1.2401125 1.2401123 1.2401125 1.2401123 1.2401123 1.2401123 1.2401123
 1.2401125 1.2401123 1.2401123 1.2401123 1.2401123 1.2401123 1.2401125
 1.2401123 1.2401125 1.2401123 1.2401123 1.2401123 1.2401123]


TIME OF ONE EPOCH: 27.237953901290894 seconds and 0.45396589835484824 minutes
Epoch 9
	TRAINING: 1398.7336254119873 total train Value loss.

	TESTING: 1807.6629638671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1308947 1.1168498 1.1777009 1.1926417 1.2393368 1.2261621 1.2378218
 1.2369205 1.239481  1.2381626 1.2391847 1.2390031 1.2390398 1.2390218
 1.2390643 1.2390552 1.2390465 1.2390563 1.2390527 1.2390542 1.2390527
 1.2390538 1.2390534 1.2390534 1.2390535 1.2390534 1.2390535 1.2390536
 1.2390534 1.2390535 1.2390534 1.2390534 1.2390534 1.2390535 1.2390535
 1.2390534 1.2390534 1.2390532 1.2390534 1.2390535 1.2390535 1.2390535
 1.2390535 1.2390532 1.2390534 1.2390535 1.2390535 1.2390536]


TIME OF ONE EPOCH: 27.531041622161865 seconds and 0.45885069370269777 minutes
Epoch 10
	TRAINING: 1175.9676609039307 total train Value loss.

	TESTING: 1773.466064453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1409392 1.1222191 1.1794881 1.1952002 1.2376591 1.2260284 1.2360886
 1.2357205 1.2377309 1.2367163 1.2375394 1.2374271 1.2374289 1.2374294
 1.2374599 1.2374545 1.2374456 1.2374547 1.2374516 1.2374524 1.2374513
 1.2374524 1.237452  1.2374521 1.2374521 1.2374521 1.2374521 1.2374521
 1.237452  1.2374521 1.2374521 1.2374521 1.2374521 1.237452  1.2374521
 1.2374521 1.2374521 1.2374519 1.2374521 1.2374521 1.2374521 1.237452
 1.237452  1.237452  1.2374519 1.237452  1.2374521 1.237452 ]


TIME OF ONE EPOCH: 28.5163516998291 seconds and 0.475272528330485 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 787.0263145783819 and inf%

TIME ELAPSED: 286.39279317855835 seconds OR 4.773213219642639 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 96, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16214 train samples and 83 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 24)
  (Dcell): RNNCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 91276.47938919067 total train Value loss.

	TESTING: 2291.71728515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1178018  0.7963327  1.0196749  0.83127546 0.9331876  0.97779703
 0.97858196 0.9333012  0.9649823  1.0087374  1.0307734  1.0031332
 0.9812836  0.98640436 0.9959238  0.98959905 0.9838174  0.9871103
 0.9951289  0.9968751  0.9917852  0.9890488  0.991041   0.9925497
 0.9914879  0.9901876  0.9907786  0.99213487 0.9921997  0.991303
 0.9909931  0.9914165  0.9916844  0.9914498  0.9912084  0.9913358
 0.9915586  0.9915387  0.99138445 0.99135    0.991437   0.991479
 0.9914287  0.99138814 0.99141496 0.99145156 0.9914437  0.99141675]


TIME OF ONE EPOCH: 30.541954040527344 seconds and 0.5090325673421224 minutes
Epoch 2
	TRAINING: 4880.767978668213 total train Value loss.

	TESTING: 1693.0570068359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2659665 1.0709901 1.0512996 0.9109451 1.0272648 1.0816858 1.0676394
 1.033998  1.0547383 1.0981853 1.1012431 1.078926  1.0660335 1.07641
 1.0807278 1.0766585 1.0722954 1.0763015 1.0806782 1.0802299 1.0768929
 1.0762539 1.0776298 1.0781904 1.0773875 1.0769699 1.0775071 1.0780135
 1.0778147 1.0774294 1.0774215 1.0776255 1.0776627 1.0775441 1.0775045
 1.0775832 1.0776347 1.0775979 1.0775539 1.0775626 1.0775894 1.0775892
 1.0775727 1.07757   1.0775812 1.0775857 1.0775799 1.0775753]


TIME OF ONE EPOCH: 32.94070219993591 seconds and 0.5490117033322652 minutes
Epoch 3
	TRAINING: 2637.4865913391113 total train Value loss.

	TESTING: 1395.619140625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3603343 1.198559  1.0963942 1.005442  1.1059928 1.1571063 1.1387341
 1.1165762 1.1329157 1.1706634 1.1648095 1.1494836 1.1401107 1.1494745
 1.151049  1.1483682 1.145757  1.1492507 1.151681  1.1509242 1.1488262
 1.1486906 1.1495129 1.1496812 1.1491975 1.1490903 1.1494544 1.149665
 1.1495063 1.1493244 1.1493516 1.149442  1.1494368 1.1493828 1.1493833
 1.1494235 1.1494374 1.1494161 1.1494011 1.1494081 1.1494166 1.149414
 1.1494085 1.1494098 1.1494141 1.1494145 1.1494118 1.149411 ]


TIME OF ONE EPOCH: 33.19080352783203 seconds and 0.5531800587972006 minutes
Epoch 4
	TRAINING: 1694.1520295143127 total train Value loss.

	TESTING: 1207.45947265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.394327  1.2618587 1.1406623 1.0813777 1.1624072 1.2088892 1.1895607
 1.1776339 1.1892155 1.2205025 1.2118864 1.2020594 1.1943653 1.2017742
 1.2019252 1.2004615 1.1989081 1.2016149 1.2029883 1.2023995 1.201078
 1.2010427 1.2014866 1.2015232 1.2012593 1.2012529 1.2014784 1.2015743
 1.2014792 1.2013885 1.2014064 1.2014436 1.2014346 1.201411  1.2014176
 1.2014372 1.2014415 1.2014314 1.2014258 1.2014289 1.2014316 1.20143
 1.2014282 1.2014292 1.2014307 1.2014308 1.20143   1.2014297]


TIME OF ONE EPOCH: 33.277806997299194 seconds and 0.5546301166216533 minutes
Epoch 5
	TRAINING: 1190.5491361618042 total train Value loss.

	TESTING: 1087.1259765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4075736 1.302399  1.1812259 1.1421921 1.2071186 1.2500414 1.2301859
 1.2258129 1.2328596 1.2591194 1.2498977 1.2438021 1.2370387 1.2428902
 1.2423381 1.2416916 1.240702  1.2427828 1.2436001 1.2432023 1.2423244
 1.2422988 1.2425332 1.2425282 1.242384  1.2424058 1.2425499 1.2426002
 1.2425452 1.2424952 1.2425036 1.2425182 1.2425115 1.242501  1.2425069
 1.2425172 1.242519  1.2425138 1.2425114 1.2425126 1.2425134 1.2425123
 1.242512  1.2425125 1.2425132 1.2425133 1.242513  1.242513 ]


TIME OF ONE EPOCH: 35.96848392486572 seconds and 0.5994747320810954 minutes
Epoch 6
	TRAINING: 899.1907851696014 total train Value loss.

	TESTING: 995.289794921875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4149096 1.3315276 1.2173852 1.1911414 1.2437979 1.2836783 1.2634877
 1.2645237 1.2677003 1.2901497 1.2810826 1.2775295 1.2714235 1.2761276
 1.2752138 1.2750914 1.2744117 1.2760379 1.2765402 1.276289  1.2756777
 1.275647  1.2757645 1.2757474 1.275667  1.2756952 1.2757907 1.2758209
 1.2757894 1.2757595 1.2757623 1.2757672 1.2757624 1.2757572 1.2757617
 1.2757678 1.275769  1.2757664 1.2757653 1.2757658 1.2757657 1.2757651
 1.275765  1.2757657 1.2757659 1.2757657 1.2757655 1.2757654]


TIME OF ONE EPOCH: 34.513259410858154 seconds and 0.5752209901809693 minutes
Epoch 7
	TRAINING: 709.4366226196289 total train Value loss.

	TESTING: 920.770263671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4190515 1.3525369 1.2484474 1.2299864 1.2736672 1.3105922 1.2903872
 1.2951471 1.2952999 1.3147804 1.306179  1.3043405 1.2987937 1.3026472
 1.3015587 1.3017578 1.3012568 1.3025537 1.3028696 1.3027208 1.3022765
 1.3022425 1.3022943 1.3022747 1.3022288 1.3022561 1.3023225 1.3023425
 1.3023245 1.3023053 1.3023057 1.3023063 1.3023025 1.3023001 1.3023033
 1.3023071 1.3023081 1.3023067 1.3023058 1.302306  1.3023057 1.3023057
 1.3023053 1.3023057 1.302306  1.302306  1.302306  1.3023058]


TIME OF ONE EPOCH: 33.2780225276947 seconds and 0.5546337087949117 minutes
Epoch 8
	TRAINING: 575.2591309547424 total train Value loss.

	TESTING: 860.0953369140625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4221331 1.3688    1.2748944 1.2615366 1.2985849 1.3328153 1.3127074
 1.3199927 1.3178465 1.334962  1.3268877 1.3262211 1.3211917 1.3244232
 1.3232616 1.3236513 1.3232552 1.3243097 1.324507  1.3244259 1.3240914
 1.324059  1.3240738 1.324056  1.3240293 1.3240534 1.3241007 1.3241153
 1.3241049 1.3240925 1.324091  1.3240896 1.324087  1.3240858 1.3240882
 1.3240905 1.3240911 1.3240907 1.3240904 1.3240902 1.32409   1.3240898
 1.3240899 1.3240899 1.32409   1.32409   1.3240901 1.32409  ]


TIME OF ONE EPOCH: 33.526795864105225 seconds and 0.5587799310684204 minutes
Epoch 9
	TRAINING: 475.4239044189453 total train Value loss.

	TESTING: 812.8341064453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4252633 1.3826966 1.2983239 1.2885493 1.3208382 1.3526405 1.3327537
 1.3416319 1.3378049 1.3529501 1.345395  1.3455266 1.3409994 1.3437717
 1.3426025 1.3430974 1.3427641 1.3436329 1.3437479 1.3437104 1.3434516
 1.3434246 1.3434199 1.3434055 1.3433892 1.34341   1.3434439 1.3434551
 1.3434488 1.34344   1.3434385 1.3434368 1.3434347 1.3434337 1.3434358
 1.3434373 1.343438  1.3434376 1.3434374 1.3434373 1.3434371 1.343437
 1.343437  1.343437  1.3434373 1.3434372 1.3434374 1.3434374]


TIME OF ONE EPOCH: 35.73105978965759 seconds and 0.5955176631609599 minutes
Epoch 10
	TRAINING: 402.9647470712662 total train Value loss.

	TESTING: 778.6368408203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4279795 1.3938048 1.317895  1.310603  1.3394709 1.368953  1.3494207
 1.3591474 1.3541447 1.367651  1.3605984 1.3612576 1.357195  1.3596272
 1.358488  1.3590318 1.3587354 1.359462  1.3595203 1.3595107 1.3593041
 1.359284  1.3592694 1.3592591 1.3592482 1.3592659 1.3592907 1.3592994
 1.3592955 1.3592896 1.3592875 1.3592858 1.3592844 1.3592843 1.3592854
 1.3592867 1.3592873 1.359287  1.3592869 1.3592867 1.3592864 1.3592864
 1.3592862 1.3592863 1.3592864 1.3592864 1.3592864 1.3592865]


TIME OF ONE EPOCH: 34.34192252159119 seconds and 0.5723653753598531 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 914.9275828901543 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 338.0411581993103 seconds OR 5.634019303321838 minutes

End of run




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 96, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16214 train samples and 83 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 48)
  (Dcell): RNNCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 28708.908576965332 total train Value loss.

	TESTING: 1072.653564453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5339078 1.5270386 1.4780236 1.4331656 1.5825047 1.569254  1.548215
 1.5064778 1.5575304 1.5392007 1.5375919 1.5488747 1.5498587 1.5423585
 1.5472468 1.5429225 1.5415158 1.543498  1.5444275 1.5418494 1.5427287
 1.542446  1.5415665 1.5420108 1.5423048 1.5420954 1.542174  1.5422652
 1.5421333 1.5420918 1.542222  1.542166  1.5421559 1.5422018 1.542171
 1.5421551 1.5421761 1.5421745 1.5421668 1.542176  1.5421758 1.5421677
 1.5421722 1.5421731 1.5421705 1.542172  1.542173  1.5421716]


TIME OF ONE EPOCH: 39.93293070793152 seconds and 0.6655488451321919 minutes
Epoch 2
	TRAINING: 1816.7859630584717 total train Value loss.

	TESTING: 1014.6817626953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5254443 1.5298493 1.5263108 1.4616557 1.5777675 1.5637517 1.5578421
 1.5265636 1.5529896 1.5388886 1.5406771 1.5457114 1.5484705 1.543464
 1.5458481 1.5436878 1.5430679 1.5437987 1.544291  1.5432315 1.5435328
 1.5433295 1.5429883 1.5430819 1.5432049 1.543159  1.5431867 1.5432212
 1.5431812 1.5431604 1.5431976 1.5431832 1.5431805 1.5431921 1.5431851
 1.5431784 1.5431831 1.5431831 1.5431811 1.5431842 1.5431839 1.5431823
 1.5431828 1.5431832 1.5431827 1.5431828 1.5431833 1.543183 ]


TIME OF ONE EPOCH: 40.789031744003296 seconds and 0.6798171957333883 minutes
Epoch 3
	TRAINING: 957.3700618743896 total train Value loss.

	TESTING: 961.4925537109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5039952 1.5100611 1.5309318 1.4800888 1.5741832 1.5578383 1.551376
 1.530845  1.5493038 1.5385247 1.5401326 1.5439839 1.5457329 1.5420374
 1.5438261 1.542491  1.5421684 1.5425589 1.5427972 1.5421318 1.5422364
 1.5421417 1.5419451 1.5419952 1.5420759 1.5420464 1.5420555 1.5420791
 1.5420606 1.5420492 1.5420691 1.5420624 1.542058  1.5420642 1.5420606
 1.5420576 1.5420597 1.54206   1.5420588 1.5420601 1.5420603 1.5420594
 1.5420599 1.5420598 1.5420598 1.5420595 1.5420599 1.5420599]


TIME OF ONE EPOCH: 40.64533042907715 seconds and 0.6774221738179524 minutes
Epoch 4
	TRAINING: 654.1970772743225 total train Value loss.

	TESTING: 963.4310913085938 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4982826 1.4960538 1.5195282 1.4845282 1.5675719 1.5503927 1.542063
 1.5275033 1.5434598 1.533687  1.535738  1.5395577 1.5401866 1.5374534
 1.5389473 1.5377976 1.5375535 1.537863  1.5379634 1.5374639 1.5375292
 1.5374831 1.5373387 1.5373831 1.5374475 1.5374181 1.537423  1.5374432
 1.537428  1.5374212 1.5374357 1.5374309 1.5374271 1.5374315 1.5374293
 1.537427  1.5374289 1.537429  1.5374283 1.5374291 1.537429  1.5374285
 1.5374286 1.5374287 1.5374287 1.5374289 1.5374289 1.5374289]


TIME OF ONE EPOCH: 40.570701360702515 seconds and 0.6761783560117086 minutes
Epoch 5
	TRAINING: 495.2045519351959 total train Value loss.

	TESTING: 946.849365234375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5025452 1.4947332 1.5120926 1.4889998 1.5658392 1.5491635 1.5407596
 1.5289907 1.5431057 1.5341362 1.5366361 1.5402844 1.5401355 1.5382121
 1.539393  1.5382991 1.5381076 1.5383645 1.5383935 1.5380142 1.5380741
 1.5380502 1.5379355 1.537976  1.5380257 1.5379975 1.5380021 1.538019
 1.5380065 1.5380017 1.5380127 1.5380089 1.5380063 1.5380095 1.5380082
 1.5380063 1.5380079 1.538008  1.5380074 1.5380079 1.5380076 1.5380075
 1.5380076 1.5380077 1.5380077 1.5380075 1.5380077 1.5380075]


TIME OF ONE EPOCH: 39.900761127471924 seconds and 0.6650126854578654 minutes
Epoch 6
	TRAINING: 371.62694454193115 total train Value loss.

	TESTING: 911.162841796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.507387  1.4953874 1.5066446 1.4918829 1.5636171 1.5475916 1.5393994
 1.5292795 1.5419828 1.5334792 1.5362983 1.5397902 1.5390396 1.537701
 1.5386848 1.5376003 1.5374279 1.5376761 1.5376602 1.5373522 1.5374246
 1.5374092 1.5373069 1.5373483 1.5373875 1.5373586 1.5373653 1.5373799
 1.5373678 1.537365  1.5373741 1.5373701 1.5373683 1.5373714 1.5373701
 1.537369  1.5373701 1.53737   1.5373694 1.5373701 1.5373701 1.5373693
 1.53737   1.53737   1.5373698 1.5373696 1.53737   1.5373697]


TIME OF ONE EPOCH: 44.07347059249878 seconds and 0.734557843208313 minutes
Epoch 7
	TRAINING: 315.9644991159439 total train Value loss.

	TESTING: 883.554931640625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5091848 1.4941846 1.4995979 1.4908639 1.5578986 1.5427501 1.5348679
 1.5259253 1.537455  1.5292286 1.5323166 1.5356071 1.5344114 1.5334992
 1.5343417 1.5332614 1.5330979 1.5333458 1.533298  1.5330344 1.5331231
 1.5331098 1.5330153 1.5330592 1.5330902 1.5330607 1.5330688 1.5330828
 1.5330707 1.5330688 1.5330774 1.5330733 1.5330714 1.5330747 1.5330734
 1.5330725 1.5330737 1.5330734 1.5330728 1.5330737 1.5330735 1.5330731
 1.5330733 1.5330733 1.5330735 1.5330733 1.5330735 1.5330733]


TIME OF ONE EPOCH: 40.0722770690918 seconds and 0.6678712844848633 minutes
Epoch 8
	TRAINING: 265.4168971776962 total train Value loss.

	TESTING: 862.1614990234375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5167122 1.5007306 1.5021493 1.4973823 1.5600698 1.5457948 1.5385802
 1.5303775 1.5408429 1.5329442 1.5361565 1.5391846 1.5376931 1.537089
 1.537816  1.5367573 1.5366046 1.5368483 1.5367799 1.5365505 1.5366501
 1.5366366 1.536548  1.5365937 1.5366185 1.5365888 1.5365987 1.5366111
 1.5365989 1.5365983 1.5366066 1.5366018 1.5366006 1.5366038 1.5366024
 1.5366014 1.5366027 1.5366026 1.5366019 1.5366023 1.5366023 1.536602
 1.5366023 1.5366025 1.5366024 1.5366026 1.5366025 1.5366025]


TIME OF ONE EPOCH: 39.95988607406616 seconds and 0.665998101234436 minutes
Epoch 9
	TRAINING: 219.25682121515274 total train Value loss.

	TESTING: 824.783935546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5219151 1.5060209 1.5041684 1.5024052 1.5608413 1.5478696 1.5415115
 1.5338819 1.5433623 1.5359796 1.5391483 1.5418586 1.5402329 1.5398175
 1.5404042 1.5394135 1.5392663 1.5394887 1.5394187 1.5392226 1.5393219
 1.5393124 1.5392329 1.5392758 1.5392959 1.5392683 1.5392778 1.539289
 1.539278  1.5392779 1.539285  1.5392811 1.5392798 1.5392827 1.5392816
 1.5392805 1.5392815 1.5392815 1.5392809 1.5392812 1.5392812 1.5392812
 1.5392816 1.5392814 1.5392812 1.5392815 1.5392814 1.5392811]


TIME OF ONE EPOCH: 41.13639974594116 seconds and 0.6856066624323527 minutes
Epoch 10
	TRAINING: 190.16572666168213 total train Value loss.

	TESTING: 812.4410400390625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5247499 1.5076203 1.5023926 1.503066  1.5571    1.5449263 1.5398564
 1.532603  1.541071  1.534133  1.5373292 1.5396818 1.5380142 1.5377958
 1.5382365 1.5373207 1.537204  1.5373998 1.5373262 1.537164  1.537258
 1.5372463 1.537177  1.5372173 1.5372317 1.5372075 1.5372173 1.5372266
 1.5372169 1.5372177 1.537223  1.5372195 1.5372189 1.5372213 1.5372202
 1.5372194 1.5372205 1.5372201 1.5372198 1.53722   1.5372204 1.53722
 1.5372202 1.5372201 1.5372201 1.53722   1.5372201 1.53722  ]


TIME OF ONE EPOCH: 39.970741748809814 seconds and 0.6661790291468302 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 885.4131763259091 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 407.9725730419159 seconds OR 6.799542884031932 minutes

End of run




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 192, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16118 train samples and 81 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 12)
  (Dcell): RNNCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 176703.7890777588 total train Value loss.

	TESTING: 3379.150146484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.95012605 0.9531961  1.1331762  0.9415946  1.2600238  1.0372803
 1.2111468  1.112798   1.1963927  1.1278362  1.1757491  1.1571864
 1.1605783  1.1615899  1.1602877  1.1636145  1.1582876  1.1639625
 1.1594877  1.1626121  1.1603327  1.1621128  1.1608226  1.1616011
 1.1612229  1.1613761  1.1613308  1.1613109  1.1613791  1.1612866
 1.1613778  1.1613021  1.1613611  1.1613154  1.1613495  1.1613262
 1.1613405  1.1613326  1.1613367  1.1613349  1.1613351  1.1613358
 1.1613345  1.161336   1.1613348  1.1613357  1.1613351  1.1613355 ]


TIME OF ONE EPOCH: 42.078277826309204 seconds and 0.7013046304384868 minutes
Epoch 2
	TRAINING: 8161.25394821167 total train Value loss.

	TESTING: 3136.1826171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.98588955 1.0178806  1.1077788  1.0422953  1.2085477  1.1256889
 1.1982932  1.168571   1.2067033  1.1718518  1.1986631  1.1881495
 1.1927435  1.1889116  1.1929811  1.1909416  1.1910993  1.1916494
 1.1913433  1.1914653  1.1912596  1.1915979  1.1912818  1.1914858
 1.1913674  1.1914595  1.1913762  1.1914388  1.1914028  1.191421
 1.1914096  1.1914184  1.1914133  1.1914148  1.1914152  1.1914142
 1.1914151  1.1914141  1.1914152  1.1914142  1.191415   1.1914146
 1.1914148  1.1914146  1.191415   1.1914146  1.1914147  1.191415  ]


TIME OF ONE EPOCH: 42.68254637718201 seconds and 0.7113757729530334 minutes
Epoch 3
	TRAINING: 4887.317726135254 total train Value loss.

	TESTING: 2881.284423828125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0088809 1.0481225 1.1100717 1.085831  1.1934472 1.1575742 1.1934336
 1.186803  1.2058985 1.1882206 1.2020127 1.1982336 1.1999111 1.1978335
 1.2004355 1.1991363 1.199379  1.1994475 1.1995829 1.1993966 1.1994611
 1.199517  1.1994563 1.1994753 1.1994759 1.1994854 1.199467  1.1994817
 1.199475  1.1994777 1.199475  1.199478  1.199476  1.1994768 1.1994765
 1.199477  1.1994766 1.1994766 1.1994767 1.199477  1.1994766 1.1994768
 1.1994766 1.1994768 1.1994767 1.1994768 1.1994768 1.1994771]


TIME OF ONE EPOCH: 42.290865659713745 seconds and 0.7048477609952291 minutes
Epoch 4
	TRAINING: 3426.7862586975098 total train Value loss.

	TESTING: 2684.77294921875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0222697 1.0605502 1.1175554 1.1094496 1.1910824 1.1717435 1.1952083
 1.1947868 1.2066239 1.1962256 1.2044464 1.2030201 1.2036481 1.202555
 1.2040993 1.2034113 1.2034984 1.2035486 1.2036563 1.2035267 1.2035753
 1.2035977 1.2035773 1.2035749 1.2035838 1.203584  1.203578  1.2035823
 1.2035818 1.2035811 1.203581  1.2035817 1.2035815 1.2035813 1.2035815
 1.2035815 1.2035813 1.2035815 1.2035813 1.2035815 1.2035815 1.2035813
 1.2035815 1.2035815 1.2035815 1.2035815 1.2035815 1.2035815]


TIME OF ONE EPOCH: 42.618277072906494 seconds and 0.7103046178817749 minutes
Epoch 5
	TRAINING: 2552.985273361206 total train Value loss.

	TESTING: 2540.2109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0349188 1.0660088 1.1243032 1.1249214 1.1928898 1.1795797 1.1984118
 1.1996949 1.2079389 1.2011331 1.2067387 1.2060866 1.2063434 1.2057579
 1.2067134 1.2063216 1.2063475 1.2063996 1.2064588 1.2063847 1.2064115
 1.2064259 1.2064147 1.2064121 1.206418  1.2064179 1.2064148 1.2064168
 1.2064168 1.2064164 1.2064162 1.2064168 1.2064161 1.2064168 1.2064165
 1.2064166 1.2064164 1.2064167 1.2064165 1.2064168 1.2064166 1.2064167
 1.2064166 1.2064166 1.2064166 1.2064166 1.2064166 1.2064166]


TIME OF ONE EPOCH: 41.81851124763489 seconds and 0.6969751874605815 minutes
Epoch 6
	TRAINING: 1990.457820892334 total train Value loss.

	TESTING: 2446.060791015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0477595 1.0687181 1.1284515 1.1351672 1.1943659 1.1837859 1.2003094
 1.2023388 1.2083668 1.203641  1.2078506 1.2074964 1.2075866 1.207287
 1.207919  1.2076677 1.2076764 1.2077264 1.2077566 1.207712  1.2077293
 1.207739  1.2077309 1.2077302 1.2077336 1.2077334 1.2077317 1.2077328
 1.207733  1.2077326 1.2077328 1.207733  1.2077326 1.2077327 1.2077329
 1.2077327 1.2077328 1.2077328 1.2077328 1.2077328 1.2077328 1.2077328
 1.2077328 1.2077327 1.2077328 1.2077328 1.2077327 1.2077328]


TIME OF ONE EPOCH: 42.195619106292725 seconds and 0.7032603184382121 minutes
Epoch 7
	TRAINING: 1609.1223192214966 total train Value loss.

	TESTING: 2390.498046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0609808 1.0708747 1.1308286 1.1421118 1.1948385 1.1857332 1.2007183
 1.203242  1.207687  1.2043191 1.2076735 1.207458  1.207452  1.207329
 1.2077684 1.2075905 1.2075956 1.2076428 1.207656  1.2076279 1.2076402
 1.2076468 1.2076405 1.207641  1.207643  1.2076426 1.2076418 1.2076424
 1.2076426 1.2076423 1.2076422 1.2076426 1.2076426 1.2076423 1.2076423
 1.2076423 1.2076423 1.2076423 1.2076423 1.2076426 1.2076424 1.2076423
 1.2076423 1.2076424 1.2076423 1.2076423 1.2076423 1.2076423]


TIME OF ONE EPOCH: 41.86129331588745 seconds and 0.6976882219314575 minutes
Epoch 8
	TRAINING: 1330.6763124465942 total train Value loss.

	TESTING: 2355.13525390625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.074046  1.0738881 1.1326977 1.1475204 1.1951786 1.1870648 1.2008525
 1.2037232 1.2070154 1.2045804 1.2073655 1.2072195 1.2071588 1.2071459
 1.2074642 1.207329  1.2073349 1.207378  1.207382  1.2073634 1.207373
 1.2073776 1.2073729 1.2073733 1.207375  1.2073745 1.2073739 1.2073745
 1.2073746 1.2073743 1.2073743 1.2073745 1.2073743 1.2073745 1.2073745
 1.2073745 1.2073745 1.2073745 1.2073745 1.2073745 1.2073745 1.2073743
 1.2073745 1.2073745 1.2073745 1.2073745 1.2073745 1.2073745]


TIME OF ONE EPOCH: 41.954265832901 seconds and 0.6992377638816833 minutes
Epoch 9
	TRAINING: 1117.0152921676636 total train Value loss.

	TESTING: 2328.9638671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0866826 1.0781568 1.1348945 1.1523442 1.1959307 1.18855   1.2013392
 1.2044135 1.2068602 1.2050779 1.2074604 1.2073482 1.2072582 1.2073123
 1.2075516 1.2074426 1.2074506 1.2074896 1.2074882 1.2074752 1.2074836
 1.2074865 1.2074828 1.2074833 1.207485  1.2074841 1.207484  1.2074845
 1.2074842 1.2074841 1.2074844 1.2074844 1.2074841 1.2074842 1.2074842
 1.2074842 1.2074841 1.2074841 1.2074842 1.2074842 1.2074841 1.2074842
 1.2074841 1.2074842 1.2074841 1.2074842 1.2074841 1.2074841]


TIME OF ONE EPOCH: 41.95295786857605 seconds and 0.6992159644762675 minutes
Epoch 10
	TRAINING: 945.8436880111694 total train Value loss.

	TESTING: 2305.792236328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0987608 1.0835338 1.1380229 1.1573143 1.1975708 1.1908007 1.2027345
 1.2058736 1.2077032 1.206389  1.2084651 1.2083678 1.2082661 1.2083594
 1.2085441 1.208453  1.2084635 1.2084979 1.2084935 1.2084843 1.2084917
 1.2084937 1.2084906 1.2084916 1.2084923 1.208492  1.2084918 1.2084922
 1.2084919 1.2084919 1.208492  1.2084918 1.208492  1.2084919 1.208492
 1.208492  1.2084919 1.2084919 1.2084919 1.2084918 1.2084918 1.2084918
 1.208492  1.208492  1.208492  1.2084919 1.2084919 1.208492 ]


TIME OF ONE EPOCH: 41.46239352226257 seconds and 0.6910398920377095 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 744.9083957750611 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 423.1056582927704 seconds OR 7.051760971546173 minutes

End of run




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 192, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16118 train samples and 81 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 24)
  (Dcell): RNNCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 83627.11171340942 total train Value loss.

	TESTING: 2205.720703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0107588  0.84461653 1.002935   0.75435174 0.7650251  0.8683555
 0.8476076  0.8693684  0.8575698  0.8995016  0.91436744 0.8980674
 0.870702   0.8725103  0.8773781  0.87761986 0.8724898  0.87307984
 0.87778276 0.8810793  0.87793976 0.8753864  0.8756857  0.87717426
 0.8770443  0.87608933 0.875923   0.87675637 0.87712824 0.8767326
 0.8763393  0.8764616  0.8767168  0.8766987  0.87651414 0.8764886
 0.8766129  0.87667227 0.87660706 0.8765483  0.87657213 0.8766164
 0.87661135 0.87658036 0.8765755  0.8765958  0.87660503 0.87659425]


TIME OF ONE EPOCH: 48.626686096191406 seconds and 0.8104447682698568 minutes
Epoch 2
	TRAINING: 3694.4350605010986 total train Value loss.

	TESTING: 1854.4739990234375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1639487  1.0246909  0.99894273 0.8275731  0.8853561  0.9778816
 0.9536275  0.94558966 0.94798815 0.99265313 0.9982817  0.977306
 0.9586798  0.96605575 0.9713502  0.96950275 0.96391106 0.96618325
 0.97075206 0.9717894  0.9685635  0.9670953  0.9681528  0.9692509
 0.9687262  0.96796685 0.9681788  0.9688249  0.9688795  0.9684788
 0.9683095  0.96849877 0.9686436  0.9685581  0.96844655 0.9684799
 0.96856505 0.9685681  0.9685132  0.96849483 0.9685238  0.9685426
 0.968529   0.96851355 0.96851885 0.9685304  0.9685301  0.9685224 ]


TIME OF ONE EPOCH: 51.97202396392822 seconds and 0.8662003993988037 minutes
Epoch 3
	TRAINING: 1897.1933975219727 total train Value loss.

	TESTING: 1661.516357421875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2489418  1.1177304  1.0307895  0.89456666 0.9626173  1.041708
 1.0168719  0.9986899  1.0075618  1.0491006  1.050157   1.02925
 1.015146   1.023735   1.028366   1.0255076  1.0206509  1.0233861
 1.0273424  1.0274551  1.024528   1.0236341  1.0248256  1.0256046
 1.0249971  1.0244302  1.0247428  1.0252391  1.025175   1.0248324
 1.0247629  1.024945   1.0250287  1.0249364  1.0248656  1.0249115
 1.0249704  1.0249563  1.0249139  1.0249106  1.0249358  1.0249442
 1.0249306  1.0249224  1.0249289  1.0249362  1.0249335  1.0249283 ]


TIME OF ONE EPOCH: 51.476587533950806 seconds and 0.8579431255658467 minutes
Epoch 4
	TRAINING: 1263.5984802246094 total train Value loss.

	TESTING: 1503.813720703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2696865  1.1544983  1.0455185  0.9345215  0.99809074 1.0635834
 1.041415   1.0218047  1.0324945  1.0695337  1.0684488  1.0493824
 1.0380647  1.0461246  1.0499873  1.0471374  1.0431819  1.0458033
 1.0490893  1.0488328  1.0463449  1.0457476  1.0468293  1.0473989
 1.0468532  1.0464355  1.0467391  1.0471126  1.0470166  1.0467427
 1.0467154  1.046867   1.0469189  1.04684    1.0467937  1.0468357
 1.0468761  1.0468593  1.0468284  1.0468297  1.0468495  1.0468531
 1.0468423  1.0468377  1.0468432  1.0468477  1.0468452  1.0468417 ]


TIME OF ONE EPOCH: 50.9040904045105 seconds and 0.8484015067418417 minutes
Epoch 5
	TRAINING: 940.891188621521 total train Value loss.

	TESTING: 1390.8447265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2735474 1.1781487 1.0618562 0.9703009 1.0283139 1.0824664 1.0638603
 1.0447842 1.0558294 1.0885895 1.0865551 1.0695903 1.0601785 1.067324
 1.0706171 1.0680674 1.0648545 1.0671716 1.0698814 1.0694922 1.0674148
 1.066979  1.0679057 1.0683442 1.0678914 1.0675762 1.0678366 1.068119
 1.0680237 1.0678084 1.0677986 1.0679196 1.0679545 1.0678923 1.0678604
 1.067894  1.0679225 1.0679076 1.0678849 1.0678878 1.0679021 1.0679039
 1.0678961 1.0678931 1.0678977 1.0679003 1.0678983 1.0678962]


TIME OF ONE EPOCH: 51.703399896621704 seconds and 0.8617233316103617 minutes
Epoch 6
	TRAINING: 730.8817977905273 total train Value loss.

	TESTING: 1296.380126953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2727352 1.1937279 1.0773522 1.000231  1.0541965 1.0991534 1.0840291
 1.0657771 1.0766226 1.1055133 1.1031364 1.0881708 1.080189  1.0864244
 1.0892906 1.087086  1.084451  1.08643   1.0886618 1.0882437 1.086519
 1.0861846 1.086963  1.0873139 1.0869482 1.0867046 1.0869164 1.0871314
 1.0870472 1.0868793 1.0868769 1.0869719 1.0869974 1.0869496 1.0869266
 1.0869523 1.0869725 1.0869602 1.086944  1.0869466 1.0869573 1.0869585
 1.0869528 1.086951  1.0869539 1.0869557 1.0869541 1.0869526]


TIME OF ONE EPOCH: 50.21985459327698 seconds and 0.8369975765546163 minutes
Epoch 7
	TRAINING: 575.4074053764343 total train Value loss.

	TESTING: 1203.432861328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2665713 1.2000098 1.0890452 1.0218322 1.0727017 1.1097659 1.0979477
 1.0806612 1.0910804 1.1165698 1.1142249 1.1010251 1.0941385 1.0994956
 1.1020337 1.1001574 1.0979867 1.0996481 1.1014949 1.1010952 1.0996633
 1.099395  1.100043  1.1003307 1.1000389 1.0998472 1.1000158 1.1001804
 1.1001103 1.0999792 1.0999795 1.1000543 1.1000737 1.1000371 1.1000202
 1.1000395 1.1000538 1.1000445 1.1000326 1.1000348 1.1000426 1.1000433
 1.1000389 1.1000378 1.1000402 1.1000414 1.1000404 1.100039 ]


TIME OF ONE EPOCH: 52.21038579940796 seconds and 0.8701730966567993 minutes
Epoch 8
	TRAINING: 468.0890395641327 total train Value loss.

	TESTING: 1136.4952392578125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.260934  1.2035507 1.1003059 1.0403662 1.0885259 1.1190783 1.1101471
 1.0938896 1.1036866 1.1262285 1.1241132 1.1125087 1.1064867 1.1110574
 1.1133108 1.1117336 1.1099303 1.1113164 1.1128513 1.1124932 1.1113017
 1.1110789 1.1116147 1.1118548 1.1116239 1.1114709 1.1116031 1.1117308
 1.1116737 1.1115712 1.111572  1.1116306 1.1116459 1.111618  1.1116049
 1.1116192 1.1116297 1.1116229 1.1116145 1.1116161 1.1116217 1.1116225
 1.1116194 1.1116184 1.1116197 1.1116208 1.1116202 1.1116192]


TIME OF ONE EPOCH: 49.8497748374939 seconds and 0.8308295806248983 minutes
Epoch 9
	TRAINING: 391.0776159763336 total train Value loss.

	TESTING: 1089.72412109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2590725 1.208946  1.1139885 1.059976  1.1061344 1.1314136 1.1248597
 1.1095784 1.1187559 1.1387397 1.1369107 1.1267102 1.1214143 1.1253123
 1.1273018 1.125976  1.1244723 1.1256342 1.1269155 1.1266016 1.1256068
 1.1254182 1.1258602 1.1260613 1.1258787 1.1257563 1.1258605 1.1259599
 1.1259139 1.1258332 1.1258339 1.1258798 1.125892  1.1258711 1.1258609
 1.1258715 1.1258793 1.1258742 1.1258677 1.1258693 1.1258733 1.1258737
 1.1258717 1.1258711 1.125872  1.1258724 1.1258719 1.1258714]


TIME OF ONE EPOCH: 50.15643882751465 seconds and 0.8359406471252442 minutes
Epoch 10
	TRAINING: 328.7255289554596 total train Value loss.

	TESTING: 1047.29296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2569777 1.213265  1.1272718 1.0776024 1.1224022 1.1433686 1.1389207
 1.1244762 1.1329708 1.1507535 1.149255  1.1402597 1.1355627 1.1389003
 1.1406813 1.139565  1.138294  1.1392674 1.1403488 1.1400789 1.1392412
 1.1390778 1.1394451 1.1396163 1.139471  1.1393716 1.1394532 1.1395317
 1.1394948 1.1394305 1.139431  1.1394677 1.1394775 1.1394616 1.1394536
 1.1394615 1.1394671 1.1394635 1.1394584 1.1394596 1.1394626 1.1394632
 1.1394615 1.139461  1.1394619 1.1394622 1.139462  1.1394614]


TIME OF ONE EPOCH: 49.706929445266724 seconds and 0.8284488240877788 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 883.224170480736 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 509.57029485702515 seconds OR 8.492838247617085 minutes

End of run




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 192, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16118 train samples and 81 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 48)
  (Dcell): RNNCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 27483.300479888916 total train Value loss.

	TESTING: 1124.306884765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4233843 1.3118663 1.2474508 1.2464104 1.3099322 1.3432713 1.291586
 1.2668853 1.304027  1.3057841 1.3059676 1.3181652 1.3182883 1.3112808
 1.3136888 1.3096807 1.3107507 1.3099291 1.3113067 1.3113351 1.3105851
 1.3111463 1.3105323 1.3106914 1.3108596 1.3107978 1.3108624 1.3107684
 1.310814  1.3107634 1.3107818 1.3108068 1.3107923 1.3108032 1.3108027
 1.3107984 1.310796  1.3107973 1.3107964 1.310797  1.3107979 1.3107985
 1.310798  1.3107977 1.3107976 1.3107975 1.3107979 1.3107979]


TIME OF ONE EPOCH: 72.15162897109985 seconds and 1.202527149518331 minutes
Epoch 2
	TRAINING: 1487.7878694534302 total train Value loss.

	TESTING: 1066.486083984375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3866584 1.293991  1.2569954 1.2374316 1.2913278 1.3406796 1.301957
 1.267711  1.3027475 1.2976955 1.307513  1.315735  1.3144114 1.3086922
 1.3088487 1.3071551 1.3082265 1.3080549 1.3085759 1.3085157 1.308102
 1.3083553 1.3081968 1.3081726 1.3082343 1.3081928 1.3082258 1.3081998
 1.3082312 1.3082083 1.3082058 1.308215  1.3082076 1.3082128 1.3082143
 1.3082138 1.3082124 1.3082126 1.3082129 1.308212  1.3082126 1.3082128
 1.3082128 1.3082129 1.308213  1.3082126 1.3082126 1.3082126]


TIME OF ONE EPOCH: 72.36696767807007 seconds and 1.2061161279678345 minutes
Epoch 3
	TRAINING: 802.0849657058716 total train Value loss.

	TESTING: 1053.9400634765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3472655 1.2704039 1.2503953 1.2319106 1.2806557 1.3356718 1.2976927
 1.2645912 1.2950013 1.2884246 1.3002791 1.3069556 1.3049636 1.2999771
 1.3000673 1.2990669 1.2996157 1.2997899 1.2999592 1.2998773 1.2996825
 1.2998624 1.2998013 1.2997514 1.299791  1.2997432 1.2997602 1.2997609
 1.2997782 1.2997669 1.2997653 1.2997684 1.2997628 1.2997668 1.2997676
 1.2997673 1.2997673 1.2997668 1.2997667 1.2997664 1.299767  1.2997667
 1.2997669 1.2997668 1.299767  1.2997668 1.2997667 1.2997668]


TIME OF ONE EPOCH: 72.20218563079834 seconds and 1.2033697605133056 minutes
Epoch 4
	TRAINING: 545.2549333572388 total train Value loss.

	TESTING: 1008.4510498046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3216437 1.2566677 1.2424283 1.2234436 1.2690709 1.3236119 1.2862024
 1.2559925 1.2833986 1.2752433 1.2878517 1.2935348 1.2910302 1.2865691
 1.2868632 1.286173  1.2864068 1.2868011 1.2868122 1.2866795 1.2865864
 1.2867398 1.2866932 1.2866534 1.2866964 1.2866396 1.2866522 1.2866613
 1.2866701 1.2866622 1.2866639 1.286665  1.2866594 1.2866633 1.2866637
 1.2866629 1.2866629 1.2866633 1.286663  1.2866628 1.286663  1.2866629
 1.2866629 1.2866629 1.286663  1.2866632 1.2866629 1.2866632]


TIME OF ONE EPOCH: 72.33264803886414 seconds and 1.2055441339810689 minutes
Epoch 5
	TRAINING: 407.7495265007019 total train Value loss.

	TESTING: 1001.6824951171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3098973 1.2560349 1.2442939 1.2250271 1.2675694 1.3192428 1.283715
 1.2561717 1.2814734 1.272329  1.2850208 1.2899802 1.2871317 1.2831033
 1.2835507 1.2830846 1.2831334 1.283656  1.2835872 1.2834104 1.2833656
 1.2835044 1.2834563 1.2834282 1.2834768 1.283416  1.283426  1.283439
 1.2834419 1.2834361 1.2834395 1.2834398 1.2834343 1.2834388 1.2834386
 1.2834375 1.2834382 1.283438  1.2834376 1.2834377 1.2834382 1.2834378
 1.283438  1.283438  1.2834378 1.2834377 1.2834378 1.2834378]


TIME OF ONE EPOCH: 72.57981705665588 seconds and 1.2096636176109314 minutes
Epoch 6
	TRAINING: 315.5755921602249 total train Value loss.

	TESTING: 1000.9647216796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3057368 1.2612478 1.2489381 1.2305034 1.2707297 1.3180711 1.2855326
 1.2602078 1.283947  1.2744005 1.2866721 1.2909918 1.2879145 1.2843602
 1.2848978 1.2845955 1.2845109 1.2850938 1.2849725 1.2847749 1.2847682
 1.2848892 1.2848401 1.2848207 1.2848704 1.2848094 1.2848189 1.2848331
 1.284832  1.2848277 1.2848321 1.2848314 1.2848266 1.2848312 1.2848308
 1.2848294 1.2848303 1.2848302 1.2848296 1.2848301 1.2848303 1.2848301
 1.2848301 1.2848303 1.2848301 1.2848301 1.2848301 1.2848301]


TIME OF ONE EPOCH: 72.76252555847168 seconds and 1.2127087593078614 minutes
Epoch 7
	TRAINING: 257.8342595100403 total train Value loss.

	TESTING: 993.2468872070312 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3008305 1.2654784 1.2534786 1.2357411 1.2733495 1.3154067 1.2862388
 1.2625098 1.2850568 1.2753406 1.2868421 1.2905926 1.2873964 1.2842474
 1.2849146 1.28471   1.2845267 1.2851212 1.2849716 1.2847649 1.2847836
 1.2848947 1.2848407 1.2848258 1.2848773 1.2848169 1.2848266 1.2848426
 1.2848377 1.284834  1.2848393 1.2848378 1.2848339 1.2848383 1.2848374
 1.2848362 1.2848371 1.284837  1.2848368 1.2848369 1.2848371 1.284837
 1.2848371 1.2848371 1.2848369 1.2848371 1.2848369 1.2848369]


TIME OF ONE EPOCH: 73.04243063926697 seconds and 1.2173738439877828 minutes
Epoch 8
	TRAINING: 214.04295086860657 total train Value loss.

	TESTING: 973.1829223632812 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2974412 1.2703058 1.2582109 1.2420245 1.276126  1.313456  1.2871852
 1.2648953 1.2862914 1.2767922 1.287381  1.2906364 1.2873495 1.2845801
 1.2853134 1.2851822 1.284936  1.2855129 1.2853521 1.2851439 1.2851815
 1.285284  1.285225  1.2852142 1.2852646 1.2852069 1.2852166 1.2852329
 1.2852267 1.2852234 1.2852286 1.2852272 1.2852234 1.2852277 1.285227
 1.2852257 1.2852268 1.2852265 1.285226  1.2852262 1.2852265 1.2852261
 1.2852263 1.2852265 1.2852261 1.2852262 1.2852262 1.2852265]


TIME OF ONE EPOCH: 73.2943947315216 seconds and 1.22157324552536 minutes
Epoch 9
	TRAINING: 191.2626223564148 total train Value loss.

	TESTING: 967.703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2938292 1.2734032 1.2618203 1.2474813 1.2789224 1.3115842 1.2880639
 1.2675141 1.2875651 1.2788085 1.2881837 1.2910279 1.2877554 1.2853557
 1.2861618 1.2860699 1.285776  1.286302  1.2861395 1.2859452 1.2859986
 1.286092  1.2860297 1.2860203 1.2860674 1.2860155 1.286025  1.2860414
 1.2860339 1.2860305 1.2860358 1.2860341 1.2860309 1.286035  1.2860341
 1.286033  1.286034  1.2860337 1.2860334 1.2860336 1.2860337 1.2860335
 1.2860339 1.2860336 1.2860337 1.2860337 1.2860337 1.2860337]


TIME OF ONE EPOCH: 73.28725218772888 seconds and 1.2214542031288147 minutes
Epoch 10
	TRAINING: 157.81478387117386 total train Value loss.

	TESTING: 949.2734375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.28893   1.2745057 1.2625952 1.2502942 1.2778839 1.3066441 1.2853649
 1.2661024 1.2848982 1.276811  1.2851568 1.2876029 1.2843862 1.2822597
 1.283094  1.2830528 1.2827239 1.2832062 1.2830458 1.2828637 1.2829258
 1.2830136 1.2829503 1.2829406 1.2829852 1.2829381 1.2829472 1.2829633
 1.282955  1.2829515 1.2829568 1.2829554 1.2829525 1.2829561 1.2829554
 1.2829542 1.2829555 1.2829553 1.2829547 1.2829552 1.2829549 1.282955
 1.282955  1.2829554 1.2829552 1.282955  1.2829552 1.2829553]


TIME OF ONE EPOCH: 72.59290742874146 seconds and 1.2098817904790242 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 863.9754923125844 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 728.0277483463287 seconds OR 12.133795805772145 minutes

End of run




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 336, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 15974 train samples and 78 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 12)
  (Dcell): RNNCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 160466.01844024658 total train Value loss.

	TESTING: 3595.60888671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.051984   0.83596635 1.2008411  0.76960105 1.2319068  0.8169038
 1.2275963  0.878952   1.2078314  0.9103915  1.1750791  0.9884603
 1.1372132  1.0224061  1.1175741  1.0631584  1.0907379  1.0864474
 1.0824839  1.0976503  1.0739666  1.1058482  1.0726041  1.1050092
 1.0747547  1.1039041  1.0771015  1.1005583  1.0813813  1.0970507
 1.0844389  1.094383   1.0872803  1.0919119  1.0892936  1.0905043
 1.0904558  1.0895647  1.0911899  1.0891542  1.0913717  1.0891168
 1.0913467  1.0892261  1.0911583  1.0894718  1.0909084  1.0897101 ]


TIME OF ONE EPOCH: 61.41622614860535 seconds and 1.0236037691434225 minutes
Epoch 2
	TRAINING: 6774.540641784668 total train Value loss.

	TESTING: 3480.478515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0291579  0.9003879  1.1296895  0.90076    1.1507965  0.96057314
 1.1577513  1.007918   1.1683435  1.0259528  1.1561217  1.0699451
 1.1463007  1.0820729  1.141669   1.1016796  1.1316521  1.1107938
 1.1299845  1.1164048  1.1257837  1.1211587  1.1245719  1.1224003
 1.1238108  1.1239074  1.123207   1.1241928  1.1233584  1.1243391
 1.1232797  1.1243829  1.1234553  1.1242461  1.1235662  1.1241984
 1.1236606  1.1240975  1.1237602  1.1240389  1.1238096  1.1239945
 1.1238581  1.1239587  1.1238836  1.1239418  1.1239004  1.1239275 ]


TIME OF ONE EPOCH: 62.949342250823975 seconds and 1.0491557041803996 minutes
Epoch 3
	TRAINING: 3919.934814453125 total train Value loss.

	TESTING: 3276.2705078125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0315832 0.9380251 1.102503  0.9640646 1.1254722 1.0207967 1.1306679
 1.0608267 1.1496973 1.0737424 1.1437793 1.104329  1.1428763 1.1094385
 1.142941  1.1217709 1.1382892 1.1261634 1.1389402 1.1293434 1.1366805
 1.1321585 1.136386  1.1328816 1.1358713 1.1340396 1.135425  1.1343523
 1.1353798 1.1346661 1.1351602 1.134852  1.1351434 1.1349103 1.1350874
 1.1349915 1.1350632 1.1350052 1.135059  1.1350278 1.1350452 1.1350359
 1.135047  1.1350387 1.1350435 1.1350428 1.1350433 1.1350424]


TIME OF ONE EPOCH: 61.71619987487793 seconds and 1.0286033312479654 minutes
Epoch 4
	TRAINING: 2759.8866291046143 total train Value loss.

	TESTING: 3099.05810546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0389894  0.96226686 1.0948431  1.0045395  1.1209381  1.0548223
 1.1249329  1.0899985  1.1459364  1.0999244  1.1426669  1.123488
 1.144816   1.125904   1.146472   1.1348312  1.1439452  1.1373435
 1.1453521  1.1394064  1.1439735  1.1412905  1.1440974  1.141665
 1.1438226  1.1425036  1.1435679  1.142688   1.1435702  1.142932
 1.1434057  1.1430725  1.1433983  1.1431264  1.1433445  1.1431993
 1.1433208  1.1432171  1.1433097  1.1432433  1.1432934  1.1432544
 1.1432902  1.1432614  1.1432836  1.1432678  1.1432815  1.1432695 ]


TIME OF ONE EPOCH: 62.039591789245605 seconds and 1.0339931964874267 minutes
Epoch 5
	TRAINING: 2043.08060836792 total train Value loss.

	TESTING: 2950.00390625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0456941  0.97783995 1.0942391  1.032443   1.1216483  1.0762051
 1.1255925  1.1075622  1.1459787  1.1155807  1.144221   1.1344895
 1.1473461  1.1357521  1.149495   1.1426092  1.1479665  1.1442366
 1.1495234  1.1456863  1.1485981  1.1470566  1.1488676  1.1472485
 1.1487238  1.1478775  1.1485726  1.1479801  1.1486093  1.1481605
 1.1484908  1.1482596  1.1484982  1.1482953  1.1484591  1.1483513
 1.1484438  1.1483623  1.1484364  1.148383   1.1484238  1.1483915
 1.1484218  1.1483971  1.148416   1.1484022  1.1484143  1.1484038 ]


TIME OF ONE EPOCH: 62.70436644554138 seconds and 1.0450727740923564 minutes
Epoch 6
	TRAINING: 1562.4138355255127 total train Value loss.

	TESTING: 2838.095458984375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0530325 0.9898697 1.0970806 1.0532168 1.1238607 1.0910451 1.1282245
 1.118941  1.146897  1.1256878 1.1460907 1.1410874 1.149419  1.1418289
 1.1515948 1.1472558 1.150618  1.1483935 1.1520925 1.149474  1.1514299
 1.1505163 1.151734  1.1506153 1.1516551 1.1511021 1.1515607 1.1511592
 1.1516095 1.1512948 1.1515216 1.1513661 1.1515361 1.1513897 1.1515073
 1.1514326 1.1514976 1.1514388 1.1514933 1.1514546 1.1514839 1.1514605
 1.1514832 1.1514642 1.1514788 1.1514684 1.1514778 1.1514695]


TIME OF ONE EPOCH: 61.836749792099 seconds and 1.0306124965349832 minutes
Epoch 7
	TRAINING: 1225.637315750122 total train Value loss.

	TESTING: 2753.13623046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0606256  0.99965286 1.1005293  1.0681062  1.1252884  1.1007146
 1.1300412  1.1253843  1.1466455  1.1312041  1.1464148  1.1438793
 1.1496367  1.1443672  1.1516514  1.1487634  1.1510041  1.1495978
 1.1523272  1.1504428  1.1518251  1.1512611  1.1521239  1.1513113
 1.1520765  1.1517006  1.1520141  1.1517313  1.1520655  1.1518375
 1.1519967  1.1518908  1.1520144  1.151906   1.1519922  1.1519397
 1.1519864  1.151943   1.1519836  1.1519554  1.1519761  1.1519594
 1.1519765  1.1519625  1.151973   1.1519654  1.151972   1.1519663 ]


TIME OF ONE EPOCH: 62.94622731208801 seconds and 1.0491037885348002 minutes
Epoch 8
	TRAINING: 986.7684860229492 total train Value loss.

	TESTING: 2690.496826171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0677917 1.0074418 1.1028773 1.0777779 1.1249018 1.1058373 1.1297576
 1.1275746 1.1443197 1.1326262 1.1444008 1.1431849 1.1473795 1.1435248
 1.1491816 1.1471565 1.1487288 1.1477901 1.1498954 1.148472  1.1494948
 1.1491337 1.1497731 1.1491549 1.1497413 1.149475  1.1496979 1.1494893
 1.1497474 1.1495757 1.1496913 1.1496162 1.1497098 1.1496265 1.1496917
 1.1496542 1.1496882 1.1496553 1.1496866 1.1496655 1.149681  1.1496681
 1.1496816 1.1496704 1.1496783 1.149673  1.1496779 1.1496735]


TIME OF ONE EPOCH: 62.24497413635254 seconds and 1.0374162356058756 minutes
Epoch 9
	TRAINING: 815.9978547096252 total train Value loss.

	TESTING: 2643.31689453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0739658 1.0133739 1.1035751 1.0831708 1.1225921 1.10733   1.1272868
 1.1264397 1.1399884 1.1308272 1.1402096 1.1397204 1.1429027 1.139957
 1.1444879 1.143004  1.144151  1.1434962 1.1451751 1.1440574 1.1448413
 1.1446042 1.145095  1.1446064 1.145072  1.1448761 1.1450391 1.14488
 1.1450859 1.1449512 1.1450381 1.1449834 1.1450566 1.1449904 1.1450413
 1.1450137 1.1450392 1.1450133 1.1450384 1.145022  1.1450332 1.1450238
 1.1450341 1.1450255 1.1450316 1.1450276 1.1450316 1.1450279]


TIME OF ONE EPOCH: 62.01557660102844 seconds and 1.033592943350474 minutes
Epoch 10
	TRAINING: 690.3034405708313 total train Value loss.

	TESTING: 2607.036865234375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.078827  1.0175285 1.1026205 1.0852143 1.1186199 1.1060634 1.1229601
 1.1228234 1.134014  1.1266279 1.1342555 1.1341772 1.1366576 1.1343267
 1.1380334 1.1369107 1.1377652 1.1372933 1.1386623 1.1377596 1.1383734
 1.1382178 1.1386018 1.138206  1.1385831 1.1384364 1.1385559 1.1384326
 1.1386    1.1384923 1.138558  1.1385181 1.1385763 1.1385221 1.138563
 1.1385422 1.1385611 1.1385407 1.1385614 1.1385483 1.1385566 1.1385496
 1.1385577 1.138551  1.1385558 1.1385525 1.1385554 1.1385525]


TIME OF ONE EPOCH: 62.65054774284363 seconds and 1.0441757957140605 minutes
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
	ACTUAL ACC. RESULTS: MAE, MAPE: 711.0213887467344 and inf%

TIME ELAPSED: 625.413215637207 seconds OR 10.42355359395345 minutes

End of run




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 336, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 15974 train samples and 78 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 24)
  (Dcell): RNNCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 81934.21383666992 total train Value loss.

	TESTING: 2457.08154296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8821467  0.7020733  0.84891576 0.55171984 0.60329527 0.6424996
 0.64089084 0.61515677 0.60304767 0.6097011  0.64658374 0.6424745
 0.61578405 0.608894   0.62496483 0.623852   0.62167025 0.61620027
 0.6183842  0.6229578  0.6231139  0.6189417  0.6190954  0.62055486
 0.6215504  0.6206076  0.6198446  0.6200034  0.6208849  0.6207579
 0.6203039  0.62017244 0.62047756 0.6206057  0.6205031  0.62032723
 0.6203875  0.62049747 0.62050396 0.62042075 0.62040496 0.62044275
 0.62047476 0.6204521  0.6204283  0.62043333 0.6204536  0.62045354]


TIME OF ONE EPOCH: 85.31821274757385 seconds and 1.4219702124595641 minutes
Epoch 2
	TRAINING: 3160.417999267578 total train Value loss.

	TESTING: 2038.3021240234375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9769746  0.82225966 0.8527848  0.59075683 0.66619825 0.71637
 0.7085268  0.6775349  0.66778105 0.68844914 0.7168151  0.7053914
 0.6791737  0.6796293  0.694239   0.69353986 0.6868154  0.68341213
 0.6877583  0.69207376 0.68987393 0.68609136 0.68688244 0.6891725
 0.6894603  0.6880021  0.6873728  0.6881948  0.6889166  0.68848675
 0.6879116  0.68803185 0.6884481  0.68848777 0.6882227  0.68811166
 0.68826914 0.6883853  0.6883105  0.6882113  0.6882342  0.6883073
 0.6883131  0.68826455 0.6882473  0.68827546 0.68829507 0.68828124]


TIME OF ONE EPOCH: 87.32409334182739 seconds and 1.4554015556971232 minutes
Epoch 3
	TRAINING: 1667.4450407028198 total train Value loss.

	TESTING: 1849.627197265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0173737  0.866043   0.8653914  0.6349844  0.71259177 0.75984967
 0.7528392  0.7199317  0.71368086 0.7387248  0.75888216 0.74521303
 0.72400403 0.7276088  0.7398474  0.7382697  0.7311162  0.72957206
 0.73420835 0.7371224  0.73432267 0.731531   0.7327516  0.7347344
 0.7345066  0.7331505  0.73291945 0.7337991  0.7342057  0.7336894
 0.7332864  0.7335253  0.7338549  0.73378754 0.7335479  0.7335274
 0.7336863  0.73374104 0.7336477  0.73358643 0.7336327  0.73368645
 0.7336699  0.733629   0.73362935 0.7336571  0.7336644  0.73364747]


TIME OF ONE EPOCH: 87.82281470298767 seconds and 1.4637135783831279 minutes
Epoch 4
	TRAINING: 1092.1985034942627 total train Value loss.

	TESTING: 1719.5750732421875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0282992  0.8861962  0.8739612  0.67359114 0.7451667  0.7846056
 0.78053874 0.75021267 0.7458389  0.7696342  0.78402364 0.7713297
 0.75505316 0.7592681  0.7686988  0.767012   0.76104635 0.7604679
 0.76430357 0.7661459  0.7637125  0.76184404 0.7629602  0.76437575
 0.7640282  0.7630397  0.76300174 0.7636685  0.7638672  0.76346105
 0.7632265  0.76343495 0.76364076 0.76355946 0.7634025  0.7634154
 0.7635241  0.7635424  0.7634749  0.76344556 0.7634825  0.7635115
 0.76349455 0.763471   0.76347595 0.7634931  0.763494   0.76348305]


TIME OF ONE EPOCH: 87.89640688896179 seconds and 1.46494011481603 minutes
Epoch 5
	TRAINING: 797.9997878074646 total train Value loss.

	TESTING: 1624.0184326171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0358524  0.9076916  0.88837737 0.7130668  0.776775   0.80879694
 0.80819136 0.7818974  0.77807695 0.79896075 0.809664   0.7991586
 0.7865179  0.7902652  0.7973862  0.79609305 0.7914715  0.7912425
 0.7941183  0.79535663 0.7935122  0.7922527  0.7930836  0.794054
 0.7937723  0.7931053  0.79311144 0.79355985 0.79366684 0.7933945
 0.7932568  0.7933979  0.79352075 0.79346305 0.79336894 0.7933829
 0.7934475  0.7934544  0.7934141  0.79339963 0.7934221  0.7934369
 0.7934265  0.7934141  0.7934176  0.7934268  0.7934265  0.7934208 ]


TIME OF ONE EPOCH: 86.18845009803772 seconds and 1.4364741683006286 minutes
Epoch 6
	TRAINING: 610.5593645572662 total train Value loss.

	TESTING: 1537.537841796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0403404  0.9265343  0.9030062  0.747903   0.8036052  0.829253
 0.8314777  0.80929685 0.8054466  0.8232479  0.83149594 0.82329
 0.813239   0.8162733  0.82165915 0.8208328  0.8173211  0.81719375
 0.81927246 0.82016903 0.81884015 0.8179652  0.81853443 0.8192026
 0.8190132  0.818571   0.8185747  0.81886566 0.8189323  0.81875986
 0.8186744  0.81876147 0.8188365  0.8188017  0.8187462  0.8187544
 0.8187916  0.81879514 0.8187725  0.8187645  0.81877714 0.81878513
 0.81877935 0.81877285 0.8187749  0.81877947 0.81877935 0.8187764 ]


TIME OF ONE EPOCH: 88.41036486625671 seconds and 1.4735060811042786 minutes
Epoch 7
	TRAINING: 486.20728945732117 total train Value loss.

	TESTING: 1460.9676513671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0432477  0.9422533  0.9174438  0.77902347 0.82758784 0.8478874
 0.8521949  0.8337772  0.82978487 0.8448599  0.8513201  0.84510094
 0.83695894 0.8393488  0.84343237 0.84298694 0.84032536 0.8402299
 0.8417147  0.8423924  0.84144986 0.84082836 0.8412065  0.8416715
 0.8415539  0.8412599  0.841256   0.84144306 0.84148896 0.8413812
 0.8413263  0.84137857 0.84142506 0.8414053  0.84137225 0.8413762
 0.84139764 0.84140027 0.8413874  0.8413827  0.8413894  0.841394
 0.8413912  0.8413875  0.8413884  0.84139085 0.84139067 0.84138924]


TIME OF ONE EPOCH: 88.74754858016968 seconds and 1.4791258096694946 minutes
Epoch 8
	TRAINING: 399.4964644908905 total train Value loss.

	TESTING: 1390.6297607421875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0455176  0.95543534 0.9307486  0.80647063 0.8489602  0.8648627
 0.8705575  0.8553355  0.8512153  0.8640485  0.8691642  0.8645342
 0.8578255  0.8597087  0.8628279  0.862651   0.86061573 0.8605341
 0.86160016 0.86212695 0.86145663 0.8610051  0.86125505 0.86158466
 0.86151457 0.86131614 0.86130744 0.861429   0.86146206 0.86139446
 0.8613578  0.86138904 0.8614185  0.8614075  0.86138767 0.86138934
 0.8614018  0.8614037  0.8613965  0.8613937  0.86139715 0.8613999
 0.8613983  0.86139625 0.8613968  0.8613981  0.8613982  0.8613973 ]


TIME OF ONE EPOCH: 86.92112588882446 seconds and 1.4486854314804076 minutes
Epoch 9
	TRAINING: 335.89693331718445 total train Value loss.

	TESTING: 1330.22509765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0490721  0.9682084  0.9440603  0.83207315 0.86939263 0.88173527
 0.88833016 0.87574947 0.8715598  0.8825485  0.88663423 0.8832479
 0.8776586  0.8791528  0.88154745 0.8815502  0.8799784  0.8799061
 0.88067776 0.8810943  0.88061535 0.88028157 0.88044715 0.88068396
 0.8806436  0.8805079  0.8804971  0.8805775  0.88060206 0.88055855
 0.8805337  0.8805524  0.8805719  0.88056594 0.88055325 0.88055366
 0.88056123 0.8805626  0.8805586  0.88055676 0.88055843 0.88056016
 0.8805596  0.8805585  0.8805585  0.88055915 0.88055944 0.88055897]


TIME OF ONE EPOCH: 86.64287662506104 seconds and 1.4440479437510172 minutes
Epoch 10
	TRAINING: 288.0492626428604 total train Value loss.

	TESTING: 1283.62841796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0560135  0.98317325 0.95955354 0.85829437 0.8912053  0.9007128
 0.9078545  0.897455   0.8932769  0.90275055 0.90604323 0.9036262
 0.8989276  0.9001208  0.9019622  0.90208095 0.90085644 0.90079236
 0.9013553  0.9016892  0.9013457  0.90109533 0.9012046  0.9013769
 0.901355   0.9012611  0.90124995 0.9013033  0.90132207 0.9012941
 0.9012768  0.9012881  0.901301   0.9012979  0.9012901  0.90129
 0.90129435 0.90129566 0.9012931  0.90129197 0.901293   0.9012939
 0.9012936  0.901293   0.9012931  0.90129364 0.90129364 0.90129334]


TIME OF ONE EPOCH: 88.94597291946411 seconds and 1.4824328819910686 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 833.594484247713 and inf%

TIME ELAPSED: 877.9169945716858 seconds OR 14.631949909528096 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'rnn', 'attention_model': ['BA'], 'window_source_size': 336, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 15974 train samples and 78 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): RNNCell(44, 48)
  (Dcell): RNNCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 21750.434118270874 total train Value loss.

	TESTING: 1018.497802734375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3561741 1.3896264 1.2807264 1.3863282 1.397679  1.4312464 1.3973454
 1.3727386 1.4205937 1.4142547 1.4132601 1.4195182 1.4105403 1.4065791
 1.414159  1.4099487 1.4131073 1.4112391 1.4115407 1.4121804 1.4112868
 1.4130136 1.4114287 1.4121304 1.4116759 1.4116179 1.4120699 1.4117157
 1.4120926 1.4118006 1.4118727 1.4118526 1.4118212 1.4119058 1.4118552
 1.4118997 1.4118575 1.41187   1.4118642 1.4118655 1.411875  1.4118685
 1.4118736 1.4118661 1.41187   1.411868  1.4118698 1.4118705]


TIME OF ONE EPOCH: 134.78343653678894 seconds and 2.2463906089464825 minutes
Epoch 2
	TRAINING: 1047.7345280647278 total train Value loss.

	TESTING: 964.046630859375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3384598 1.3775723 1.31975   1.3811504 1.3679156 1.4214995 1.3817751
 1.3679401 1.408505  1.3974353 1.405368  1.403239  1.3981164 1.3952729
 1.399666  1.3994527 1.3996745 1.3998933 1.3990982 1.3996471 1.3992944
 1.399912  1.3994893 1.399528  1.3994836 1.3993651 1.3995743 1.3994536
 1.3995848 1.3995    1.3994995 1.3995087 1.399481  1.3995209 1.3995012
 1.399518  1.3995055 1.3995056 1.3995072 1.3995037 1.3995097 1.3995063
 1.3995086 1.3995064 1.3995067 1.399507  1.3995072 1.3995076]


TIME OF ONE EPOCH: 135.95405983924866 seconds and 2.265900997320811 minutes
Epoch 3
	TRAINING: 569.5934402942657 total train Value loss.

	TESTING: 975.6712646484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.342421  1.3683524 1.3382958 1.3738251 1.3548797 1.404247  1.3621877
 1.3566505 1.392349  1.380461  1.3900626 1.3856921 1.3820982 1.3801342
 1.3836994 1.3842828 1.3836867 1.384311  1.3832496 1.3837878 1.3836478
 1.3839457 1.3838252 1.3837065 1.383744  1.3836253 1.3837643 1.3837099
 1.3837705 1.3837422 1.383724  1.3837382 1.3837167 1.383741  1.3837322
 1.3837391 1.3837351 1.3837322 1.3837345 1.3837317 1.3837354 1.3837341
 1.3837347 1.3837341 1.3837337 1.3837341 1.3837339 1.3837342]


TIME OF ONE EPOCH: 136.24990797042847 seconds and 2.270831799507141 minutes
Epoch 4
	TRAINING: 389.39847898483276 total train Value loss.

	TESTING: 956.0790405273438 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3517615 1.3697493 1.3534392 1.3758798 1.356649  1.3959326 1.3542395
 1.3549123 1.387006  1.3752533 1.3847729 1.3798959 1.3767377 1.3755518
 1.3786529 1.3793683 1.3785734 1.3792058 1.3781478 1.3786255 1.3785911
 1.37877   1.3787444 1.3785934 1.3786447 1.3785399 1.3786427 1.3786174
 1.3786498 1.3786405 1.3786197 1.3786325 1.3786166 1.3786325 1.3786286
 1.3786314 1.3786298 1.3786271 1.378629  1.3786273 1.3786294 1.378629
 1.3786291 1.3786287 1.3786284 1.3786288 1.3786286 1.378629 ]


TIME OF ONE EPOCH: 135.94857096672058 seconds and 2.2658095161120095 minutes
Epoch 5
	TRAINING: 302.44215071201324 total train Value loss.

	TESTING: 928.81640625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3525083 1.3655127 1.3558153 1.3715036 1.3528252 1.3838108 1.344057
 1.3486418 1.3776172 1.3662577 1.3751674 1.3701898 1.3673425 1.3667145
 1.369387  1.3701049 1.3692781 1.3698506 1.3688812 1.369292  1.3693104
 1.3694273 1.3694408 1.369291  1.3693421 1.3692527 1.3693311 1.3693203
 1.369339  1.3693371 1.3693177 1.3693283 1.3693163 1.3693278 1.3693255
 1.3693271 1.3693267 1.369324  1.3693258 1.3693241 1.369326  1.3693254
 1.3693256 1.3693256 1.3693252 1.3693255 1.3693252 1.3693256]


TIME OF ONE EPOCH: 134.83621430397034 seconds and 2.247270238399506 minutes
Epoch 6
	TRAINING: 253.33978259563446 total train Value loss.

	TESTING: 920.291015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3532315 1.3641034 1.3585052 1.3694496 1.3513877 1.3758866 1.3390809
 1.3456148 1.3718286 1.3612788 1.3693743 1.3646591 1.3619908 1.3618035
 1.3640612 1.3647324 1.3639799 1.3644462 1.3636019 1.363939  1.363984
 1.3640647 1.3640937 1.3639607 1.3640025 1.3639312 1.36399   1.3639867
 1.3639984 1.3639992 1.3639829 1.3639911 1.3639821 1.3639903 1.3639896
 1.3639901 1.36399   1.3639883 1.3639891 1.3639885 1.3639896 1.3639894
 1.3639892 1.3639894 1.3639891 1.3639891 1.3639891 1.3639891]


TIME OF ONE EPOCH: 135.78004026412964 seconds and 2.2630006710688275 minutes
Epoch 7
	TRAINING: 213.04687774181366 total train Value loss.

	TESTING: 915.4905395507812 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3574386 1.3672291 1.3628434 1.3710247 1.3535217 1.373419  1.3394859
 1.3471439 1.370906  1.3611231 1.3686222 1.3641452 1.3616707 1.3617717
 1.3636707 1.3642946 1.3636179 1.3640083 1.363268  1.3635522 1.3636063
 1.363663  1.3636992 1.3635811 1.3636174 1.3635584 1.3636048 1.3636054
 1.3636128 1.3636149 1.3636011 1.3636074 1.3636004 1.3636067 1.3636067
 1.3636068 1.3636067 1.3636054 1.363606  1.3636054 1.3636063 1.3636061
 1.3636062 1.363606  1.3636059 1.3636061 1.3636059 1.3636062]


TIME OF ONE EPOCH: 135.33617758750916 seconds and 2.2556029597918195 minutes
Epoch 8
	TRAINING: 213.47617065906525 total train Value loss.

	TESTING: 927.7590942382812 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3536673 1.3604013 1.3571063 1.3645513 1.3469815 1.3636342 1.3319583
 1.3402843 1.3619877 1.3530439 1.360058  1.3557299 1.3534732 1.353757
 1.3553549 1.35595   1.3553485 1.3556689 1.3550166 1.355258  1.3553131
 1.3553551 1.3553952 1.3552907 1.3553208 1.3552718 1.3553092 1.3553118
 1.3553166 1.3553195 1.3553078 1.3553125 1.3553075 1.3553127 1.3553126
 1.3553123 1.3553122 1.3553112 1.3553118 1.3553112 1.3553115 1.3553118
 1.3553119 1.3553116 1.3553115 1.3553118 1.3553118 1.3553118]


TIME OF ONE EPOCH: 135.16641473770142 seconds and 2.25277357896169 minutes
Epoch 9
	TRAINING: 179.58774387836456 total train Value loss.

	TESTING: 912.20166015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3545241 1.3611895 1.3576664 1.3634843 1.3461345 1.3601815 1.330947
 1.339457  1.3593155 1.3511064 1.3576496 1.3535358 1.351466  1.3518835
 1.3532238 1.3537863 1.353244  1.3535113 1.3529359 1.3531451 1.3531986
 1.3532298 1.3532709 1.3531767 1.3532037 1.353162  1.3531924 1.3531969
 1.3531997 1.3532025 1.3531922 1.3531966 1.3531922 1.353196  1.353196
 1.3531964 1.3531965 1.3531953 1.3531958 1.3531953 1.3531957 1.3531957
 1.3531955 1.3531955 1.3531954 1.3531955 1.3531957 1.3531957]


TIME OF ONE EPOCH: 136.04184556007385 seconds and 2.2673640926678975 minutes
Epoch 10
	TRAINING: 162.0292323231697 total train Value loss.

	TESTING: 890.9697265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3569124 1.3634077 1.359744  1.3645611 1.3477266 1.3596468 1.332682
 1.341064  1.3592559 1.3517425 1.3578385 1.3539363 1.3520453 1.3525555
 1.3536705 1.3542013 1.353715  1.3539356 1.3534317 1.353614  1.3536644
 1.3536872 1.353727  1.3536426 1.3536665 1.3536316 1.3536568 1.3536612
 1.3536631 1.3536661 1.3536574 1.3536607 1.353657  1.3536603 1.3536607
 1.3536603 1.3536607 1.3536596 1.3536601 1.3536597 1.3536599 1.3536602
 1.35366   1.3536602 1.3536602 1.35366   1.35366   1.35366  ]


TIME OF ONE EPOCH: 135.14691591262817 seconds and 2.2524485985438027 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 835.48942282261 and inf%

TIME ELAPSED: 1357.5195581912994 seconds OR 22.62532596985499 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 48, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16262 train samples and 84 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 12)
  (Dcell): GRUCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 145101.93762922287 total train Value loss.

	TESTING: 1470.2427978515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.52698296 0.7355512  0.85504663 0.935148   0.98810464 1.0223417
 1.0442159  1.0581459  1.0670321  1.0727232  1.0763838  1.0787475
 1.080278   1.0812715  1.0819173  1.0823371  1.0826105  1.0827883
 1.0829041  1.0829794  1.0830284  1.0830601  1.0830808  1.0830944
 1.0831031  1.0831088  1.0831124  1.0831147  1.0831164  1.0831175
 1.0831181  1.0831186  1.0831189  1.0831189  1.083119   1.083119
 1.0831192  1.0831192  1.0831192  1.0831192  1.0831192  1.0831192
 1.0831192  1.0831192  1.0831192  1.0831192  1.0831192  1.0831192 ]


TIME OF ONE EPOCH: 26.90824604034424 seconds and 0.44847076733907065 minutes
Epoch 2
	TRAINING: 7268.95286488533 total train Value loss.

	TESTING: 936.1416015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.72037095 0.9149517  1.0105397  1.0694233  1.1049418  1.1258997
 1.1382214  1.1455127  1.1498684  1.1524937  1.1540867  1.1550577
 1.1556511  1.1560143  1.1562365  1.1563725  1.1564558  1.1565067
 1.1565377  1.1565564  1.156568   1.1565752  1.1565794  1.1565818
 1.1565833  1.1565843  1.156585   1.1565853  1.1565855  1.1565856
 1.1565857  1.1565857  1.1565858  1.1565858  1.1565858  1.1565858
 1.1565858  1.1565858  1.1565858  1.1565858  1.1565858  1.1565858
 1.1565858  1.1565858  1.1565858  1.1565858  1.1565858  1.1565858 ]


TIME OF ONE EPOCH: 23.05764102935791 seconds and 0.3842940171559652 minutes
Epoch 3
	TRAINING: 3589.8810678720474 total train Value loss.

	TESTING: 728.3126220703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.88459986 1.0432559  1.1156497  1.1590599  1.1835091  1.1967868
 1.203966   1.2078857  1.2100533  1.2112651  1.2119483  1.2123352
 1.2125555  1.2126812  1.2127529  1.212794   1.2128174  1.2128307
 1.2128383  1.2128428  1.2128454  1.2128468  1.2128475  1.212848
 1.2128481  1.2128483  1.2128484  1.2128483  1.2128484  1.2128485
 1.2128485  1.2128485  1.2128485  1.2128485  1.2128485  1.2128485
 1.2128485  1.2128485  1.2128485  1.2128485  1.2128485  1.2128485
 1.2128485  1.2128485  1.2128485  1.2128485  1.2128485  1.2128485 ]


TIME OF ONE EPOCH: 22.333757638931274 seconds and 0.3722292939821879 minutes
Epoch 4
	TRAINING: 2129.4963079690933 total train Value loss.

	TESTING: 611.5807495117188 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9989534 1.1270444 1.1875033 1.2238035 1.2429774 1.2523987 1.2568475
 1.2588754 1.2597535 1.2601001 1.2602112 1.2602261 1.2602074 1.2601815
 1.2601588 1.2601414 1.260129  1.2601207 1.2601154 1.260112  1.2601098
 1.2601085 1.2601079 1.2601074 1.2601072 1.2601069 1.2601068 1.2601067
 1.2601068 1.2601067 1.2601068 1.2601068 1.2601067 1.2601067 1.2601067
 1.2601067 1.2601067 1.2601067 1.2601067 1.2601067 1.2601067 1.2601067
 1.2601067 1.2601067 1.2601067 1.2601067 1.2601067 1.2601067]


TIME OF ONE EPOCH: 22.220547914505005 seconds and 0.3703424652417501 minutes
Epoch 5
	TRAINING: 1422.0542867779732 total train Value loss.

	TESTING: 535.3300170898438 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.079532  1.1864144 1.2408578 1.2736887 1.290081  1.2973046 1.3000696
 1.300838  1.3007958 1.3004845 1.3001351 1.2998338 1.2996014 1.2994341
 1.299318  1.2992402 1.2991891 1.2991561 1.2991352 1.299122  1.2991139
 1.2991087 1.2991056 1.2991039 1.2991029 1.2991022 1.2991018 1.2991015
 1.2991014 1.2991012 1.2991011 1.2991011 1.2991011 1.2991011 1.2991011
 1.2991011 1.2991011 1.2991011 1.2991011 1.2991011 1.2991011 1.2991011
 1.2991011 1.2991011 1.2991011 1.2991011 1.2991011 1.2991011]


TIME OF ONE EPOCH: 22.702352046966553 seconds and 0.3783725341161092 minutes
Epoch 6
	TRAINING: 1034.7704143226147 total train Value loss.

	TESTING: 483.6099548339844 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.13899   1.2318019 1.2823522 1.3129164 1.3275121 1.3333132 1.3349655
 1.3348749 1.3341815 1.3333869 1.3326854 1.3321321 1.331723  1.3314322
 1.3312316 1.3310962 1.3310064 1.3309474 1.3309095 1.3308847 1.3308691
 1.3308591 1.3308529 1.3308488 1.3308464 1.3308448 1.3308437 1.3308431
 1.3308429 1.3308426 1.3308425 1.3308424 1.3308421 1.3308424 1.3308424
 1.3308423 1.3308421 1.3308421 1.3308421 1.3308421 1.3308421 1.3308421
 1.3308421 1.3308421 1.3308421 1.3308421 1.3308421 1.3308421]


TIME OF ONE EPOCH: 21.77916717529297 seconds and 0.36298611958821614 minutes
Epoch 7
	TRAINING: 806.3660491704941 total train Value loss.

	TESTING: 447.28619384765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1835991 1.2665095 1.3136412 1.342183  1.3553277 1.360076  1.3609562
 1.360295  1.3591809 1.3580787 1.3571554 1.3564441 1.355923  1.3555541
 1.3552992 1.3551267 1.3550111 1.3549349 1.354885  1.3548524 1.3548315
 1.3548181 1.3548094 1.354804  1.3548005 1.3547983 1.3547968 1.3547957
 1.3547951 1.3547949 1.3547945 1.3547945 1.3547945 1.3547944 1.3547944
 1.3547943 1.3547943 1.3547943 1.3547943 1.3547943 1.3547943 1.3547943
 1.3547943 1.3547943 1.3547943 1.3547943 1.3547943 1.3547943]


TIME OF ONE EPOCH: 22.054397583007812 seconds and 0.3675732930501302 minutes
Epoch 8
	TRAINING: 651.7992179393768 total train Value loss.

	TESTING: 419.484619140625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2166119 1.2926109 1.3365893 1.3632312 1.3751271 1.3790668 1.3794237
 1.3784227 1.3770876 1.3758423 1.3748273 1.3740574 1.3734995 1.3731076
 1.3728385 1.3726568 1.372536  1.3724562 1.3724043 1.3723705 1.3723487
 1.3723348 1.3723259 1.37232   1.3723165 1.3723142 1.3723127 1.3723118
 1.3723114 1.372311  1.3723105 1.3723105 1.3723104 1.3723103 1.3723104
 1.3723103 1.3723104 1.3723103 1.3723104 1.3723103 1.3723103 1.3723103
 1.3723103 1.3723103 1.3723103 1.3723103 1.3723104 1.3723103]


TIME OF ONE EPOCH: 21.63779854774475 seconds and 0.36062997579574585 minutes
Epoch 9
	TRAINING: 539.3372696042061 total train Value loss.

	TESTING: 399.1849060058594 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2408752 1.3117131 1.352631  1.3773857 1.3881234 1.3913994 1.3914001
 1.3902237 1.3888152 1.3875513 1.3865446 1.3857936 1.3852571 1.3848852
 1.3846328 1.3844645 1.3843539 1.3842816 1.3842351 1.3842056 1.3841866
 1.3841743 1.384167  1.384162  1.3841591 1.3841572 1.384156  1.3841554
 1.3841549 1.3841546 1.3841546 1.3841543 1.3841543 1.3841543 1.3841543
 1.3841543 1.3841542 1.3841542 1.3841541 1.3841541 1.3841541 1.3841538
 1.3841541 1.3841541 1.3841541 1.3841538 1.3841541 1.3841538]


TIME OF ONE EPOCH: 21.32568049430847 seconds and 0.35542800823847454 minutes
Epoch 10
	TRAINING: 455.1038069874048 total train Value loss.

	TESTING: 387.2939758300781 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2606049 1.3281721 1.366325  1.3893327 1.399055  1.4018127 1.4015964
 1.400368  1.3989888 1.3977877 1.3968503 1.3961637 1.395681  1.3953513
 1.395131  1.3949863 1.3948926 1.3948325 1.3947943 1.3947701 1.3947555
 1.394746  1.39474   1.3947366 1.3947343 1.394733  1.3947321 1.3947316
 1.3947314 1.3947312 1.3947313 1.394731  1.3947312 1.3947309 1.3947309
 1.3947308 1.3947308 1.3947308 1.3947308 1.3947308 1.3947308 1.3947308
 1.3947308 1.3947308 1.3947308 1.3947308 1.3947308 1.3947308]


TIME OF ONE EPOCH: 22.25490427017212 seconds and 0.3709150711695353 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 944.2074826558431 and inf%

TIME ELAPSED: 226.76360487937927 seconds OR 3.779393414656321 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 48, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16262 train samples and 84 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 24)
  (Dcell): GRUCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 90639.38222575188 total train Value loss.

	TESTING: 521.538330078125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3067585 1.3350171 1.3747528 1.4045545 1.4254888 1.4396263 1.4489971
 1.4551656 1.4592241 1.4619012 1.4636744 1.4648535 1.4656414 1.4661692
 1.466524  1.4667631 1.4669249 1.4670341 1.4671078 1.4671583 1.4671919
 1.4672151 1.4672309 1.4672414 1.4672484 1.4672537 1.4672568 1.4672589
 1.467261  1.4672619 1.4672623 1.4672631 1.4672633 1.4672636 1.4672636
 1.4672638 1.4672638 1.4672638 1.4672639 1.4672638 1.467264  1.467264
 1.4672642 1.4672642 1.4672642 1.4672642 1.4672642 1.4672642]


TIME OF ONE EPOCH: 22.312406539916992 seconds and 0.37187344233194985 minutes
Epoch 2
	TRAINING: 2111.6856452822685 total train Value loss.

	TESTING: 459.9476318359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3975943 1.3924263 1.4174145 1.4377515 1.4523854 1.4622583 1.4687669
 1.473042  1.4758596 1.4777284 1.4789743 1.4798087 1.4803691 1.4807465
 1.4810007 1.4811722 1.4812876 1.4813656 1.4814178 1.4814531 1.4814765
 1.4814923 1.4815031 1.4815098 1.4815148 1.481518  1.48152   1.4815215
 1.4815227 1.4815233 1.4815235 1.4815239 1.4815243 1.4815243 1.4815245
 1.4815245 1.4815245 1.4815245 1.4815247 1.4815247 1.4815247 1.4815247
 1.4815251 1.481525  1.4815246 1.4815247 1.4815247 1.4815246]


TIME OF ONE EPOCH: 23.32975196838379 seconds and 0.38882919947306316 minutes
Epoch 3
	TRAINING: 1003.7235514521599 total train Value loss.

	TESTING: 400.1278991699219 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.421631  1.4035097 1.4239928 1.4422793 1.4559964 1.4654375 1.4717343
 1.4758993 1.4786566 1.4804871 1.4817061 1.4825197 1.4830629 1.4834262
 1.4836686 1.4838303 1.4839385 1.4840103 1.484058  1.4840902 1.4841108
 1.4841253 1.4841344 1.4841406 1.4841448 1.4841474 1.4841495 1.4841506
 1.4841512 1.484152  1.4841522 1.4841526 1.4841527 1.4841527 1.4841527
 1.4841529 1.484153  1.4841529 1.4841529 1.4841528 1.4841528 1.4841529
 1.4841529 1.4841529 1.4841529 1.4841529 1.4841529 1.4841529]


TIME OF ONE EPOCH: 22.878286838531494 seconds and 0.3813047806421916 minutes
Epoch 4
	TRAINING: 614.2655370533466 total train Value loss.

	TESTING: 355.0406494140625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4297866 1.4052787 1.423923  1.442304  1.4567792 1.4670398 1.4740088
 1.4786619 1.4817486 1.4837914 1.4851414 1.4860333 1.4866217 1.4870096
 1.4872651 1.4874336 1.4875441 1.4876169 1.4876642 1.487696  1.4877162
 1.48773   1.487739  1.4877445 1.4877485 1.487751  1.4877528 1.4877539
 1.4877546 1.4877553 1.4877554 1.4877553 1.4877555 1.4877557 1.4877558
 1.4877558 1.4877559 1.4877559 1.487756  1.487756  1.487756  1.487756
 1.4877561 1.4877561 1.4877561 1.4877558 1.4877559 1.4877561]


TIME OF ONE EPOCH: 22.573321104049683 seconds and 0.37622201840082803 minutes
Epoch 5
	TRAINING: 437.4824827462435 total train Value loss.

	TESTING: 331.3533020019531 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4345717 1.4070885 1.4249052 1.4439954 1.4596184 1.470956  1.4787617
 1.4840046 1.4874831 1.4897748 1.4912785 1.4922622 1.4929045 1.4933228
 1.4935952 1.4937723 1.4938874 1.493962  1.4940109 1.4940419 1.4940625
 1.4940759 1.4940844 1.4940902 1.4940939 1.4940962 1.4940978 1.4940987
 1.4940995 1.4940999 1.4941002 1.4941006 1.4941007 1.4941008 1.4941009
 1.4941009 1.4941008 1.4941009 1.4941008 1.4941009 1.494101  1.4941008
 1.494101  1.4941008 1.4941008 1.4941008 1.4941008 1.4941008]


TIME OF ONE EPOCH: 22.48591446876526 seconds and 0.37476524114608767 minutes
Epoch 6
	TRAINING: 339.30912132561207 total train Value loss.

	TESTING: 312.2192077636719 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4386444 1.4102294 1.427551  1.4473224 1.4639277 1.476159  1.4846462
 1.4903604 1.4941447 1.4966266 1.4982439 1.4992937 1.4999729 1.5004117
 1.5006944 1.5008763 1.5009935 1.5010687 1.501117  1.5011482 1.5011681
 1.501181  1.5011891 1.5011946 1.5011979 1.5012003 1.5012016 1.5012023
 1.5012033 1.5012038 1.5012039 1.501204  1.5012041 1.5012041 1.5012043
 1.5012043 1.5012043 1.5012044 1.5012043 1.5012043 1.5012043 1.5012044
 1.5012043 1.5012043 1.5012043 1.5012043 1.5012043 1.5012043]


TIME OF ONE EPOCH: 23.109286785125732 seconds and 0.38515477975209556 minutes
Epoch 7
	TRAINING: 285.251006513834 total train Value loss.

	TESTING: 296.8822326660156 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.442608  1.4142177 1.4311423 1.45138   1.4686658 1.4815121 1.4904604
 1.4964861 1.5004665 1.5030649 1.504749  1.5058345 1.5065318 1.5069788
 1.5072644 1.5074464 1.507563  1.5076369 1.5076844 1.5077142 1.5077336
 1.5077455 1.5077531 1.5077583 1.5077615 1.5077636 1.5077647 1.5077658
 1.5077662 1.5077666 1.507767  1.5077667 1.5077668 1.5077672 1.5077671
 1.5077672 1.5077672 1.5077672 1.5077674 1.5077672 1.5077672 1.5077672
 1.5077672 1.5077672 1.5077672 1.5077672 1.5077672 1.5077672]


TIME OF ONE EPOCH: 23.22412133216858 seconds and 0.3870686888694763 minutes
Epoch 8
	TRAINING: 242.31352926790714 total train Value loss.

	TESTING: 282.0030517578125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4455494 1.4176993 1.4341935 1.4546256 1.4722711 1.4854515 1.4946454
 1.5008293 1.5049019 1.5075489 1.509256  1.5103495 1.511048  1.5114921
 1.5117743 1.5119536 1.5120662 1.5121381 1.5121833 1.5122116 1.5122298
 1.5122411 1.5122485 1.5122529 1.5122558 1.5122577 1.5122589 1.5122596
 1.51226   1.5122603 1.5122607 1.5122608 1.5122608 1.5122609 1.5122609
 1.5122607 1.5122609 1.512261  1.512261  1.512261  1.512261  1.512261
 1.512261  1.5122609 1.5122609 1.5122612 1.5122609 1.512261 ]


TIME OF ONE EPOCH: 23.77387285232544 seconds and 0.396231214205424 minutes
Epoch 9
	TRAINING: 203.6968602500856 total train Value loss.

	TESTING: 268.4228210449219 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4482794 1.4213806 1.4374133 1.4578345 1.4755986 1.4889016 1.4981802
 1.5044076 1.508495  1.5111412 1.5128386 1.5139208 1.5146079 1.5150424
 1.5153166 1.5154893 1.5155977 1.5156658 1.5157086 1.5157354 1.5157523
 1.5157629 1.5157695 1.5157735 1.5157763 1.5157777 1.5157785 1.5157793
 1.5157797 1.5157801 1.5157802 1.5157803 1.5157804 1.5157804 1.5157806
 1.5157806 1.5157804 1.5157804 1.5157804 1.5157806 1.5157807 1.5157806
 1.5157806 1.5157806 1.5157806 1.5157806 1.5157806 1.5157806]


TIME OF ONE EPOCH: 23.345533847808838 seconds and 0.389092230796814 minutes
Epoch 10
	TRAINING: 174.90765676274896 total train Value loss.

	TESTING: 259.590087890625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4518647 1.4260671 1.4415163 1.4617094 1.4793808 1.4926363 1.5018754
 1.508063  1.5121119 1.5147225 1.5163898 1.5174481 1.5181162 1.5185366
 1.5188004 1.5189657 1.5190688 1.519133  1.5191733 1.5191983 1.5192137
 1.5192233 1.5192294 1.5192331 1.5192355 1.5192367 1.5192378 1.5192384
 1.5192386 1.5192388 1.5192391 1.519239  1.519239  1.519239  1.5192393
 1.5192391 1.5192393 1.5192392 1.5192393 1.5192392 1.5192393 1.5192393
 1.5192393 1.5192393 1.5192393 1.5192393 1.5192393 1.5192393]


TIME OF ONE EPOCH: 23.127767086029053 seconds and 0.3854627847671509 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 973.7299074445452 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 230.63709688186646 seconds OR 3.843951614697774 minutes

End of run




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 48, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16262 train samples and 84 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 48)
  (Dcell): GRUCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 53146.33467710018 total train Value loss.

	TESTING: 214.9261474609375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.376254  1.6079865 1.6887437 1.716761  1.7256482 1.7284205 1.7296059
 1.730486  1.7312944 1.7320116 1.7326016 1.733056  1.7333884 1.7336222
 1.7337823 1.7338885 1.7339576 1.734002  1.7340302 1.7340475 1.7340583
 1.7340649 1.7340689 1.7340714 1.7340727 1.7340735 1.734074  1.7340744
 1.7340744 1.7340744 1.7340745 1.7340746 1.7340748 1.7340746 1.7340746
 1.7340746 1.7340746 1.7340747 1.7340745 1.7340745 1.7340745 1.7340746
 1.7340745 1.7340745 1.7340745 1.7340746 1.7340746 1.7340746]


TIME OF ONE EPOCH: 26.92569875717163 seconds and 0.4487616459528605 minutes
Epoch 2
	TRAINING: 1317.504790008068 total train Value loss.

	TESTING: 184.2301025390625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5233659 1.6702372 1.6918763 1.6876197 1.6802883 1.6754545 1.6732985
 1.6727986 1.6730709 1.6735909 1.6741102 1.6745374 1.6748568 1.6750817
 1.6752341 1.6753347 1.6753994 1.6754407 1.6754668 1.6754827 1.675493
 1.6754992 1.6755029 1.6755052 1.6755068 1.6755074 1.6755081 1.6755083
 1.6755087 1.6755086 1.6755087 1.6755089 1.675509  1.6755089 1.6755089
 1.675509  1.6755089 1.675509  1.675509  1.675509  1.675509  1.675509
 1.675509  1.675509  1.675509  1.675509  1.675509  1.6755087]


TIME OF ONE EPOCH: 29.944801568984985 seconds and 0.4990800261497498 minutes
Epoch 3
	TRAINING: 642.7161786258221 total train Value loss.

	TESTING: 160.27923583984375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5790682 1.6770552 1.6768132 1.6652789 1.6566924 1.6526259 1.6515868
 1.6519997 1.6528866 1.6537809 1.6545143 1.6550586 1.6554401 1.6556972
 1.6558661 1.6559752 1.6560447 1.6560886 1.6561161 1.656133  1.6561439
 1.6561503 1.6561548 1.6561574 1.6561589 1.6561602 1.6561607 1.6561611
 1.6561614 1.6561617 1.6561615 1.6561618 1.6561618 1.6561619 1.6561619
 1.6561619 1.6561619 1.6561619 1.656162  1.6561619 1.6561619 1.6561619
 1.656162  1.6561618 1.6561619 1.6561619 1.6561619 1.656162 ]


TIME OF ONE EPOCH: 31.89330267906189 seconds and 0.5315550446510315 minutes
Epoch 4
	TRAINING: 393.9565423130989 total train Value loss.

	TESTING: 149.80612182617188 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6057435 1.6726142 1.6621476 1.6491822 1.6419519 1.6396197 1.6399316
 1.6412237 1.6426327 1.6438218 1.644718  1.6453522 1.6457844 1.6460717
 1.6462591 1.6463805 1.6464585 1.6465076 1.6465392 1.6465592 1.646572
 1.6465801 1.6465852 1.6465887 1.6465911 1.6465924 1.6465935 1.6465935
 1.6465944 1.6465945 1.6465948 1.6465949 1.6465949 1.6465948 1.6465949
 1.6465948 1.6465951 1.6465951 1.6465952 1.6465949 1.6465949 1.646595
 1.646595  1.6465951 1.6465949 1.6465951 1.646595  1.6465951]


TIME OF ONE EPOCH: 29.495986938476562 seconds and 0.4915997823079427 minutes
Epoch 5
	TRAINING: 274.89934673160315 total train Value loss.

	TESTING: 130.92153930664062 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6146587 1.6609069 1.6451398 1.6323072 1.6265707 1.625628  1.6268853
 1.6287354 1.6304498 1.6318007 1.6327821 1.6334631 1.6339225 1.6342266
 1.6344262 1.6345556 1.6346399 1.6346936 1.6347287 1.6347511 1.6347659
 1.6347753 1.6347815 1.6347858 1.6347884 1.6347901 1.6347915 1.6347923
 1.6347929 1.6347933 1.6347933 1.6347935 1.6347939 1.6347939 1.6347939
 1.634794  1.634794  1.6347939 1.634794  1.6347936 1.6347936 1.6347939
 1.634794  1.634794  1.634794  1.634794  1.634794  1.6347941]


TIME OF ONE EPOCH: 30.64421319961548 seconds and 0.510736886660258 minutes
Epoch 6
	TRAINING: 196.03970530629158 total train Value loss.

	TESTING: 122.287353515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6224462 1.6564211 1.638661  1.6267711 1.622362  1.6224023 1.6242394
 1.6263903 1.6282469 1.6296599 1.6306673 1.631359  1.6318231 1.6321295
 1.6323305 1.6324617 1.6325468 1.632602  1.632638  1.6326615 1.6326767
 1.6326867 1.6326935 1.6326979 1.632701  1.6327033 1.6327044 1.6327052
 1.6327059 1.6327062 1.6327065 1.6327065 1.6327068 1.6327066 1.6327069
 1.632707  1.6327071 1.632707  1.6327071 1.632707  1.6327071 1.6327071
 1.6327071 1.6327071 1.6327071 1.6327071 1.6327071 1.632707 ]


TIME OF ONE EPOCH: 30.513020753860474 seconds and 0.5085503458976746 minutes
Epoch 7
	TRAINING: 157.299339979887 total train Value loss.

	TESTING: 118.60148620605469 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6272235 1.6533993 1.6351832 1.6244296 1.6210873 1.6217871 1.6239486
 1.6262258 1.6281128 1.629518  1.6305057 1.6311772 1.6316246 1.6319189
 1.632111  1.6322361 1.6323168 1.6323695 1.6324034 1.632426  1.6324402
 1.6324496 1.6324562 1.6324602 1.6324632 1.6324649 1.6324663 1.6324672
 1.6324675 1.6324681 1.6324682 1.6324685 1.6324686 1.6324688 1.6324688
 1.6324688 1.632469  1.6324689 1.6324689 1.6324689 1.6324688 1.632469
 1.632469  1.6324689 1.6324688 1.6324689 1.632469  1.632469 ]


TIME OF ONE EPOCH: 30.53429913520813 seconds and 0.5089049855868022 minutes
Epoch 8
	TRAINING: 134.61520627886057 total train Value loss.

	TESTING: 116.36750030517578 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6324987 1.6538007 1.6361151 1.626638  1.6242235 1.6254054 1.6277505
 1.6300594 1.6319158 1.6332729 1.6342149 1.6348485 1.6352667 1.6355398
 1.635716  1.6358302 1.6359034 1.6359504 1.6359807 1.6360006 1.6360133
 1.6360216 1.6360271 1.6360307 1.6360333 1.6360348 1.6360359 1.6360365
 1.6360371 1.6360375 1.6360376 1.6360378 1.636038  1.6360382 1.6360383
 1.636038  1.6360378 1.636038  1.636038  1.636038  1.6360382 1.636038
 1.636038  1.6360382 1.6360381 1.6360381 1.6360382 1.636038 ]


TIME OF ONE EPOCH: 31.655664443969727 seconds and 0.5275944073994955 minutes
Epoch 9
	TRAINING: 113.53517082706094 total train Value loss.

	TESTING: 107.5294189453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6336408 1.6509527 1.6337777 1.6253091 1.6235598 1.6250327 1.6274396
 1.629706  1.6314884 1.6327724 1.6336532 1.6342398 1.6346235 1.6348714
 1.6350302 1.6351315 1.6351961 1.635237  1.6352633 1.63528   1.6352906
 1.6352977 1.6353025 1.6353055 1.6353074 1.6353086 1.6353097 1.6353099
 1.6353106 1.6353109 1.6353111 1.6353112 1.635311  1.6353112 1.6353111
 1.6353112 1.6353112 1.6353114 1.6353114 1.6353114 1.6353111 1.635311
 1.6353111 1.6353111 1.6353111 1.6353111 1.6353111 1.6353111]


TIME OF ONE EPOCH: 31.523473739624023 seconds and 0.5253912289937337 minutes
Epoch 10
	TRAINING: 96.43121499940753 total train Value loss.

	TESTING: 103.75724792480469 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6322942 1.6460122 1.6292474 1.6216054 1.6203816 1.6220587 1.62448
 1.6266812 1.6283797 1.6295872 1.6304066 1.6309469 1.6312968 1.6315209
 1.631663  1.6317526 1.6318091 1.631845  1.6318673 1.6318814 1.6318904
 1.6318961 1.6319    1.6319025 1.6319039 1.6319047 1.6319058 1.6319065
 1.6319065 1.6319069 1.6319067 1.6319072 1.6319072 1.6319071 1.6319072
 1.6319072 1.6319072 1.6319076 1.6319075 1.6319075 1.6319075 1.6319076
 1.6319076 1.6319075 1.6319076 1.6319073 1.6319075 1.6319076]


TIME OF ONE EPOCH: 30.900668382644653 seconds and 0.5150111397107442 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 1022.3003428020174 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 304.53901410102844 seconds OR 5.07565023501714 minutes

End of run




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 96, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16214 train samples and 83 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 12)
  (Dcell): GRUCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 145635.82276916504 total train Value loss.

	TESTING: 1489.3826904296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.54310524 0.73877597 0.8465619  0.9180307  0.96578664 0.99752355
 1.018715   1.0330522  1.0429139  1.0498073  1.0546899  1.0581832
 1.0606992  1.0625197  1.0638399  1.0647988  1.0654956  1.0660022
 1.0663705  1.066638   1.0668324  1.0669736  1.0670763  1.0671507
 1.0672048  1.067244   1.0672727  1.0672933  1.0673082  1.0673192
 1.0673271  1.0673329  1.067337   1.0673401  1.0673424  1.067344
 1.067345   1.0673459  1.0673466  1.067347   1.0673473  1.0673475
 1.0673478  1.0673478  1.0673479  1.0673479  1.067348   1.067348  ]


TIME OF ONE EPOCH: 30.1607928276062 seconds and 0.5026798804601034 minutes
Epoch 2
	TRAINING: 6163.162363052368 total train Value loss.

	TESTING: 1008.2548828125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7485527 0.9370425 1.0204742 1.0703133 1.1005023 1.1186534 1.1296831
 1.1365418 1.1409202 1.1437802 1.1456808 1.1469588 1.1478238 1.1484113
 1.1488107 1.1490828 1.1492676 1.1493928 1.149478  1.1495355 1.1495743
 1.1496006 1.1496184 1.1496304 1.1496384 1.1496438 1.1496476 1.1496499
 1.1496516 1.1496528 1.1496534 1.149654  1.1496544 1.1496546 1.1496547
 1.1496547 1.1496549 1.1496549 1.149655  1.149655  1.149655  1.149655
 1.149655  1.149655  1.149655  1.149655  1.149655  1.149655 ]


TIME OF ONE EPOCH: 27.39915180206299 seconds and 0.45665253003438316 minutes
Epoch 3
	TRAINING: 2918.1639404296875 total train Value loss.

	TESTING: 807.8820190429688 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.91969246 1.0705956  1.126129   1.1580949  1.1761677  1.1860865
 1.1915661  1.1946815  1.196518   1.1976367  1.198337   1.1987838
 1.1990721  1.1992596  1.1993821  1.199462   1.1995143  1.1995482
 1.1995705  1.1995847  1.199594   1.1996     1.1996038  1.1996064
 1.1996078  1.199609   1.1996096  1.19961    1.1996102  1.1996104
 1.1996104  1.1996105  1.1996106  1.1996105  1.1996106  1.1996106
 1.1996105  1.1996106  1.1996105  1.1996106  1.1996105  1.1996106
 1.1996105  1.1996106  1.1996105  1.1996106  1.1996105  1.1996106 ]


TIME OF ONE EPOCH: 27.65824604034424 seconds and 0.46097076733907066 minutes
Epoch 4
	TRAINING: 1738.3031816482544 total train Value loss.

	TESTING: 687.6104736328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0342742 1.1487529 1.1881746 1.2116574 1.2241707 1.2302432 1.2330242
 1.2342317 1.2347144 1.2348765 1.2349051 1.234885  1.2348526 1.2348216
 1.2347968 1.2347784 1.2347655 1.2347566 1.2347504 1.2347466 1.2347441
 1.2347423 1.2347412 1.2347404 1.2347399 1.2347397 1.2347394 1.2347394
 1.2347394 1.2347394 1.2347393 1.2347393 1.2347393 1.2347393 1.2347393
 1.2347393 1.2347393 1.2347393 1.2347393 1.2347393 1.2347393 1.2347393
 1.2347393 1.2347393 1.2347393 1.2347393 1.2347393 1.2347393]


TIME OF ONE EPOCH: 26.567898273468018 seconds and 0.4427983045578003 minutes
Epoch 5
	TRAINING: 1179.1072330474854 total train Value loss.

	TESTING: 608.7256469726562 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1123362 1.1989616 1.2301775 1.2501255 1.260303  1.2646393 1.2660835
 1.2662497 1.2659264 1.2654723 1.2650388 1.2646785 1.264399  1.2641919
 1.2640424 1.2639371 1.2638642 1.263814  1.2637798 1.2637568 1.2637414
 1.2637312 1.2637244 1.2637199 1.2637168 1.2637149 1.2637137 1.2637128
 1.2637122 1.2637118 1.2637117 1.2637116 1.2637113 1.2637113 1.2637112
 1.2637112 1.2637112 1.2637112 1.2637112 1.2637112 1.2637112 1.2637112
 1.2637112 1.2637112 1.2637112 1.2637112 1.2637112 1.2637112]


TIME OF ONE EPOCH: 26.720492362976074 seconds and 0.4453415393829346 minutes
Epoch 6
	TRAINING: 874.5574243068695 total train Value loss.

	TESTING: 558.9011840820312 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1705076 1.237368  1.2642609 1.282693  1.2918519 1.2953851 1.2961668
 1.2957798 1.2949994 1.2941763 1.2934517 1.2928659 1.2924153 1.29208
 1.2918363 1.2916621 1.2915391 1.291453  1.2913933 1.2913524 1.291324
 1.2913047 1.2912916 1.2912827 1.2912767 1.2912724 1.2912699 1.2912679
 1.2912668 1.2912657 1.2912654 1.2912649 1.2912648 1.2912647 1.2912643
 1.2912645 1.2912642 1.291264  1.291264  1.291264  1.291264  1.291264
 1.2912639 1.2912639 1.2912639 1.2912639 1.2912639 1.2912639]


TIME OF ONE EPOCH: 26.584482431411743 seconds and 0.4430747071901957 minutes
Epoch 7
	TRAINING: 669.5402090549469 total train Value loss.

	TESTING: 519.0594482421875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2131057 1.2673006 1.2919137 1.3096315 1.318277  1.3214022 1.3218548
 1.3211993 1.320201  1.3192042 1.3183429 1.3176527 1.3171232 1.3167294
 1.3164425 1.3162367 1.316091  1.3159887 1.315917  1.3158677 1.3158336
 1.31581   1.3157939 1.3157829 1.3157754 1.3157704 1.3157668 1.3157642
 1.3157626 1.3157618 1.315761  1.3157605 1.3157601 1.3157599 1.3157597
 1.3157597 1.3157594 1.3157594 1.3157594 1.3157594 1.3157594 1.3157594
 1.3157594 1.3157594 1.3157593 1.3157593 1.3157593 1.3157593]


TIME OF ONE EPOCH: 26.34042239189148 seconds and 0.439007039864858 minutes
Epoch 8
	TRAINING: 530.342725276947 total train Value loss.

	TESTING: 483.09747314453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2434688 1.2890879 1.3119884 1.3291291 1.3374065 1.3402865 1.3405758
 1.3398085 1.3387322 1.3376817 1.3367845 1.3360701 1.3355253 1.3351222
 1.3348296 1.3346206 1.3344734 1.3343701 1.3342983 1.334249  1.334215
 1.3341917 1.3341757 1.3341651 1.3341577 1.3341527 1.3341494 1.3341469
 1.3341453 1.3341445 1.3341439 1.334143  1.334143  1.3341427 1.3341424
 1.3341426 1.3341424 1.3341423 1.3341423 1.3341424 1.3341423 1.3341423
 1.3341422 1.3341423 1.3341422 1.3341423 1.3341422 1.3341423]


TIME OF ONE EPOCH: 26.6059627532959 seconds and 0.44343271255493166 minutes
Epoch 9
	TRAINING: 434.2373813390732 total train Value loss.

	TESTING: 451.770263671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2659063 1.3053784 1.3266987 1.3432136 1.3511367 1.3538328 1.3540417
 1.3532522 1.3521844 1.3511571 1.3502885 1.3496033 1.3490855 1.3487056
 1.3484325 1.3482393 1.3481042 1.3480107 1.3479463 1.3479023 1.3478724
 1.3478521 1.3478384 1.3478292 1.347823  1.3478189 1.3478162 1.3478143
 1.347813  1.3478122 1.3478116 1.3478113 1.3478111 1.3478109 1.3478107
 1.3478107 1.3478106 1.3478107 1.3478105 1.3478106 1.3478106 1.3478106
 1.3478106 1.3478105 1.3478106 1.3478106 1.3478106 1.3478106]


TIME OF ONE EPOCH: 26.454063415527344 seconds and 0.4409010569254557 minutes
Epoch 10
	TRAINING: 362.15824723243713 total train Value loss.

	TESTING: 426.0101318359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2840492 1.3192569 1.3391361 1.3550012 1.3625821 1.3651394 1.3653306
 1.3645859 1.3635902 1.3626417 1.3618485 1.3612295 1.3607671 1.360432
 1.360194  1.3600278 1.3599133 1.359835  1.3597819 1.3597463 1.3597223
 1.3597065 1.3596958 1.3596889 1.359684  1.3596814 1.3596791 1.3596778
 1.3596768 1.3596765 1.3596761 1.3596758 1.3596756 1.3596756 1.3596754
 1.3596755 1.3596753 1.3596753 1.3596753 1.3596754 1.3596753 1.3596753
 1.3596753 1.3596753 1.3596753 1.3596753 1.3596753 1.3596753]


TIME OF ONE EPOCH: 26.837050914764404 seconds and 0.44728418191274005 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 931.9817204303052 and inf%

TIME ELAPSED: 271.9230160713196 seconds OR 4.532050267855326 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 96, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16214 train samples and 83 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 24)
  (Dcell): GRUCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 84905.1318359375 total train Value loss.

	TESTING: 525.0995483398438 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3910199 1.4168088 1.4513451 1.477892  1.4967759 1.5096282 1.5181661
 1.5237647 1.5274124 1.5297832 1.5313258 1.5323306 1.5329876 1.5334182
 1.5337017 1.5338887 1.5340124 1.5340945 1.5341489 1.5341852 1.5342093
 1.5342255 1.5342358 1.5342433 1.534248  1.5342511 1.5342534 1.5342549
 1.5342557 1.5342565 1.5342568 1.5342572 1.5342574 1.5342574 1.5342574
 1.5342575 1.5342577 1.5342574 1.5342574 1.5342574 1.5342577 1.5342577
 1.5342579 1.5342578 1.5342579 1.5342578 1.5342579 1.5342578]


TIME OF ONE EPOCH: 33.53966498374939 seconds and 0.5589944163958231 minutes
Epoch 2
	TRAINING: 1580.6280674934387 total train Value loss.

	TESTING: 474.33587646484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4605277 1.4517335 1.4704142 1.4871457 1.4997478 1.5084871 1.5143296
 1.5181733 1.5206835 1.5223185 1.5233818 1.5240738 1.5245239 1.5248171
 1.5250082 1.5251329 1.5252142 1.525267  1.5253015 1.525324  1.525339
 1.5253483 1.5253546 1.5253588 1.5253613 1.5253632 1.5253644 1.5253649
 1.5253654 1.5253656 1.5253658 1.525366  1.5253661 1.5253662 1.5253662
 1.5253662 1.5253662 1.5253663 1.5253664 1.5253664 1.5253664 1.5253664
 1.5253664 1.5253664 1.5253662 1.5253664 1.5253664 1.5253664]


TIME OF ONE EPOCH: 34.557608127593994 seconds and 0.5759601354598999 minutes
Epoch 3
	TRAINING: 767.3499326705933 total train Value loss.

	TESTING: 435.5390319824219 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4729589 1.4479995 1.4618397 1.4770864 1.4895166 1.4984758 1.5045973
 1.5086741 1.5113523 1.5130978 1.5142288 1.5149587 1.5154281 1.5157297
 1.5159227 1.5160459 1.5161252 1.5161752 1.5162071 1.5162277 1.5162406
 1.5162491 1.5162544 1.5162578 1.5162597 1.5162613 1.5162622 1.5162627
 1.5162631 1.5162634 1.5162634 1.5162634 1.5162636 1.5162635 1.5162635
 1.5162635 1.5162635 1.5162635 1.5162635 1.5162636 1.5162635 1.5162636
 1.5162636 1.5162636 1.5162636 1.5162636 1.5162636 1.5162636]


TIME OF ONE EPOCH: 34.6712372303009 seconds and 0.5778539538383484 minutes
Epoch 4
	TRAINING: 461.1842894554138 total train Value loss.

	TESTING: 410.42462158203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4748366 1.4402924 1.4521384 1.4680054 1.4818008 1.4920672 1.4992006
 1.5039842 1.5071266 1.5091628 1.5104697 1.511302  1.5118299 1.5121624
 1.5123719 1.5125031 1.5125849 1.512636  1.5126678 1.5126877 1.5127002
 1.5127077 1.5127122 1.5127155 1.5127172 1.5127186 1.5127194 1.5127199
 1.5127199 1.5127203 1.5127205 1.5127205 1.5127205 1.5127205 1.5127205
 1.5127206 1.5127206 1.5127206 1.5127207 1.5127206 1.5127206 1.5127206
 1.5127206 1.5127206 1.5127206 1.5127206 1.5127206 1.5127206]


TIME OF ONE EPOCH: 34.54591774940491 seconds and 0.5757652958234151 minutes
Epoch 5
	TRAINING: 327.53318893909454 total train Value loss.

	TESTING: 384.2828063964844 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4728082 1.4334152 1.4445456 1.4614911 1.4767609 1.4883175 1.4964035
 1.5018277 1.5053741 1.5076535 1.5091004 1.5100112 1.5105802 1.5109333
 1.5111513 1.5112857 1.5113683 1.5114187 1.5114493 1.5114679 1.5114795
 1.5114864 1.5114906 1.511493  1.5114946 1.5114958 1.5114962 1.5114967
 1.5114968 1.5114969 1.511497  1.511497  1.5114973 1.5114973 1.5114973
 1.5114974 1.5114974 1.511497  1.5114974 1.5114974 1.5114974 1.5114974
 1.5114974 1.5114974 1.5114974 1.5114974 1.5114974 1.5114974]


TIME OF ONE EPOCH: 33.28076100349426 seconds and 0.5546793500582378 minutes
Epoch 6
	TRAINING: 251.98433113098145 total train Value loss.

	TESTING: 367.56329345703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4717677 1.4304596 1.4415699 1.4595997 1.4760917 1.4886447 1.4974291
 1.5032979 1.5071081 1.5095341 1.511058  1.5120045 1.5125875 1.5129447
 1.5131618 1.5132931 1.5133721 1.5134197 1.513448  1.5134649 1.513475
 1.5134809 1.5134846 1.5134864 1.5134877 1.5134884 1.513489  1.513489
 1.5134892 1.5134894 1.5134895 1.5134892 1.5134894 1.5134894 1.5134892
 1.5134892 1.5134895 1.5134895 1.5134894 1.5134894 1.5134894 1.5134895
 1.5134894 1.5134894 1.5134894 1.5134894 1.5134894 1.5134894]


TIME OF ONE EPOCH: 34.83060622215271 seconds and 0.5805101037025452 minutes
Epoch 7
	TRAINING: 203.74528515338898 total train Value loss.

	TESTING: 344.1495666503906 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4702183 1.4288205 1.440212  1.4591203 1.4764661 1.4896585 1.4988554
 1.5049615 1.5088935 1.5113728 1.5129131 1.5138588 1.5144341 1.5147809
 1.5149889 1.5151126 1.5151861 1.5152289 1.5152537 1.5152684 1.5152769
 1.5152819 1.5152845 1.5152861 1.5152869 1.5152875 1.5152878 1.515288
 1.515288  1.5152879 1.515288  1.5152881 1.5152881 1.5152882 1.515288
 1.515288  1.5152881 1.515288  1.5152879 1.5152879 1.515288  1.5152879
 1.515288  1.515288  1.515288  1.515288  1.515288  1.515288 ]


TIME OF ONE EPOCH: 35.03655457496643 seconds and 0.5839425762494405 minutes
Epoch 8
	TRAINING: 175.42319351434708 total train Value loss.

	TESTING: 328.7569580078125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4699346 1.4291303 1.4408287 1.4603478 1.4782135 1.4917483 1.5011309
 1.507316  1.5112649 1.5137315 1.5152476 1.5161676 1.5167204 1.5170497
 1.517244  1.5173578 1.517424  1.5174619 1.5174836 1.517496  1.5175028
 1.5175066 1.5175089 1.51751   1.5175105 1.517511  1.517511  1.517511
 1.5175112 1.5175112 1.5175114 1.5175112 1.5175111 1.5175114 1.5175111
 1.5175112 1.5175112 1.5175112 1.5175112 1.5175112 1.5175112 1.5175112
 1.5175112 1.5175112 1.5175112 1.5175112 1.5175112 1.5175112]


TIME OF ONE EPOCH: 33.510329246520996 seconds and 0.5585054874420166 minutes
Epoch 9
	TRAINING: 153.20265358686447 total train Value loss.

	TESTING: 314.02197265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4700688 1.4303191 1.4423121 1.4622515 1.4804101 1.4940935 1.5035183
 1.5096853 1.5135906 1.5160078 1.5174785 1.518362  1.5188866 1.519195
 1.5193746 1.5194781 1.5195373 1.5195711 1.5195897 1.5196    1.5196054
 1.5196085 1.5196098 1.5196106 1.5196112 1.5196112 1.5196115 1.5196114
 1.5196112 1.5196116 1.5196115 1.5196112 1.5196115 1.5196114 1.5196114
 1.5196115 1.5196115 1.5196112 1.5196115 1.5196115 1.5196115 1.5196112
 1.5196112 1.5196115 1.5196115 1.5196116 1.5196116 1.5196115]


TIME OF ONE EPOCH: 33.38173985481262 seconds and 0.5563623309135437 minutes
Epoch 10
	TRAINING: 132.09335273504257 total train Value loss.

	TESTING: 297.7475280761719 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4714527 1.4331807 1.445421  1.4656332 1.4839234 1.4976212 1.506994
 1.5130827 1.5169082 1.519256  1.5206724 1.521515  1.52201   1.5222974
 1.5224631 1.5225569 1.5226101 1.5226393 1.5226554 1.522664  1.5226684
 1.5226707 1.5226719 1.5226727 1.5226727 1.5226727 1.5226728 1.5226724
 1.5226727 1.5226729 1.5226729 1.5226727 1.5226727 1.5226728 1.5226728
 1.5226728 1.5226728 1.5226727 1.5226728 1.5226728 1.5226728 1.5226728
 1.5226728 1.5226728 1.5226728 1.5226728 1.5226728 1.5226728]


TIME OF ONE EPOCH: 33.686063289642334 seconds and 0.5614343881607056 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 957.5499401475531 and inf%

TIME ELAPSED: 341.4720447063446 seconds OR 5.691200745105744 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 96, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16214 train samples and 83 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 48)
  (Dcell): GRUCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 47997.483832359314 total train Value loss.

	TESTING: 203.69886779785156 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4310288 1.6634355 1.7333889 1.7512501 1.7525245 1.7499369 1.747472
 1.7459346 1.7451826 1.744917  1.744901  1.7449875 1.7451003 1.7452047
 1.7452887 1.7453507 1.7453947 1.7454243 1.7454438 1.7454567 1.7454647
 1.7454697 1.7454724 1.7454742 1.7454754 1.745476  1.7454762 1.7454766
 1.7454766 1.7454766 1.7454767 1.7454768 1.7454771 1.7454771 1.7454771
 1.7454771 1.7454771 1.7454771 1.7454771 1.7454771 1.7454771 1.7454771
 1.7454771 1.7454771 1.7454771 1.7454771 1.7454771 1.7454771]


TIME OF ONE EPOCH: 38.32782435417175 seconds and 0.6387970725695292 minutes
Epoch 2
	TRAINING: 965.3517656326294 total train Value loss.

	TESTING: 189.60220336914062 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5730411 1.7208784 1.7342988 1.7228482 1.7104236 1.7021363 1.6976964
 1.6957355 1.6951059 1.6950907 1.6953024 1.6955583 1.6957846 1.6959602
 1.6960866 1.6961734 1.6962312 1.6962688 1.6962922 1.6963073 1.6963162
 1.6963216 1.6963253 1.6963271 1.6963286 1.6963294 1.6963297 1.69633
 1.6963302 1.6963303 1.6963303 1.6963304 1.6963303 1.6963303 1.6963303
 1.6963303 1.6963303 1.6963303 1.6963303 1.6963303 1.6963303 1.6963303
 1.6963303 1.6963303 1.6963303 1.6963303 1.6963303 1.6963303]


TIME OF ONE EPOCH: 40.1011483669281 seconds and 0.668352472782135 minutes
Epoch 3
	TRAINING: 465.43462347984314 total train Value loss.

	TESTING: 166.7423095703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6100655 1.7074835 1.7016962 1.6856546 1.6738094 1.6673893 1.664699
 1.6640134 1.6642101 1.6646929 1.6651909 1.665605  1.665915  1.6661335
 1.6662811 1.6663779 1.66644   1.6664791 1.6665033 1.6665177 1.6665269
 1.6665326 1.6665356 1.6665378 1.6665393 1.6665399 1.6665403 1.6665405
 1.666541  1.6665407 1.6665409 1.666541  1.6665411 1.666541  1.666541
 1.666541  1.6665411 1.6665411 1.666541  1.6665411 1.6665411 1.6665411
 1.6665411 1.6665411 1.6665411 1.6665411 1.6665411 1.6665411]


TIME OF ONE EPOCH: 41.14155888557434 seconds and 0.6856926480929056 minutes
Epoch 4
	TRAINING: 302.32265651226044 total train Value loss.

	TESTING: 166.16384887695312 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6334628 1.7019309 1.6896174 1.6747257 1.6656364 1.6616298 1.6606035
 1.6609379 1.6617168 1.6625155 1.663179  1.663677  1.6640286 1.6642675
 1.6644253 1.6645273 1.6645919 1.6646328 1.664658  1.6646737 1.6646831
 1.6646887 1.6646924 1.664695  1.6646963 1.6646972 1.6646978 1.6646981
 1.6646982 1.6646984 1.6646986 1.6646984 1.6646985 1.6646985 1.6646984
 1.6646985 1.6646985 1.6646985 1.6646985 1.6646985 1.6646985 1.6646982
 1.6646987 1.6646987 1.6646987 1.6646985 1.6646986 1.6646986]


TIME OF ONE EPOCH: 41.58373808860779 seconds and 0.6930623014767965 minutes
Epoch 5
	TRAINING: 246.3437079191208 total train Value loss.

	TESTING: 161.01206970214844 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6387681 1.6873599 1.6724703 1.6595126 1.652802  1.6505643 1.6506318
 1.6515749 1.6526675 1.653619  1.6543518 1.6548793 1.6552428 1.6554859
 1.6556445 1.655747  1.6558119 1.6558526 1.655878  1.6558938 1.6559038
 1.6559098 1.655914  1.6559163 1.6559179 1.6559186 1.6559192 1.6559196
 1.6559199 1.6559199 1.65592   1.6559201 1.6559201 1.6559201 1.6559201
 1.6559203 1.6559201 1.6559204 1.6559203 1.6559201 1.6559203 1.6559201
 1.6559203 1.6559201 1.6559203 1.6559201 1.6559203 1.6559201]


TIME OF ONE EPOCH: 40.20069670677185 seconds and 0.6700116117795308 minutes
Epoch 6
	TRAINING: 173.45295351743698 total train Value loss.

	TESTING: 154.21835327148438 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6429225 1.6803341 1.6650312 1.6538281 1.6487446 1.6475687 1.648221
 1.6494473 1.650661  1.6516538 1.6523933 1.652915  1.6532695 1.6535047
 1.6536572 1.6537554 1.6538173 1.6538566 1.6538811 1.6538962 1.6539057
 1.6539118 1.6539154 1.6539178 1.6539192 1.6539204 1.6539207 1.6539211
 1.6539212 1.6539215 1.6539217 1.6539217 1.6539217 1.653922  1.653922
 1.653922  1.653922  1.653922  1.653922  1.653922  1.653922  1.653922
 1.653922  1.653922  1.653922  1.6539218 1.653922  1.653922 ]


TIME OF ONE EPOCH: 41.24946427345276 seconds and 0.6874910712242126 minutes
Epoch 7
	TRAINING: 127.3935295343399 total train Value loss.

	TESTING: 147.11715698242188 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6439632 1.67439   1.6594983 1.6497544 1.6457965 1.6452656 1.6462207
 1.6475575 1.6487898 1.6497641 1.6504753 1.6509699 1.6513025 1.6515207
 1.6516619 1.6517513 1.6518079 1.6518434 1.6518658 1.6518794 1.6518877
 1.651893  1.6518964 1.6518985 1.6519    1.6519005 1.6519015 1.6519017
 1.6519018 1.6519022 1.6519023 1.6519023 1.6519023 1.6519026 1.6519024
 1.6519023 1.6519023 1.6519023 1.6519023 1.6519023 1.6519023 1.6519023
 1.6519023 1.6519023 1.6519023 1.6519024 1.6519023 1.6519023]


TIME OF ONE EPOCH: 40.16588020324707 seconds and 0.6694313367207845 minutes
Epoch 8
	TRAINING: 106.42921629548073 total train Value loss.

	TESTING: 150.0661163330078 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6484649 1.674679  1.6608279 1.6524667 1.649405  1.6493212 1.6504486
 1.6518183 1.6530267 1.6539599 1.6546305 1.655091  1.6553975 1.655597
 1.6557249 1.6558055 1.655856  1.6558871 1.6559066 1.6559184 1.655926
 1.6559303 1.6559334 1.6559354 1.6559362 1.6559368 1.6559374 1.6559377
 1.655938  1.655938  1.655938  1.6559381 1.6559383 1.6559383 1.6559385
 1.6559384 1.6559385 1.6559385 1.6559384 1.6559384 1.6559385 1.6559385
 1.6559384 1.6559385 1.6559385 1.6559385 1.6559384 1.6559385]


TIME OF ONE EPOCH: 40.06012487411499 seconds and 0.6676687479019165 minutes
Epoch 9
	TRAINING: 86.80002602934837 total train Value loss.

	TESTING: 148.9856719970703 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6496307 1.6730937 1.6604583 1.6533034 1.6509227 1.6511208 1.6523094
 1.6536465 1.6547906 1.6556597 1.6562766 1.656696  1.6569722 1.6571504
 1.6572634 1.6573339 1.6573774 1.6574047 1.657421  1.6574314 1.6574374
 1.6574413 1.6574435 1.6574452 1.6574458 1.6574464 1.6574469 1.6574472
 1.6574471 1.6574473 1.6574472 1.6574475 1.6574476 1.6574473 1.6574475
 1.6574473 1.6574473 1.6574473 1.6574476 1.6574476 1.6574476 1.6574476
 1.6574473 1.6574476 1.6574475 1.6574473 1.6574476 1.6574475]


TIME OF ONE EPOCH: 40.859111070632935 seconds and 0.6809851845105489 minutes
Epoch 10
	TRAINING: 83.60637804865837 total train Value loss.

	TESTING: 140.41964721679688 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6472435 1.6682669 1.656745  1.6506345 1.64882   1.649234  1.6504532
 1.6517438 1.6528213 1.6536275 1.6541935 1.6545744 1.6548228 1.6549814
 1.6550819 1.6551433 1.6551812 1.6552043 1.6552186 1.6552268 1.6552321
 1.6552353 1.6552373 1.6552385 1.6552393 1.6552399 1.6552402 1.6552402
 1.6552402 1.6552405 1.6552407 1.6552407 1.6552407 1.6552407 1.6552407
 1.6552405 1.6552405 1.6552405 1.6552407 1.6552407 1.6552407 1.6552407
 1.6552405 1.6552405 1.6552405 1.6552405 1.6552405 1.6552405]


TIME OF ONE EPOCH: 40.80793213844299 seconds and 0.6801322023073832 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 1001.5048454621709 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 405.1539115905762 seconds OR 6.752565193176269 minutes

End of run




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 192, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16118 train samples and 81 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 12)
  (Dcell): GRUCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 134960.90062713623 total train Value loss.

	TESTING: 1593.0986328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.5791594  0.81795204 0.9409814  1.0161865  1.0637846  1.0942954
 1.114226   1.1275924  1.1368163  1.1433464  1.1480631  1.1515179
 1.1540711  1.1559678  1.1573805  1.1584338  1.1592194  1.1598047
 1.1602409  1.1605653  1.1608065  1.1609862  1.1611193  1.1612182
 1.1612916  1.1613462  1.1613864  1.1614164  1.1614386  1.1614552
 1.1614673  1.1614763  1.1614829  1.1614879  1.1614915  1.1614945
 1.1614964  1.161498   1.1614989  1.1614996  1.1615005  1.1615009
 1.1615012  1.1615013  1.1615015  1.1615018  1.161502   1.161502  ]


TIME OF ONE EPOCH: 42.97146940231323 seconds and 0.7161911567052205 minutes
Epoch 2
	TRAINING: 4784.212785720825 total train Value loss.

	TESTING: 1085.688720703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7587956 1.0051787 1.1078292 1.1622614 1.1927894 1.2102572 1.220557
 1.2268816 1.2309269 1.2336026 1.2354149 1.2366601 1.2375234 1.2381246
 1.2385436 1.2388356 1.2390393 1.2391808 1.2392792 1.2393473 1.2393947
 1.2394274 1.2394501 1.2394657 1.2394762 1.2394837 1.2394886 1.2394923
 1.2394946 1.2394964 1.2394973 1.2394981 1.2394987 1.2394991 1.2394993
 1.2394994 1.2394997 1.2394997 1.2394997 1.2394998 1.2394998 1.2394998
 1.2394998 1.2394998 1.2394998 1.2394998 1.2394998 1.2394998]


TIME OF ONE EPOCH: 42.31301546096802 seconds and 0.7052169243494669 minutes
Epoch 3
	TRAINING: 2150.976441383362 total train Value loss.

	TESTING: 897.5233154296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9222049 1.1400493 1.2122074 1.245458  1.2618467 1.270075  1.274386
 1.276794  1.2782286 1.2791271 1.2797083 1.2800915 1.2803465 1.2805169
 1.2806311 1.2807077 1.2807589 1.2807928 1.2808155 1.2808305 1.2808404
 1.2808471 1.2808512 1.2808542 1.2808563 1.2808574 1.2808584 1.2808588
 1.280859  1.2808594 1.2808595 1.2808595 1.2808595 1.2808595 1.2808596
 1.2808596 1.2808595 1.2808596 1.2808596 1.2808595 1.2808596 1.2808596
 1.2808595 1.2808596 1.2808595 1.2808596 1.2808595 1.2808596]


TIME OF ONE EPOCH: 42.32936358451843 seconds and 0.7054893930753072 minutes
Epoch 4
	TRAINING: 1250.8655891418457 total train Value loss.

	TESTING: 773.6422119140625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0325031 1.2163754 1.2663738 1.2866696 1.295103  1.2983848 1.2995923
 1.3000212 1.300171  1.300224  1.3002441 1.3002541 1.3002609 1.3002664
 1.3002713 1.3002753 1.3002787 1.3002812 1.3002832 1.3002847 1.3002858
 1.3002865 1.300287  1.3002875 1.3002878 1.3002877 1.3002878 1.3002881
 1.300288  1.300288  1.3002881 1.3002881 1.3002881 1.3002881 1.3002881
 1.3002881 1.3002881 1.3002881 1.3002881 1.3002881 1.3002881 1.3002881
 1.3002881 1.3002881 1.3002881 1.3002881 1.3002881 1.3002881]


TIME OF ONE EPOCH: 40.89779496192932 seconds and 0.6816299160321554 minutes
Epoch 5
	TRAINING: 821.1708455085754 total train Value loss.

	TESTING: 684.5376586914062 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1084157 1.261811  1.2968286 1.3096764 1.3139155 1.3146957 1.3143535
 1.3137915 1.3132946 1.3129226 1.3126643 1.3124919 1.3123806 1.3123105
 1.312267  1.3122402 1.3122241 1.3122146 1.312209  1.3122058 1.3122038
 1.3122028 1.3122022 1.312202  1.3122016 1.3122017 1.3122015 1.3122015
 1.3122015 1.3122015 1.3122015 1.3122015 1.3122015 1.3122015 1.3122015
 1.3122015 1.3122015 1.3122015 1.3122015 1.3122015 1.3122015 1.3122015
 1.3122015 1.3122015 1.3122015 1.3122015 1.3122015 1.3122015]


TIME OF ONE EPOCH: 41.12944221496582 seconds and 0.6854907035827636 minutes
Epoch 6
	TRAINING: 593.1432666778564 total train Value loss.

	TESTING: 622.498291015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.163208  1.2911444 1.3162488 1.325147  1.3274963 1.3272523 1.3262923
 1.3253258 1.3245527 1.3239884 1.3235973 1.3233347 1.3231627 1.323052
 1.3229821 1.3229381 1.3229111 1.3228946 1.3228844 1.3228785 1.3228745
 1.3228726 1.3228712 1.3228706 1.3228701 1.3228699 1.3228698 1.3228697
 1.3228695 1.3228695 1.3228695 1.3228695 1.3228695 1.3228695 1.3228695
 1.3228695 1.3228695 1.3228695 1.3228693 1.3228695 1.3228695 1.3228693
 1.3228695 1.3228693 1.3228695 1.3228693 1.3228695 1.3228693]


TIME OF ONE EPOCH: 41.99216866493225 seconds and 0.6998694777488709 minutes
Epoch 7
	TRAINING: 466.20241689682007 total train Value loss.

	TESTING: 574.7356567382812 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2018251 1.3106755 1.3297608 1.336887  1.3386489 1.338188  1.3371241
 1.3360848 1.3352493 1.3346317 1.3341969 1.3339    1.3337023 1.3335731
 1.3334898 1.3334368 1.3334036 1.3333828 1.33337   1.333362  1.3333573
 1.3333545 1.3333528 1.3333517 1.3333509 1.3333507 1.3333505 1.3333503
 1.3333503 1.3333503 1.3333501 1.3333502 1.3333501 1.3333502 1.3333501
 1.3333502 1.3333501 1.3333502 1.3333501 1.3333502 1.3333501 1.3333502
 1.3333501 1.3333502 1.3333501 1.3333502 1.3333501 1.3333502]


TIME OF ONE EPOCH: 41.908188581466675 seconds and 0.6984698096911113 minutes
Epoch 8
	TRAINING: 383.60564398765564 total train Value loss.

	TESTING: 537.443603515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2290095 1.3244712 1.3399392 1.3463391 1.3480632 1.3477159 1.346764
 1.3457999 1.3450062 1.3444086 1.3439804 1.343684  1.3434839 1.3433514
 1.3432652 1.3432099 1.3431749 1.3431526 1.3431388 1.3431302 1.3431249
 1.3431216 1.3431196 1.3431184 1.3431178 1.3431175 1.3431171 1.3431168
 1.3431169 1.3431169 1.3431168 1.3431166 1.3431168 1.3431168 1.3431166
 1.3431168 1.3431168 1.3431166 1.3431168 1.3431166 1.3431168 1.3431168
 1.3431166 1.3431168 1.3431166 1.3431168 1.3431166 1.3431168]


TIME OF ONE EPOCH: 41.17640972137451 seconds and 0.6862734953562418 minutes
Epoch 9
	TRAINING: 318.14693808555603 total train Value loss.

	TESTING: 506.7306213378906 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2494681 1.3360845 1.3493398 1.3554748 1.3573567 1.3572272 1.3564563
 1.3556197 1.3549086 1.3543619 1.3539644 1.353686  1.3534968 1.3533705
 1.3532878 1.3532344 1.3532003 1.3531789 1.3531654 1.353157  1.3531519
 1.3531486 1.3531468 1.3531455 1.3531448 1.3531444 1.353144  1.3531439
 1.3531439 1.3531438 1.3531437 1.3531438 1.3531438 1.3531438 1.3531438
 1.3531438 1.3531438 1.3531438 1.3531438 1.3531438 1.3531438 1.3531438
 1.3531438 1.3531438 1.3531438 1.3531438 1.3531438 1.3531438]


TIME OF ONE EPOCH: 40.69056415557861 seconds and 0.6781760692596436 minutes
Epoch 10
	TRAINING: 267.52749609947205 total train Value loss.

	TESTING: 482.3658447265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2652305 1.3459969 1.3576965 1.3636774 1.3657303 1.3658196 1.365235
 1.3645371 1.3639227 1.3634408 1.3630867 1.3628368 1.3626659 1.3625517
 1.3624767 1.3624282 1.3623974 1.3623779 1.3623658 1.3623582 1.3623536
 1.3623505 1.3623489 1.3623476 1.3623469 1.3623468 1.3623465 1.3623464
 1.3623463 1.3623462 1.3623462 1.3623462 1.3623462 1.3623462 1.3623463
 1.3623462 1.3623462 1.3623462 1.3623462 1.3623462 1.3623462 1.3623462
 1.3623462 1.3623462 1.3623462 1.3623462 1.3623462 1.3623462]


TIME OF ONE EPOCH: 40.620744466781616 seconds and 0.6770124077796936 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 905.321121749564 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 417.14955735206604 seconds OR 6.952492622534434 minutes

End of run




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 192, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16118 train samples and 81 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 24)
  (Dcell): GRUCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 84834.00402832031 total train Value loss.

	TESTING: 510.00714111328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.392349  1.4031347 1.4312681 1.4547377 1.4721942 1.4843742 1.4925572
 1.4979217 1.501379  1.5035818 1.5049729 1.5058473 1.5063945 1.5067374
 1.5069511 1.5070846 1.5071687 1.507221  1.5072541 1.5072749 1.5072879
 1.5072962 1.5073012 1.5073045 1.5073068 1.507308  1.5073087 1.5073096
 1.5073098 1.5073099 1.5073102 1.5073103 1.5073103 1.5073104 1.5073103
 1.5073105 1.5073104 1.5073105 1.5073105 1.5073105 1.5073105 1.5073105
 1.5073105 1.5073105 1.5073105 1.5073105 1.5073105 1.5073105]


TIME OF ONE EPOCH: 48.77947664260864 seconds and 0.8129912773768108 minutes
Epoch 2
	TRAINING: 1249.4456338882446 total train Value loss.

	TESTING: 487.73388671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4818145 1.4606127 1.4726547 1.4862297 1.497599  1.5059637 1.511729
 1.5155517 1.5180205 1.5195853 1.520562  1.5211647 1.5215331 1.5217562
 1.5218911 1.5219721 1.5220208 1.5220499 1.5220672 1.5220776 1.5220839
 1.5220873 1.5220897 1.5220912 1.5220919 1.522092  1.5220926 1.5220927
 1.5220928 1.5220928 1.5220928 1.5220929 1.522093  1.522093  1.522093
 1.522093  1.522093  1.522093  1.5220932 1.522093  1.5220932 1.522093
 1.5220932 1.522093  1.5220932 1.522093  1.5220932 1.522093 ]


TIME OF ONE EPOCH: 50.09099626541138 seconds and 0.8348499377568562 minutes
Epoch 3
	TRAINING: 658.2628791332245 total train Value loss.

	TESTING: 468.2382507324219 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4986902 1.4654794 1.473868  1.4862453 1.4974184 1.5058758 1.5117658
 1.5156741 1.5181836 1.5197558 1.5207213 1.5213045 1.5216513 1.5218548
 1.5219724 1.5220402 1.5220782 1.5220999 1.5221118 1.5221181 1.5221215
 1.5221233 1.5221246 1.5221251 1.5221254 1.5221255 1.5221257 1.5221256
 1.5221257 1.5221256 1.5221256 1.5221257 1.5221256 1.5221257 1.5221255
 1.5221257 1.5221256 1.5221256 1.5221256 1.5221255 1.5221256 1.5221255
 1.5221256 1.5221255 1.5221256 1.5221256 1.5221255 1.5221256]


TIME OF ONE EPOCH: 50.44899249076843 seconds and 0.8408165415128072 minutes
Epoch 4
	TRAINING: 401.4335706233978 total train Value loss.

	TESTING: 452.9371032714844 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4988573 1.458509  1.4655226 1.4784817 1.4907377 1.5001731 1.5067779
 1.5111526 1.513944  1.5156759 1.5167254 1.5173495 1.5177131 1.5179213
 1.5180382 1.518103  1.5181379 1.5181563 1.5181656 1.5181704 1.5181725
 1.5181733 1.5181736 1.5181736 1.5181737 1.5181737 1.5181738 1.5181736
 1.5181738 1.5181738 1.5181738 1.5181737 1.5181737 1.5181736 1.5181737
 1.5181736 1.5181737 1.5181736 1.5181737 1.5181736 1.5181737 1.5181736
 1.5181738 1.5181736 1.5181737 1.5181736 1.5181737 1.5181736]


TIME OF ONE EPOCH: 50.940038442611694 seconds and 0.8490006407101949 minutes
Epoch 5
	TRAINING: 272.62210834026337 total train Value loss.

	TESTING: 441.6947021484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4976028 1.4529984 1.459357  1.4731548 1.4865588 1.4969745 1.5042812
 1.5091112 1.5121787 1.5140692 1.5152057 1.5158745 1.5162603 1.5164781
 1.5165988 1.5166634 1.5166979 1.5167149 1.5167235 1.5167272 1.5167284
 1.5167289 1.5167288 1.5167286 1.5167284 1.5167283 1.5167282 1.516728
 1.5167282 1.5167279 1.5167279 1.5167279 1.5167278 1.5167278 1.5167278
 1.5167278 1.5167278 1.5167278 1.5167278 1.5167278 1.5167278 1.5167278
 1.5167278 1.5167278 1.5167278 1.5167278 1.5167278 1.5167278]


TIME OF ONE EPOCH: 50.746928215026855 seconds and 0.8457821369171142 minutes
Epoch 6
	TRAINING: 204.12768244743347 total train Value loss.

	TESTING: 428.8006286621094 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4974282 1.4510621 1.457354  1.4720529 1.4864665 1.4976919 1.5055565
 1.510738  1.5140135 1.5160214 1.517222  1.5179235 1.5183254 1.5185505
 1.5186739 1.5187396 1.5187736 1.51879   1.5187981 1.518801  1.5188019
 1.5188023 1.518802  1.5188015 1.5188012 1.5188007 1.5188006 1.5188005
 1.5188004 1.5188004 1.5188004 1.5188004 1.5188004 1.5188004 1.5188004
 1.5188004 1.5188004 1.5188004 1.5188004 1.5188004 1.5188004 1.5188004
 1.5188004 1.5188004 1.5188004 1.5188004 1.5188004 1.5188004]


TIME OF ONE EPOCH: 49.91339468955994 seconds and 0.8318899114926656 minutes
Epoch 7
	TRAINING: 160.96708261966705 total train Value loss.

	TESTING: 420.0397033691406 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4974384 1.4506805 1.4571425 1.4725841 1.4877269 1.4994969 1.507715
 1.5131062 1.5164976 1.5185659 1.5197959 1.5205112 1.5209187 1.5211451
 1.5212685 1.5213336 1.5213668 1.5213828 1.5213903 1.521393  1.5213935
 1.5213934 1.5213932 1.5213925 1.5213921 1.5213916 1.5213914 1.5213914
 1.5213914 1.5213914 1.5213913 1.5213913 1.5213912 1.5213913 1.5213912
 1.5213913 1.5213912 1.5213913 1.5213912 1.5213913 1.5213912 1.5213913
 1.5213912 1.5213912 1.5213913 1.5213912 1.5213913 1.5213912]


TIME OF ONE EPOCH: 50.12840294837952 seconds and 0.835473382472992 minutes
Epoch 8
	TRAINING: 136.44298964738846 total train Value loss.

	TESTING: 405.7434997558594 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4979991 1.4519701 1.4588232 1.4749299 1.4906248 1.502763  1.511196
 1.5167    1.5201453 1.5222362 1.5234734 1.5241897 1.5245954 1.5248206
 1.5249422 1.5250063 1.5250385 1.5250537 1.5250608 1.5250632 1.5250633
 1.5250632 1.5250627 1.5250621 1.5250616 1.5250616 1.5250614 1.525061
 1.5250609 1.5250608 1.5250608 1.5250608 1.5250605 1.5250605 1.5250608
 1.5250605 1.5250605 1.5250605 1.5250608 1.5250608 1.5250605 1.5250605
 1.5250605 1.5250608 1.5250608 1.5250608 1.5250605 1.5250605]


TIME OF ONE EPOCH: 49.64115500450134 seconds and 0.8273525834083557 minutes
Epoch 9
	TRAINING: 110.94616425037384 total train Value loss.

	TESTING: 384.651123046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4961971 1.4513817 1.4586037 1.4751979 1.4912388 1.5035725 1.5120956
 1.5176296 1.5210766 1.5231595 1.5243864 1.5250942 1.5254935 1.525714
 1.525833  1.5258951 1.5259265 1.525941  1.5259476 1.5259498 1.5259498
 1.5259497 1.5259491 1.5259486 1.5259483 1.5259478 1.5259476 1.5259473
 1.5259472 1.5259472 1.5259471 1.5259471 1.5259471 1.5259471 1.5259471
 1.525947  1.525947  1.5259471 1.5259471 1.525947  1.525947  1.5259471
 1.525947  1.525947  1.5259471 1.525947  1.525947  1.5259471]


TIME OF ONE EPOCH: 49.112151861190796 seconds and 0.8185358643531799 minutes
Epoch 10
	TRAINING: 94.95224559307098 total train Value loss.

	TESTING: 365.6915283203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4946378 1.4512798 1.4588301 1.4757638 1.4919914 1.5043905 1.5129117
 1.5184164 1.5218291 1.5238814 1.5250869 1.525779  1.5261685 1.526383
 1.5264983 1.5265585 1.5265884 1.5266026 1.5266085 1.5266109 1.5266111
 1.5266107 1.5266101 1.5266099 1.5266091 1.5266088 1.5266087 1.5266087
 1.5266085 1.5266083 1.5266083 1.5266083 1.5266083 1.5266083 1.5266083
 1.5266083 1.5266083 1.5266083 1.5266083 1.5266083 1.5266083 1.5266083
 1.5266083 1.5266083 1.5266083 1.5266083 1.5266083 1.5266083]


TIME OF ONE EPOCH: 48.08962869644165 seconds and 0.8014938116073609 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 924.3570042362919 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 498.51994609832764 seconds OR 8.308665768305461 minutes

End of run




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 192, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16118 train samples and 81 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 48)
  (Dcell): GRUCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 46275.36246967316 total train Value loss.

	TESTING: 204.32647705078125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4516926 1.6646224 1.7215949 1.7303686 1.7252676 1.7182729 1.7128197
 1.709296  1.7072482 1.7061505 1.7056077 1.705366  1.7052777 1.7052604
 1.7052721 1.7052923 1.7053125 1.7053288 1.7053415 1.7053503 1.7053565
 1.7053607 1.7053634 1.705365  1.7053663 1.7053671 1.7053674 1.7053677
 1.7053678 1.7053679 1.7053682 1.7053682 1.7053682 1.7053682 1.7053682
 1.7053682 1.7053682 1.7053682 1.7053682 1.7053682 1.7053682 1.7053682
 1.7053682 1.7053682 1.7053682 1.7053682 1.7053682 1.7053682]


TIME OF ONE EPOCH: 70.28681206703186 seconds and 1.1714468677838643 minutes
Epoch 2
	TRAINING: 668.4012053012848 total train Value loss.

	TESTING: 206.6002197265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5991334 1.7396753 1.7492293 1.733706  1.7176424 1.7065105 1.7000198
 1.6966575 1.6951066 1.6945019 1.6943457 1.6943765 1.6944681 1.6945647
 1.694646  1.694708  1.694752  1.6947819 1.6948022 1.6948153 1.6948235
 1.6948285 1.6948318 1.6948339 1.6948353 1.694836  1.6948365 1.6948367
 1.694837  1.6948369 1.6948369 1.6948369 1.694837  1.694837  1.694837
 1.6948369 1.694837  1.694837  1.694837  1.694837  1.6948369 1.694837
 1.694837  1.694837  1.694837  1.694837  1.694837  1.694837 ]


TIME OF ONE EPOCH: 70.44502758979797 seconds and 1.1740837931632995 minutes
Epoch 3
	TRAINING: 313.0056676864624 total train Value loss.

	TESTING: 199.27870178222656 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6363122 1.7316476 1.726068  1.7081907 1.6939254 1.6853664 1.681068
 1.6792761 1.6787536 1.6787868 1.6790105 1.6792616 1.6794773 1.6796418
 1.6797591 1.6798391 1.6798922 1.6799263 1.6799481 1.6799614 1.6799698
 1.6799746 1.6799773 1.6799794 1.6799803 1.6799809 1.6799812 1.6799814
 1.6799816 1.6799817 1.6799817 1.6799817 1.6799817 1.6799817 1.6799817
 1.6799817 1.6799817 1.6799817 1.6799817 1.6799817 1.6799817 1.6799817
 1.6799817 1.6799815 1.6799816 1.6799815 1.6799816 1.6799815]


TIME OF ONE EPOCH: 70.48382639884949 seconds and 1.1747304399808247 minutes
Epoch 4
	TRAINING: 189.4479495882988 total train Value loss.

	TESTING: 195.40176391601562 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6541252 1.723929  1.7145271 1.6993487 1.6887087 1.683073  1.6807574
 1.6801924 1.6803867 1.6808212 1.6812632 1.6816293 1.6819037 1.6820971
 1.6822284 1.6823146 1.68237   1.6824046 1.682426  1.6824393 1.6824471
 1.6824515 1.6824543 1.6824561 1.6824571 1.6824574 1.6824578 1.6824579
 1.6824579 1.6824579 1.6824579 1.6824579 1.6824579 1.682458  1.6824582
 1.6824582 1.6824582 1.6824582 1.6824582 1.6824582 1.6824582 1.6824582
 1.6824582 1.682458  1.6824582 1.6824582 1.6824582 1.6824582]


TIME OF ONE EPOCH: 70.22858762741089 seconds and 1.170476460456848 minutes
Epoch 5
	TRAINING: 141.7927810549736 total train Value loss.

	TESTING: 192.9517822265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6596109 1.7129439 1.7030544 1.6909457 1.6832973 1.6797844 1.6787806
 1.6789616 1.6795548 1.6801926 1.6807328 1.681143  1.681435  1.6816341
 1.6817659 1.6818507 1.6819046 1.6819378 1.681958  1.6819702 1.6819775
 1.6819816 1.6819842 1.6819855 1.6819862 1.6819866 1.681987  1.6819868
 1.6819869 1.6819872 1.6819872 1.6819872 1.6819872 1.6819872 1.6819872
 1.6819872 1.6819872 1.6819872 1.6819872 1.6819872 1.6819872 1.6819873
 1.6819872 1.6819872 1.6819872 1.6819872 1.6819872 1.6819872]


TIME OF ONE EPOCH: 71.16526675224304 seconds and 1.1860877792040507 minutes
Epoch 6
	TRAINING: 94.0038274526596 total train Value loss.

	TESTING: 191.1331787109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6643159 1.7081487 1.6993576 1.6899995 1.6845827 1.682497  1.6822989
 1.6828964 1.6836879 1.6844097 1.6849791 1.6853938 1.6856815 1.6858734
 1.6859984 1.6860777 1.6861275 1.686158  1.6861764 1.6861873 1.6861938
 1.6861976 1.6861998 1.6862011 1.6862018 1.686202  1.6862023 1.6862023
 1.6862025 1.6862025 1.6862024 1.6862024 1.6862024 1.6862024 1.6862024
 1.6862023 1.6862024 1.6862024 1.6862022 1.6862023 1.6862024 1.6862023
 1.6862023 1.6862023 1.6862024 1.6862023 1.6862023 1.6862023]


TIME OF ONE EPOCH: 70.56106162071228 seconds and 1.176017693678538 minutes
Epoch 7
	TRAINING: 77.40670388936996 total train Value loss.

	TESTING: 185.5796356201172 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6650416 1.7023444 1.694991  1.6878804 1.6840937 1.6829624 1.6832558
 1.6840781 1.6849573 1.685702  1.6862673 1.6866692 1.6869428 1.6871228
 1.6872385 1.6873113 1.687356  1.6873833 1.6873997 1.6874094 1.6874149
 1.6874179 1.6874197 1.6874206 1.6874216 1.6874216 1.6874217 1.6874216
 1.6874216 1.6874219 1.6874218 1.6874217 1.6874219 1.6874219 1.6874218
 1.6874217 1.6874219 1.6874218 1.6874218 1.6874217 1.6874218 1.6874218
 1.6874218 1.6874218 1.6874218 1.6874218 1.6874218 1.6874218]


TIME OF ONE EPOCH: 70.33463621139526 seconds and 1.1722439368565878 minutes
Epoch 8
	TRAINING: 65.3026314675808 total train Value loss.

	TESTING: 185.43971252441406 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6647955 1.6977332 1.6919986 1.6867582 1.6841892 1.6837062 1.6842964
 1.6852313 1.6861368 1.6868725 1.6874181 1.687799  1.6880548 1.6882213
 1.6883271 1.6883929 1.6884333 1.6884576 1.6884718 1.68848   1.6884845
 1.6884874 1.6884891 1.6884898 1.6884902 1.6884903 1.6884904 1.6884904
 1.6884906 1.6884906 1.6884906 1.6884906 1.6884906 1.6884906 1.6884904
 1.6884906 1.6884906 1.6884906 1.6884905 1.6884905 1.6884906 1.6884905
 1.6884904 1.6884904 1.6884905 1.6884905 1.6884906 1.6884906]


TIME OF ONE EPOCH: 70.54458427429199 seconds and 1.1757430712381998 minutes
Epoch 9
	TRAINING: 58.18658697605133 total train Value loss.

	TESTING: 180.4615478515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.662342  1.6919367 1.6876307 1.6838591 1.6821705 1.6821074 1.682857
 1.6838275 1.6847178 1.685424  1.6859392 1.6862953 1.6865317 1.6866844
 1.6867803 1.6868396 1.6868753 1.6868966 1.6869092 1.6869161 1.6869203
 1.6869227 1.6869236 1.6869243 1.6869249 1.6869249 1.6869252 1.686925
 1.6869249 1.686925  1.686925  1.686925  1.6869252 1.6869252 1.686925
 1.686925  1.686925  1.686925  1.686925  1.686925  1.686925  1.686925
 1.686925  1.686925  1.686925  1.686925  1.686925  1.686925 ]


TIME OF ONE EPOCH: 70.1249487400055 seconds and 1.1687491456667582 minutes
Epoch 10
	TRAINING: 55.58836841583252 total train Value loss.

	TESTING: 174.64276123046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6601355 1.6870971 1.6841255 1.6815847 1.680575  1.6807998 1.681632
 1.6825967 1.6834521 1.6841193 1.6846011 1.6849313 1.685149  1.6852882
 1.6853753 1.6854286 1.6854604 1.6854794 1.6854905 1.6854963 1.6854999
 1.6855019 1.6855028 1.6855031 1.6855035 1.6855038 1.6855038 1.685504
 1.685504  1.6855038 1.6855038 1.6855037 1.6855036 1.6855035 1.6855036
 1.6855036 1.6855035 1.6855035 1.6855036 1.6855038 1.6855035 1.6855036
 1.6855036 1.6855035 1.6855036 1.6855036 1.6855036 1.6855035]


TIME OF ONE EPOCH: 70.71865439414978 seconds and 1.1786442399024963 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 979.371450636122 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 705.6562054157257 seconds OR 11.760936756928762 minutes

End of run




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 336, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 15974 train samples and 78 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 12)
  (Dcell): GRUCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 136310.15830230713 total train Value loss.

	TESTING: 1837.980224609375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.6307756  0.85897696 0.9700635  1.0386256  1.082772   1.1114938
 1.1305023  1.143405   1.1524091  1.158851   1.1635501  1.1670245
 1.1696148  1.1715559  1.173014   1.1741102  1.1749345  1.1755536
 1.1760187  1.1763676  1.1766294  1.1768254  1.1769723  1.1770822
 1.1771644  1.1772258  1.1772718  1.1773062  1.1773319  1.177351
 1.1773654  1.1773763  1.1773844  1.1773902  1.1773945  1.177398
 1.1774005  1.1774025  1.1774038  1.1774048  1.1774055  1.1774061
 1.1774065  1.1774069  1.1774071  1.1774074  1.1774075  1.1774076 ]


TIME OF ONE EPOCH: 61.97426915168762 seconds and 1.0329044858614604 minutes
Epoch 2
	TRAINING: 3855.555913925171 total train Value loss.

	TESTING: 1364.8408203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8047651 1.0316459 1.1190615 1.1671212 1.1954112 1.2122654 1.2225547
 1.2290814 1.2333932 1.2363408 1.2384043 1.2398703 1.2409201 1.2416737
 1.2422153 1.242604  1.2428824 1.2430812 1.2432228 1.2433237 1.2433953
 1.2434462 1.243482  1.2435073 1.2435253 1.2435378 1.2435467 1.2435528
 1.2435573 1.2435603 1.2435626 1.2435641 1.2435651 1.2435658 1.2435665
 1.243567  1.2435672 1.2435673 1.2435673 1.2435673 1.2435675 1.2435675
 1.2435675 1.2435675 1.2435675 1.2435675 1.2435675 1.2435675]


TIME OF ONE EPOCH: 61.19461464881897 seconds and 1.0199102441469827 minutes
Epoch 3
	TRAINING: 1671.5820560455322 total train Value loss.

	TESTING: 1181.400634765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.94733214 1.1441274  1.203665   1.2332168  1.2490981  1.2576103
 1.2622864  1.2649977  1.266672   1.2677635  1.2685019  1.2690126
 1.2693695  1.2696196  1.2697947  1.269917   1.2700019  1.2700605
 1.2701013  1.2701288  1.2701479  1.2701608  1.2701696  1.2701757
 1.2701796  1.2701821  1.2701839  1.2701851  1.2701861  1.2701865
 1.2701869  1.270187   1.2701871  1.2701873  1.2701873  1.2701873
 1.2701874  1.2701874  1.2701874  1.2701875  1.2701875  1.2701875
 1.2701874  1.2701875  1.2701875  1.2701875  1.2701874  1.2701875 ]


TIME OF ONE EPOCH: 60.55667519569397 seconds and 1.009277919928233 minutes
Epoch 4
	TRAINING: 982.944685459137 total train Value loss.

	TESTING: 1052.9217529296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0423887 1.2055368 1.2465101 1.2659441 1.2756076 1.2801402 1.2822239
 1.2832146 1.2837249 1.2840172 1.2842017 1.2843271 1.2844154 1.2844789
 1.2845243 1.2845567 1.2845798 1.284596  1.2846075 1.284615  1.2846203
 1.2846239 1.2846264 1.284628  1.284629  1.2846296 1.2846301 1.2846305
 1.2846308 1.2846308 1.2846309 1.284631  1.284631  1.284631  1.284631
 1.2846311 1.2846311 1.2846309 1.2846311 1.2846309 1.2846311 1.2846309
 1.2846309 1.284631  1.2846309 1.284631  1.2846309 1.284631 ]


TIME OF ONE EPOCH: 61.48108243942261 seconds and 1.0246847073237102 minutes
Epoch 5
	TRAINING: 657.6911973953247 total train Value loss.

	TESTING: 956.386962890625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.105064  1.2403342 1.2702004 1.2846729 1.291578  1.2944295 1.2954375
 1.295712  1.2957323 1.2956842 1.2956319 1.2955922 1.2955669 1.295552
 1.2955443 1.2955412 1.2955401 1.2955403 1.2955407 1.2955418 1.2955422
 1.2955426 1.2955431 1.2955433 1.2955437 1.2955437 1.2955438 1.295544
 1.295544  1.2955441 1.295544  1.2955441 1.2955441 1.2955441 1.2955441
 1.2955441 1.2955441 1.2955441 1.2955441 1.2955441 1.2955441 1.2955441
 1.2955441 1.2955441 1.2955441 1.2955441 1.2955441 1.2955441]


TIME OF ONE EPOCH: 61.08664107322693 seconds and 1.0181106845537822 minutes
Epoch 6
	TRAINING: 477.704092502594 total train Value loss.

	TESTING: 878.189697265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1486841 1.26293   1.2861241 1.2982477 1.3040735 1.3063442 1.306997
 1.307029  1.306872  1.3066914 1.3065405 1.3064287 1.3063513 1.3063003
 1.3062673 1.3062465 1.3062339 1.306226  1.3062214 1.3062186 1.306217
 1.3062161 1.3062156 1.3062152 1.3062152 1.3062149 1.3062148 1.3062148
 1.3062148 1.3062148 1.3062148 1.3062148 1.3062148 1.3062147 1.3062148
 1.3062148 1.3062147 1.3062148 1.3062148 1.3062147 1.3062148 1.3062148
 1.3062147 1.3062148 1.3062148 1.3062147 1.3062148 1.3062148]


TIME OF ONE EPOCH: 61.49833607673645 seconds and 1.0249722679456075 minutes
Epoch 7
	TRAINING: 370.830361366272 total train Value loss.

	TESTING: 811.9969482421875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1778307 1.2770238 1.2961441 1.3071494 1.3126255 1.314791  1.3154094
 1.3154198 1.3152387 1.3150318 1.3148552 1.3147212 1.3146259 1.3145604
 1.3145169 1.3144883 1.3144704 1.314459  1.3144519 1.3144473 1.3144447
 1.3144428 1.3144418 1.314441  1.3144408 1.3144404 1.3144405 1.3144404
 1.3144403 1.3144403 1.3144403 1.3144401 1.3144401 1.3144401 1.3144401
 1.3144401 1.3144401 1.3144401 1.3144401 1.3144401 1.3144401 1.3144401
 1.3144401 1.3144401 1.3144401 1.3144401 1.3144401 1.3144401]


TIME OF ONE EPOCH: 61.489869594573975 seconds and 1.0248311599095663 minutes
Epoch 8
	TRAINING: 300.53544795513153 total train Value loss.

	TESTING: 758.3787841796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1981983 1.2878268 1.3046774 1.315235  1.3206896 1.3229387 1.3236471
 1.3237227 1.3235819 1.3233963 1.3232292 1.3230981 1.3230021 1.3229353
 1.32289   1.3228599 1.3228402 1.3228276 1.3228196 1.3228147 1.3228114
 1.3228093 1.322808  1.3228074 1.322807  1.3228067 1.3228065 1.3228065
 1.3228064 1.3228062 1.3228062 1.3228062 1.3228062 1.3228062 1.3228062
 1.3228062 1.3228062 1.3228062 1.3228062 1.3228062 1.3228062 1.3228062
 1.3228062 1.3228062 1.3228062 1.3228062 1.3228062 1.3228062]


TIME OF ONE EPOCH: 61.092567443847656 seconds and 1.018209457397461 minutes
Epoch 9
	TRAINING: 250.26870048046112 total train Value loss.

	TESTING: 720.074951171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2130057 1.2974098 1.3132349 1.3237199 1.329286  1.3316725 1.3324989
 1.332662  1.3325801 1.3324325 1.332289  1.3321725 1.3320854 1.3320234
 1.331981  1.3319526 1.331934  1.3319218 1.331914  1.3319091 1.3319061
 1.3319039 1.331903  1.3319021 1.3319016 1.3319013 1.3319011 1.3319013
 1.331901  1.331901  1.331901  1.331901  1.331901  1.331901  1.331901
 1.331901  1.331901  1.331901  1.331901  1.331901  1.331901  1.331901
 1.331901  1.331901  1.331901  1.331901  1.331901  1.331901 ]


TIME OF ONE EPOCH: 60.46581983566284 seconds and 1.007763663927714 minutes
Epoch 10
	TRAINING: 212.87088894844055 total train Value loss.

	TESTING: 688.669921875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2236326 1.3056505 1.3211945 1.3317896 1.3375093 1.3400369 1.3409786
 1.3412288 1.3412095 1.3411052 1.3409914 1.3408945 1.3408201 1.3407667
 1.3407301 1.3407053 1.3406886 1.340678  1.3406711 1.3406668 1.340664
 1.3406624 1.3406613 1.3406606 1.3406602 1.3406599 1.3406599 1.3406596
 1.3406595 1.3406595 1.3406595 1.3406595 1.3406595 1.3406596 1.3406595
 1.3406595 1.3406595 1.3406595 1.3406595 1.3406595 1.3406595 1.3406595
 1.3406595 1.3406595 1.3406595 1.3406595 1.3406595 1.3406595]


TIME OF ONE EPOCH: 61.11381411552429 seconds and 1.0185635685920715 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 857.4565050826113 and inf%

TIME ELAPSED: 614.9137902259827 seconds OR 10.248563170433044 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 336, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 15974 train samples and 78 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 24)
  (Dcell): GRUCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 77996.83805370331 total train Value loss.

	TESTING: 520.986572265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4028592 1.4160455 1.4366564 1.4562724 1.4719195 1.4834299 1.4915181
 1.4970388 1.500732  1.5031685 1.5047604 1.5057932 1.5064602 1.5068899
 1.5071656 1.5073426 1.5074563 1.5075288 1.5075755 1.5076053 1.5076245
 1.5076365 1.5076447 1.5076498 1.5076532 1.5076551 1.5076567 1.5076575
 1.5076581 1.5076585 1.5076587 1.507659  1.507659  1.5076592 1.5076593
 1.5076593 1.5076593 1.5076593 1.5076593 1.5076593 1.5076593 1.5076593
 1.5076593 1.5076593 1.5076593 1.5076593 1.5076593 1.5076593]


TIME OF ONE EPOCH: 81.60478258132935 seconds and 1.3600797096888224 minutes
Epoch 2
	TRAINING: 803.3547828197479 total train Value loss.

	TESTING: 480.585693359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4785615 1.4581918 1.4618554 1.4717199 1.4816796 1.4897623 1.4957167
 1.4998724 1.5026727 1.5045131 1.5057006 1.5064552 1.50693   1.5072258
 1.507409  1.5075208 1.5075897 1.5076313 1.5076569 1.5076724 1.5076817
 1.5076874 1.5076909 1.5076933 1.5076944 1.5076952 1.5076957 1.5076959
 1.507696  1.5076962 1.5076963 1.5076964 1.5076965 1.5076964 1.5076965
 1.5076964 1.5076964 1.5076964 1.5076964 1.5076964 1.5076964 1.5076964
 1.5076964 1.5076964 1.5076964 1.5076964 1.5076964 1.5076964]


TIME OF ONE EPOCH: 83.23988699913025 seconds and 1.387331449985504 minutes
Epoch 3
	TRAINING: 444.32090759277344 total train Value loss.

	TESTING: 470.5863037109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4939433 1.4595569 1.4597547 1.4689326 1.4792155 1.4877986 1.4941515
 1.498556  1.5014851 1.5033758 1.504569  1.5053082 1.505759  1.5060304
 1.5061916 1.5062869 1.5063419 1.5063741 1.5063918 1.5064025 1.5064081
 1.5064111 1.5064129 1.5064139 1.5064142 1.5064148 1.5064149 1.5064148
 1.5064149 1.5064149 1.5064148 1.5064148 1.5064148 1.5064149 1.5064149
 1.5064149 1.5064149 1.5064149 1.5064148 1.5064149 1.5064148 1.5064149
 1.5064149 1.5064148 1.506415  1.5064149 1.5064148 1.5064149]


TIME OF ONE EPOCH: 83.77493262290955 seconds and 1.3962488770484924 minutes
Epoch 4
	TRAINING: 295.27462017536163 total train Value loss.

	TESTING: 466.7992858886719 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4940624 1.4512763 1.4504783 1.4605434 1.4721525 1.4818766 1.4890345
 1.4939451 1.4971663 1.4992127 1.5004809 1.5012516 1.5017111 1.5019808
 1.5021368 1.5022258 1.5022755 1.5023028 1.502317  1.5023253 1.5023288
 1.5023305 1.5023316 1.502332  1.502332  1.502332  1.5023317 1.502332
 1.5023316 1.5023319 1.5023319 1.5023319 1.5023319 1.5023319 1.502332
 1.5023319 1.502332  1.502332  1.502332  1.502332  1.5023319 1.502332
 1.5023319 1.502332  1.502332  1.5023319 1.502332  1.502332 ]


TIME OF ONE EPOCH: 83.39569282531738 seconds and 1.3899282137552897 minutes
Epoch 5
	TRAINING: 216.5466604232788 total train Value loss.

	TESTING: 466.7132568359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4952786 1.4472548 1.4459964 1.4570056 1.4698359 1.4805795 1.4884491
 1.493806  1.4972872 1.499475  1.500816  1.50162   1.5020936 1.5023675
 1.5025234 1.5026098 1.5026572 1.5026823 1.5026952 1.5027018 1.5027043
 1.5027055 1.502706  1.5027059 1.5027058 1.5027056 1.5027052 1.5027052
 1.5027051 1.5027051 1.5027052 1.502705  1.502705  1.5027052 1.5027051
 1.5027052 1.5027052 1.5027052 1.5027052 1.5027052 1.5027052 1.5027052
 1.5027052 1.5027052 1.5027052 1.5027052 1.5027052 1.5027052]


TIME OF ONE EPOCH: 83.45252084732056 seconds and 1.3908753474553426 minutes
Epoch 6
	TRAINING: 165.61529725790024 total train Value loss.

	TESTING: 463.8154296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4946933 1.4429358 1.4411762 1.4527606 1.4663984 1.4778228 1.4861634
 1.4918112 1.4954565 1.4977314 1.4991146 1.4999375 1.5004181 1.5006934
 1.5008476 1.5009327 1.5009782 1.5010016 1.5010134 1.5010189 1.5010213
 1.5010216 1.5010217 1.5010214 1.5010214 1.501021  1.5010208 1.5010206
 1.5010204 1.5010203 1.5010203 1.5010203 1.5010202 1.5010203 1.5010203
 1.5010203 1.5010203 1.5010203 1.5010202 1.5010203 1.5010203 1.5010203
 1.5010203 1.5010203 1.5010203 1.5010203 1.5010203 1.5010203]


TIME OF ONE EPOCH: 83.21514558792114 seconds and 1.386919093132019 minutes
Epoch 7
	TRAINING: 129.71631962060928 total train Value loss.

	TESTING: 464.455078125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4951487 1.4411268 1.4390612 1.4510585 1.4652361 1.4770939 1.4857204
 1.4915346 1.4952669 1.4975828 1.4989831 1.4998113 1.5002917 1.5005649
 1.5007174 1.5008003 1.500844  1.5008662 1.5008768 1.5008819 1.5008837
 1.5008838 1.5008839 1.5008835 1.500883  1.5008829 1.5008825 1.5008823
 1.500882  1.500882  1.500882  1.500882  1.500882  1.500882  1.500882
 1.5008819 1.500882  1.500882  1.500882  1.500882  1.500882  1.500882
 1.500882  1.500882  1.500882  1.500882  1.500882  1.500882 ]


TIME OF ONE EPOCH: 83.70295763015747 seconds and 1.3950492938359578 minutes
Epoch 8
	TRAINING: 105.21190142631531 total train Value loss.

	TESTING: 455.2293395996094 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4950842 1.44005   1.4378864 1.4502239 1.4647695 1.4768945 1.4856791
 1.4915739 1.4953417 1.4976693 1.4990699 1.4998956 1.500372  1.5006421
 1.5007918 1.5008727 1.5009155 1.5009367 1.500947  1.5009514 1.5009526
 1.5009528 1.5009527 1.5009526 1.5009522 1.5009515 1.5009515 1.5009512
 1.5009512 1.500951  1.500951  1.500951  1.500951  1.500951  1.5009509
 1.5009509 1.5009509 1.5009509 1.5009509 1.5009509 1.5009509 1.5009509
 1.5009509 1.5009509 1.5009509 1.5009509 1.5009509 1.5009509]


TIME OF ONE EPOCH: 84.02197480201721 seconds and 1.4003662467002869 minutes
Epoch 9
	TRAINING: 88.16441887617111 total train Value loss.

	TESTING: 447.4847412109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4954817 1.4400203 1.4378749 1.4505187 1.4653425 1.4776444 1.4865203
 1.4924524 1.4962293 1.4985551 1.4999506 1.5007709 1.5012432 1.50151
 1.5016577 1.5017376 1.5017793 1.5018004 1.5018102 1.5018145 1.5018157
 1.501816  1.5018156 1.5018152 1.5018151 1.5018145 1.5018145 1.5018139
 1.5018138 1.5018139 1.5018137 1.5018135 1.5018133 1.5018135 1.5018137
 1.5018133 1.5018133 1.5018135 1.5018135 1.5018133 1.5018135 1.5018137
 1.5018134 1.5018135 1.5018135 1.5018135 1.5018135 1.5018135]


TIME OF ONE EPOCH: 82.74850130081177 seconds and 1.3791416883468628 minutes
Epoch 10
	TRAINING: 76.9437375664711 total train Value loss.

	TESTING: 434.97796630859375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4960214 1.4406885 1.4387295 1.4517181 1.4667953 1.4792362 1.4881712
 1.4941194 1.4978949 1.5002129 1.501601  1.502415  1.5028836 1.5031476
 1.5032941 1.503373  1.5034143 1.503435  1.5034449 1.5034493 1.5034506
 1.5034511 1.5034504 1.5034503 1.5034496 1.5034494 1.5034492 1.5034492
 1.503449  1.5034488 1.5034487 1.5034487 1.5034487 1.5034486 1.5034487
 1.5034487 1.5034486 1.5034486 1.5034487 1.5034487 1.5034487 1.5034486
 1.5034486 1.5034487 1.5034487 1.5034486 1.5034487 1.5034487]


TIME OF ONE EPOCH: 82.97977423667908 seconds and 1.3829962372779847 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 887.0185987032377 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 836.1701371669769 seconds OR 13.936168952782948 minutes

End of run




{'cell_type': 'gru', 'attention_model': ['BA'], 'window_source_size': 336, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 15974 train samples and 78 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): GRUCell(44, 48)
  (Dcell): GRUCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 40255.930050849915 total train Value loss.

	TESTING: 213.83534240722656 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.4305382 1.6430755 1.6988438 1.7063454 1.6998852 1.691569  1.6849912
 1.6806152 1.677978  1.6765027 1.6757327 1.6753631 1.675206  1.6751541
 1.6751502 1.675164  1.675182  1.6751984 1.6752115 1.6752214 1.6752284
 1.6752328 1.6752357 1.6752379 1.675239  1.6752398 1.67524   1.6752405
 1.6752408 1.6752408 1.675241  1.675241  1.675241  1.6752409 1.675241
 1.6752409 1.6752409 1.6752409 1.6752409 1.675241  1.6752409 1.675241
 1.6752409 1.6752409 1.6752409 1.6752409 1.6752409 1.6752409]


TIME OF ONE EPOCH: 131.0101342201233 seconds and 2.1835022370020547 minutes
Epoch 2
	TRAINING: 579.9159548282623 total train Value loss.

	TESTING: 211.991455078125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.5856565 1.7240855 1.7311007 1.7145487 1.6981332 1.6868311 1.6802297
 1.6768062 1.6752416 1.6746582 1.6745422 1.6746182 1.6747516 1.6748828
 1.6749905 1.675071  1.6751281 1.6751667 1.6751921 1.6752086 1.6752192
 1.6752255 1.6752295 1.6752322 1.6752337 1.6752343 1.6752348 1.6752353
 1.6752352 1.6752354 1.6752354 1.6752354 1.6752355 1.6752355 1.6752355
 1.6752355 1.6752355 1.6752356 1.6752356 1.6752355 1.6752355 1.6752356
 1.6752356 1.6752356 1.6752356 1.6752356 1.6752356 1.6752356]


TIME OF ONE EPOCH: 131.10980892181396 seconds and 2.185163482030233 minutes
Epoch 3
	TRAINING: 235.01681554317474 total train Value loss.

	TESTING: 201.16098022460938 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6316    1.7255844 1.7166137 1.6973937 1.6828396 1.6742905 1.6700532
 1.6683285 1.6678764 1.6679822 1.668277  1.6685907 1.6688586 1.6690632
 1.6692108 1.6693124 1.66938   1.6694236 1.669452  1.6694692 1.66948
 1.6694864 1.6694903 1.669493  1.669494  1.6694949 1.6694952 1.6694956
 1.6694958 1.669496  1.6694962 1.6694962 1.669496  1.6694962 1.6694963
 1.6694963 1.6694963 1.6694963 1.6694963 1.6694962 1.6694962 1.6694962
 1.6694963 1.6694963 1.6694963 1.6694963 1.6694963 1.6694963]


TIME OF ONE EPOCH: 131.29259371757507 seconds and 2.188209895292918 minutes
Epoch 4
	TRAINING: 137.99647337198257 total train Value loss.

	TESTING: 200.2286376953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6431105 1.7094889 1.6953677 1.6782287 1.6669941 1.6611917 1.6588242
 1.6582499 1.6584628 1.658935  1.6594235 1.6598356 1.6601504 1.6603769
 1.6605331 1.6606371 1.6607051 1.6607482 1.6607755 1.6607924 1.6608027
 1.6608087 1.6608121 1.6608143 1.6608157 1.6608163 1.6608169 1.6608174
 1.6608176 1.6608174 1.6608173 1.6608176 1.6608175 1.6608176 1.6608176
 1.6608176 1.6608176 1.6608175 1.6608176 1.6608176 1.6608179 1.6608179
 1.6608176 1.6608177 1.6608176 1.6608176 1.6608176 1.6608176]


TIME OF ONE EPOCH: 130.91979432106018 seconds and 2.1819965720176695 minutes
Epoch 5
	TRAINING: 117.62494331598282 total train Value loss.

	TESTING: 200.7491912841797 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6497269 1.7004808 1.6858557 1.6715925 1.6630814 1.6591504 1.6579006
 1.6579381 1.6584618 1.6590798 1.6596295 1.6600623 1.6603795 1.6606015
 1.6607518 1.6608509 1.6609147 1.660955  1.6609805 1.6609958 1.6610051
 1.6610105 1.661014  1.6610161 1.6610173 1.6610179 1.6610183 1.6610186
 1.6610186 1.6610188 1.6610187 1.6610188 1.661019  1.661019  1.661019
 1.6610191 1.661019  1.661019  1.661019  1.661019  1.661019  1.661019
 1.661019  1.661019  1.661019  1.661019  1.661019  1.661019 ]


TIME OF ONE EPOCH: 139.92386603355408 seconds and 2.332064433892568 minutes
Epoch 6
	TRAINING: 81.08392581343651 total train Value loss.

	TESTING: 200.33221435546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6507477 1.6931672 1.6802036 1.6688129 1.6624303 1.6597729 1.6592004
 1.6595639 1.6602273 1.6608938 1.6614501 1.6618739 1.6621783 1.6623882
 1.6625285 1.6626201 1.6626785 1.6627152 1.6627381 1.662752  1.6627605
 1.6627656 1.6627687 1.6627707 1.6627716 1.6627723 1.6627725 1.6627728
 1.662773  1.662773  1.6627729 1.6627731 1.662773  1.6627729 1.6627733
 1.6627731 1.6627733 1.6627731 1.6627731 1.6627731 1.6627731 1.6627731
 1.6627731 1.6627731 1.6627731 1.6627731 1.6627731 1.6627731]


TIME OF ONE EPOCH: 131.3988721370697 seconds and 2.189981202284495 minutes
Epoch 7
	TRAINING: 71.18003690242767 total train Value loss.

	TESTING: 195.45098876953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6503925 1.687663  1.6765432 1.6673466 1.6623824 1.6604726 1.6602372
 1.6607244 1.661413  1.6620646 1.6625955 1.6629933 1.6632762 1.6634699
 1.6635984 1.663682  1.6637348 1.6637683 1.6637887 1.663801  1.663809
 1.6638137 1.6638162 1.6638178 1.6638186 1.6638194 1.6638197 1.6638199
 1.66382   1.66382   1.6638203 1.6638203 1.6638204 1.6638201 1.6638204
 1.6638203 1.6638204 1.6638204 1.6638204 1.6638204 1.6638204 1.6638203
 1.6638201 1.6638204 1.6638204 1.6638204 1.6638204 1.6638204]


TIME OF ONE EPOCH: 132.78850483894348 seconds and 2.2131417473157247 minutes
Epoch 8
	TRAINING: 95.35586300492287 total train Value loss.

	TESTING: 193.99893188476562 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6466793 1.6796135 1.6701691 1.6626889 1.6587216 1.6572686 1.6571925
 1.6577008 1.6583579 1.6589658 1.6594559 1.6598207 1.6600792 1.6602552
 1.6603719 1.660447  1.660495  1.660525  1.6605434 1.6605546 1.6605614
 1.6605653 1.6605679 1.6605692 1.6605701 1.6605705 1.6605711 1.6605711
 1.6605712 1.6605711 1.6605712 1.6605712 1.6605713 1.6605713 1.6605713
 1.6605713 1.6605713 1.6605713 1.6605713 1.6605713 1.6605713 1.6605713
 1.6605713 1.6605713 1.6605713 1.6605713 1.6605713 1.6605713]


TIME OF ONE EPOCH: 131.40736627578735 seconds and 2.1901227712631224 minutes
Epoch 9
	TRAINING: 116.73920169472694 total train Value loss.

	TESTING: 194.0806427001953 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6456035 1.6750245 1.667308  1.6613371 1.6581818 1.6570734 1.6571
 1.6576059 1.6582252 1.658789  1.6592407 1.6595757 1.6598122 1.6599729
 1.6600794 1.6601474 1.6601909 1.6602181 1.6602345 1.660245  1.660251
 1.6602545 1.6602569 1.660258  1.6602588 1.6602592 1.6602597 1.6602598
 1.6602598 1.6602598 1.6602601 1.6602601 1.6602603 1.6602601 1.66026
 1.6602601 1.6602601 1.6602601 1.6602601 1.6602601 1.6602601 1.6602601
 1.6602601 1.6602601 1.6602601 1.6602601 1.6602601 1.6602601]


TIME OF ONE EPOCH: 130.80190682411194 seconds and 2.180031780401866 minutes
Epoch 10
	TRAINING: 91.41940915584564 total train Value loss.

	TESTING: 191.8294677734375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.6425439 1.669069  1.662709  1.6578981 1.6553538 1.6544969 1.6545923
 1.6550908 1.6556771 1.656205  1.6566257 1.6569372 1.6571567 1.6573057
 1.6574035 1.6574665 1.6575065 1.657531  1.6575463 1.6575557 1.6575611
 1.6575644 1.6575663 1.6575677 1.6575683 1.6575689 1.6575689 1.657569
 1.6575695 1.6575693 1.6575695 1.6575693 1.6575695 1.6575695 1.6575694
 1.6575694 1.6575694 1.6575694 1.6575695 1.6575695 1.6575694 1.6575695
 1.6575694 1.6575695 1.6575693 1.6575695 1.6575694 1.6575694]


TIME OF ONE EPOCH: 132.40499114990234 seconds and 2.206749852498372 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 953.7012902610322 and inf%

TIME ELAPSED: 1324.4422373771667 seconds OR 22.074037289619447 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 48, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16262 train samples and 84 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 12)
  (Dcell): LSTMCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 109310.79661798477 total train Value loss.

	TESTING: 9664.9921875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.5200887  0.70251036 0.7610979  0.7997985  0.8289304  0.84996796
 0.86427    0.8733957  0.878782   0.88159895 0.8827329  0.8828228
 0.8823111  0.8814919  0.8805543  0.87961274 0.8787335  0.8779504
 0.8772765  0.8767131  0.8762539  0.87588924 0.8756076  0.8753971
 0.87524676 0.87514615 0.87508637 0.8750593  0.87505794 0.8750769
 0.8751111  0.87515634 0.8752096  0.8752684  0.8753302  0.87539405
 0.8754578  0.8755208  0.8755824  0.8756419  0.8756994  0.8757537
 0.8758054  0.8758541  0.8759001  0.875943   0.8759832  0.8760207 ]


TIME OF ONE EPOCH: 26.276679039001465 seconds and 0.4379446506500244 minutes
Epoch 2
	TRAINING: 12320.903296470642 total train Value loss.

	TESTING: 7884.89794921875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.70727885 0.8538048  0.89335614 0.9227361  0.9462966  0.9637693
 0.9756634  0.9830768  0.9871875  0.9890164  0.98936856 0.988848
 0.9878876  0.9867828  0.9857242  0.98482454 0.984141   0.9836943
 0.9834807  0.9834819  0.98367274 0.98402405 0.98450637 0.98509204
 0.98575544 0.98647416 0.9872284  0.98800206 0.98878145 0.98955584
 0.9903158  0.99105513 0.9917685  0.99245214 0.99310386 0.9937217
 0.99430513 0.9948542  0.9953691  0.9958507  0.9962996  0.9967176
 0.9971056  0.9974656  0.9977988  0.9981067  0.99839103 0.99865305]


TIME OF ONE EPOCH: 22.52595806121826 seconds and 0.3754326343536377 minutes
Epoch 3
	TRAINING: 5793.868703484535 total train Value loss.

	TESTING: 6614.0166015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8147956  0.90356696 0.9333102  0.96076834 0.9837636  1.0009938
 1.0125139  1.0192547  1.0223837  1.0229788  1.0219268  1.0199165
 1.0174595  1.0149162  1.0125259  1.0104333  1.0087116  1.007385
 1.0064445  1.0058599  1.0055898  1.0055894  1.0058119  1.006214
 1.006756   1.0074025  1.0081233  1.008893   1.0096909  1.0104992
 1.011305   1.0120966  1.0128667  1.0136088  1.0143191  1.0149945
 1.0156335  1.0162354  1.0167996  1.0173274  1.0178193  1.0182767
 1.018701   1.0190939  1.0194566  1.0197916  1.0201001  1.0203842 ]


TIME OF ONE EPOCH: 22.299113512039185 seconds and 0.37165189186731973 minutes
Epoch 4
	TRAINING: 3623.187328875065 total train Value loss.

	TESTING: 6120.8525390625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.86976504 0.908973   0.93527085 0.9626791  0.98664963 1.0053912
 1.0185446  1.0267769  1.0311127  1.0325757  1.0320626  1.0303078
 1.0278823  1.0252093  1.0225824  1.0201929  1.0181507  1.0165071
 1.0152708  1.014424   1.0139307  1.0137476  1.0138268  1.0141225
 1.0145901  1.0151906  1.0158887  1.0166552  1.0174651  1.0182974
 1.0191358  1.0199668  1.0207803  1.0215689  1.0223264  1.0230495
 1.0237349  1.0243821  1.02499    1.0255592  1.0260904  1.0265844
 1.027043   1.0274675  1.02786    1.0282218  1.0285555  1.0288621 ]


TIME OF ONE EPOCH: 21.539840936660767 seconds and 0.3589973489443461 minutes
Epoch 5
	TRAINING: 2574.944214940071 total train Value loss.

	TESTING: 5791.94091796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.91017985 0.9152299  0.9400958  0.96723044 0.9919144  1.0119009
 1.0264572  1.0360246  1.0415012  1.0438496  1.0439501  1.0425525
 1.0402627  1.0375471  1.0347452  1.0320895  1.0297257  1.0277345
 1.0261471  1.0249624  1.0241556  1.02369    1.023521   1.023603
 1.023891   1.0243436  1.0249231  1.0255961  1.0263348  1.0271147
 1.027917   1.028725   1.0295266  1.0303116  1.0310723  1.0318037
 1.0325022  1.0331646  1.0337901  1.0343783  1.0349288  1.035443
 1.0359213  1.0363653  1.0367764  1.0371567  1.0375075  1.0378307 ]


TIME OF ONE EPOCH: 21.245442628860474 seconds and 0.3540907104810079 minutes
Epoch 6
	TRAINING: 1971.5833400189877 total train Value loss.

	TESTING: 5542.70166015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.94805074 0.9321981  0.9555487  0.98146564 1.0058262  1.0260754
 1.041163   1.0513184  1.0573226  1.0600797  1.0604427  1.0591542
 1.0568291  1.0539539  1.0508932  1.0479064  1.0451659  1.0427742
 1.0407822  1.0392028  1.038022   1.0372107  1.0367287  1.0365322
 1.036576   1.0368181  1.0372182  1.0377407  1.0383544  1.0390326
 1.0397527  1.0404959  1.0412471  1.0419943  1.0427278  1.0434409
 1.0441276  1.0447844  1.0454086  1.045999   1.0465547  1.0470762
 1.0475634  1.048017   1.0484389  1.04883    1.0491922  1.0495263 ]


TIME OF ONE EPOCH: 21.243441343307495 seconds and 0.3540573557217916 minutes
Epoch 7
	TRAINING: 1587.0616965293884 total train Value loss.

	TESTING: 5328.658203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9836392 0.9563264 0.9777742 1.0018075 1.02499   1.04468   1.05958
 1.0697104 1.0757357 1.0785028 1.0788338 1.0774531 1.0749681 1.071866
 1.0685202 1.0652033 1.0621012 1.0593318 1.0569576 1.0550029 1.0534629
 1.0523138 1.0515203 1.0510406 1.0508313 1.0508492 1.051053  1.0514057
 1.0518742 1.0524288 1.0530456 1.0537025 1.0543829 1.0550727 1.0557603
 1.0564364 1.0570947 1.0577303 1.0583388 1.0589182 1.0594671 1.0599847
 1.0604707 1.0609255 1.0613495 1.0617445 1.0621113 1.0624506]


TIME OF ONE EPOCH: 21.150577783584595 seconds and 0.3525096297264099 minutes
Epoch 8
	TRAINING: 1315.6884217262268 total train Value loss.

	TESTING: 5144.4873046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0158715 0.983258  1.0025408 1.0244619 1.0460767 1.0647892 1.0791132
 1.0888772 1.0946399 1.097198  1.0973454 1.0957841 1.0931046 1.0897833
 1.0861907 1.0826011 1.0792073 1.0761335 1.0734507 1.0711906 1.0693543
 1.067923  1.0668654 1.0661428 1.0657119 1.0655302 1.065557  1.0657532
 1.066085  1.0665216 1.0670363 1.0676066 1.0682139 1.0688419 1.0694782
 1.0701122 1.0707359 1.0713434 1.0719296 1.0724918 1.0730269 1.0735339
 1.0740128 1.0744623 1.0748833 1.0752769 1.075643  1.0759832]


TIME OF ONE EPOCH: 21.28384828567505 seconds and 0.3547308047612508 minutes
Epoch 9
	TRAINING: 1112.4944859743118 total train Value loss.

	TESTING: 4980.3154296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.044304  1.0099615 1.0270152 1.0468984 1.0669177 1.0845363 1.0981177
 1.1073421 1.1126918 1.1149312 1.1148305 1.113067  1.1102074 1.1067102
 1.1029342 1.0991483 1.0955456 1.0922526 1.0893456 1.0868598 1.0848014
 1.0831562 1.0818952 1.0809821 1.0803754 1.0800335 1.0799155 1.0799826
 1.0802    1.0805361 1.0809634 1.081458  1.0819998 1.0825719 1.0831605
 1.0837548 1.084345  1.0849245 1.0854877 1.0860307 1.0865507 1.0870454
 1.0875142 1.0879562 1.0883718 1.0887603 1.0891234 1.0894614]


TIME OF ONE EPOCH: 21.236801147460938 seconds and 0.3539466857910156 minutes
Epoch 10
	TRAINING: 956.0318205356598 total train Value loss.

	TESTING: 4839.6689453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0675529 1.0333703 1.0484143 1.0665858 1.0852249 1.1017976 1.1145641
 1.1231315 1.1279613 1.1298069 1.1294185 1.127446  1.1244276 1.1207966
 1.1168951 1.1129832 1.1092485 1.1058176 1.1027678 1.1001378 1.0979362
 1.096151  1.0947562 1.0937169 1.0929929 1.0925437 1.0923282 1.0923078
 1.0924473 1.0927148 1.0930817 1.093524  1.0940206 1.0945541 1.0951098
 1.0956757 1.0962422 1.0968018 1.0973485 1.0978776 1.098386  1.0988718
 1.099333  1.0997692 1.1001798 1.100565  1.1009253 1.1012614]


TIME OF ONE EPOCH: 21.36240267753601 seconds and 0.3560400446256002 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 636.2142204405769 and inf%

TIME ELAPSED: 220.591623544693 seconds OR 3.6765270590782166 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 48, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16262 train samples and 84 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 24)
  (Dcell): LSTMCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 67569.84998774529 total train Value loss.

	TESTING: 3461.7578125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8750442  0.7108102  0.709866   0.6921105  0.6819773  0.6774972
 0.6784551  0.6839367  0.6934596  0.70696485 0.7244368  0.7453848
 0.76842797 0.7912407  0.8110442  0.82547987 0.83332235 0.83461434
 0.8303186  0.82183975 0.8106548  0.79809344 0.78523475 0.7728815
 0.7615769  0.7516495  0.7432592  0.736446   0.7311669  0.72732806
 0.7248055  0.7234604  0.72314936 0.72373104 0.72506905 0.72703564
 0.7295119  0.73238975 0.7355711  0.7389695  0.7425087  0.74612355
 0.7497588  0.7533683  0.7569157  0.76037186 0.7637156  0.766931  ]


TIME OF ONE EPOCH: 22.65506339073181 seconds and 0.37758438984553017 minutes
Epoch 2
	TRAINING: 2742.309462428093 total train Value loss.

	TESTING: 3176.66064453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8695024  0.7403871  0.7425379  0.7336478  0.73115736 0.73375887
 0.7407583  0.75089675 0.7634566  0.7781916  0.79481465 0.81252915
 0.8298768  0.8449891  0.85613334 0.862246   0.86315614 0.8594583
 0.852203   0.8425899  0.83175087 0.8206322  0.8099508  0.80019933
 0.7916778  0.7845343  0.7788049  0.7744496  0.7713792  0.76947606
 0.7686072  0.7686364  0.769428   0.7708527  0.7727893  0.77512753
 0.7777679  0.7806228  0.78361607 0.7866838  0.78977215 0.79283816
 0.7958481  0.79877585 0.801603   0.8043178  0.8069118  0.8093826 ]


TIME OF ONE EPOCH: 22.758676052093506 seconds and 0.37931126753489175 minutes
Epoch 3
	TRAINING: 1429.2620428800583 total train Value loss.

	TESTING: 3073.291015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8668644  0.7666063  0.76957035 0.7660343  0.7677251  0.7735302
 0.7824237  0.7932873  0.8056168  0.8192142  0.83368385 0.8481609
 0.86137605 0.8719757  0.8789204  0.8817546  0.88064945 0.8762498
 0.86944884 0.8611866  0.8523105  0.8435045  0.83527046 0.82793957
 0.82170016 0.81663084 0.812731   0.80994636 0.8081886  0.80735016
 0.80731547 0.80796677 0.80918986 0.81087744 0.8129297  0.81525767
 0.81778234 0.82043606 0.8231604  0.82590777 0.8286391  0.8313238
 0.83393806 0.83646506 0.8388921  0.841212   0.8434201  0.8455147 ]


TIME OF ONE EPOCH: 22.59368634223938 seconds and 0.376561439037323 minutes
Epoch 4
	TRAINING: 945.1147895604372 total train Value loss.

	TESTING: 3015.6201171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.86595297 0.78653127 0.78964895 0.78916013 0.79308015 0.8002849
 0.8096439  0.82028306 0.8319202  0.8444146  0.85732615 0.8697946
 0.88070977 0.88902664 0.89406157 0.89563507 0.89404196 0.8899049
 0.883993   0.8770752  0.8698225  0.8627638  0.856277   0.85060424
 0.8458753  0.8421358  0.83937037 0.8375234  0.8365144  0.8362489
 0.8366268  0.83754855 0.8389177  0.8406447  0.84264785 0.84485394
 0.8471991  0.84962815 0.8520957  0.85456264 0.8569993  0.8593805
 0.8616878  0.8639077  0.8660304  0.8680495  0.86996174 0.8717657 ]


TIME OF ONE EPOCH: 23.695576906204224 seconds and 0.3949262817700704 minutes
Epoch 5
	TRAINING: 698.5947831124067 total train Value loss.

	TESTING: 2987.556640625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.87067187 0.8055312  0.80864877 0.80986506 0.81486046 0.8224787
 0.8316603  0.8417771  0.85268927 0.8642486  0.8759568  0.8869615
 0.89628327 0.90309995 0.9069565  0.90783244 0.90607446 0.90226233
 0.8970635  0.89112145 0.88498676 0.87908596 0.87372005 0.8690775
 0.86525726 0.86228853 0.8601527  0.8587982  0.85815316 0.85813576
 0.8586589  0.8596373  0.8609876  0.86263376 0.8645058  0.8665415
 0.86868644 0.8708944  0.873126   0.8753486  0.8775363  0.8796679
 0.88172776 0.8837035  0.88558733 0.8873733  0.88905823 0.8906414 ]


TIME OF ONE EPOCH: 23.03893518447876 seconds and 0.383982253074646 minutes
Epoch 6
	TRAINING: 541.6665105819702 total train Value loss.

	TESTING: 2939.41796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.87924546 0.8241011  0.82695866 0.8289174  0.83417904 0.8416007
 0.8502649  0.85974014 0.86995304 0.8807039  0.89142877 0.90128595
 0.9094046  0.91513044 0.9181687  0.91859746 0.91678375 0.91326284
 0.9086198  0.9034042  0.8980787  0.8929977  0.8884096  0.8844686
 0.8812536  0.87878597 0.8770462  0.87598777 0.8755473  0.87565213
 0.8762259  0.87719375 0.8784829  0.88002634 0.8817635  0.88363934
 0.8856066  0.88762426 0.88965803 0.8916792  0.89366466 0.8955959
 0.8974585  0.8992422  0.9009391  0.90254426 0.9040551  0.90547085]


TIME OF ONE EPOCH: 22.819750547409058 seconds and 0.38032917579015096 minutes
Epoch 7
	TRAINING: 442.3690101876855 total train Value loss.

	TESTING: 2893.5712890625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8893157  0.84138125 0.8438901  0.8461268  0.8513619  0.8584959
 0.8667442  0.8757905  0.8855493  0.895731   0.90570086 0.9146311
 0.9217534  0.92656064 0.9288907  0.92890024 0.9269742  0.9236145
 0.91934395 0.91464025 0.9098982  0.90541726 0.9014037  0.8979844
 0.89522135 0.89312875 0.8916851  0.89084756 0.8905576  0.89075005
 0.8913565  0.89230967 0.8935453  0.8950033  0.8966293  0.89837533
 0.9001987  0.90206325 0.9039382  0.90579826 0.9076225  0.90939456
 0.91110134 0.91273344 0.9142841  0.91574895 0.91712534 0.91841274]


TIME OF ONE EPOCH: 22.893155097961426 seconds and 0.3815525849660238 minutes
Epoch 8
	TRAINING: 372.46497908979654 total train Value loss.

	TESTING: 2853.826171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8997256  0.85676485 0.85885686 0.86108154 0.86615515 0.87303185
 0.88101673 0.88982713 0.8993073  0.90905905 0.91838783 0.9264973
 0.93272793 0.9367076  0.9383886  0.93799245 0.9359157  0.932632
 0.92861354 0.9242802  0.9199728  0.9159442  0.91236854 0.9093485
 0.90693206 0.9051267  0.9039093  0.9032379  0.90305865 0.9033115
 0.90393424 0.90486574 0.90604776 0.9074268  0.90895367 0.9105851
 0.9122837  0.91401637 0.91575575 0.9174789  0.9191674  0.9208059
 0.9223831  0.9238906  0.92532176 0.9266724  0.92794114 0.9291261 ]


TIME OF ONE EPOCH: 22.811634302139282 seconds and 0.3801939050356547 minutes
Epoch 9
	TRAINING: 327.85429018363357 total train Value loss.

	TESTING: 2830.017822265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9107302  0.8713321  0.8731076  0.87529904 0.8802797  0.88704866
 0.89496464 0.9037264  0.913073   0.9224919  0.9312453  0.9385883
 0.9439774  0.94717294 0.9482309  0.94743013 0.94517726 0.94192153
 0.9380918  0.93405807 0.9301137  0.9264729  0.923278   0.92061126
 0.9185074  0.91696525 0.91595995 0.9154496  0.91538316 0.91570455
 0.9163565  0.9172832  0.91843224 0.9197543  0.9212063  0.92274886
 0.9243481  0.9259748  0.9276046  0.9292169  0.930795   0.93232536
 0.9337974  0.9352038  0.9365383  0.9377975  0.93897927 0.94008315]


TIME OF ONE EPOCH: 22.96404457092285 seconds and 0.3827340761820475 minutes
Epoch 10
	TRAINING: 293.0475852228701 total train Value loss.

	TESTING: 2815.478515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9217297  0.8849345  0.88642794 0.88855493 0.8934516  0.90015024
 0.9080392  0.91677296 0.92597944 0.93504804 0.94322526 0.9498344
 0.95445013 0.95695055 0.9574775  0.9563501  0.95397687 0.95078063
 0.9471506  0.94341177 0.93981653 0.936545   0.93371314 0.93138456
 0.92958176 0.9282977  0.92750394 0.92715985 0.92721593 0.92761976
 0.92831856 0.9292614  0.9304003  0.93169075 0.9330938  0.9345743
 0.9361019  0.93765086 0.9391987  0.9407273  0.9422216  0.94366956
 0.945062   0.94639117 0.94765234 0.9488421  0.9499584  0.9510005 ]


TIME OF ONE EPOCH: 22.94759488105774 seconds and 0.38245991468429563 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 755.0639215651013 and inf%

TIME ELAPSED: 229.61221051216125 seconds OR 3.8268701752026875 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 48, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16262 train samples and 84 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 48)
  (Dcell): LSTMCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 36466.90245783329 total train Value loss.

	TESTING: 2596.405029296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2765692 1.3486212 1.3395402 1.326776  1.3170463 1.3094133 1.302435
 1.2952735 1.2877856 1.2802508 1.2730767 1.2666088 1.2610571 1.2564996
 1.2529174 1.2502338 1.248345  1.247138  1.2465031 1.2463374 1.246549
 1.2470567 1.2477907 1.2486913 1.2497084 1.2508006 1.2519348 1.2530842
 1.2542278 1.2553504 1.2564394 1.2574875 1.2584885 1.2594398 1.260339
 1.2611867 1.2619828 1.262729  1.263427  1.2640792 1.2646879 1.2652555
 1.2657849 1.2662781 1.266738  1.2671671 1.2675672 1.2679409]


TIME OF ONE EPOCH: 28.16969895362854 seconds and 0.46949498256047567 minutes
Epoch 2
	TRAINING: 1253.4091038107872 total train Value loss.

	TESTING: 2294.63916015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.285811  1.3265252 1.3128594 1.3001053 1.291268  1.2850432 1.2799743
 1.2751403 1.2702289 1.2653258 1.2606677 1.2564778 1.2528956 1.2499689
 1.2476774 1.2459614 1.2447422 1.2439392 1.2434753 1.2432815 1.2432973
 1.243472  1.2437615 1.2441308 1.2445502 1.2449961 1.2454505 1.2458981
 1.246329  1.2467356 1.2471123 1.2474566 1.2477665 1.2480421 1.2482843
 1.2484941 1.2486739 1.2488258 1.248952  1.2490556 1.2491387 1.2492039
 1.2492536 1.2492901 1.2493157 1.2493318 1.2493408 1.249344 ]


TIME OF ONE EPOCH: 29.674769401550293 seconds and 0.49457949002583823 minutes
Epoch 3
	TRAINING: 621.2317861020565 total train Value loss.

	TESTING: 2154.768310546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3059552 1.329748  1.3175899 1.3075904 1.30094   1.2963878 1.292651
 1.2889073 1.2848705 1.2806224 1.2763993 1.272439  1.2689072 1.2658834
 1.2633797 1.2613634 1.2597805 1.2585679 1.257663  1.2570091 1.2565554
 1.2562577 1.2560796 1.2559894 1.2559623 1.255977  1.2560174 1.2560706
 1.256126  1.2561773 1.2562186 1.2562469 1.25626   1.2562569 1.256238
 1.2562038 1.2561551 1.2560936 1.2560208 1.2559382 1.2558482 1.255752
 1.2556509 1.2555469 1.2554415 1.2553357 1.2552308 1.2551278]


TIME OF ONE EPOCH: 30.507923364639282 seconds and 0.5084653894106547 minutes
Epoch 4
	TRAINING: 430.1551042795181 total train Value loss.

	TESTING: 2091.959716796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3183174 1.3309256 1.3214687 1.3143706 1.3099066 1.3069234 1.3042884
 1.3012857 1.2976967 1.2936529 1.2894377 1.2853353 1.2815541 1.2782114
 1.2753472 1.2729511 1.2709818 1.2693863 1.2681091 1.2670968 1.2663009
 1.2656794 1.265196  1.2648205 1.2645276 1.2642964 1.2641095 1.2639538
 1.2638186 1.2636957 1.2635785 1.2634631 1.2633458 1.2632257 1.2631006
 1.2629707 1.262836  1.2626971 1.2625543 1.2624087 1.2622616 1.2621139
 1.2619666 1.2618202 1.2616761 1.2615349 1.2613977 1.2612643]


TIME OF ONE EPOCH: 30.967455625534058 seconds and 0.5161242604255676 minutes
Epoch 5
	TRAINING: 316.5992660075426 total train Value loss.

	TESTING: 2039.9775390625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3219268 1.3266186 1.3195602 1.3145875 1.3115838 1.3095267 1.3074279
 1.3046784 1.301132  1.2969744 1.2925365 1.2881415 1.2840315 1.2803483
 1.2771475 1.2744287 1.2721574 1.2702824 1.2687483 1.267502  1.2664937
 1.2656803 1.2650248 1.264495  1.2640654 1.2637128 1.2634197 1.2631716
 1.2629563 1.2627647 1.2625895 1.2624254 1.2622683 1.2621149 1.261964
 1.2618134 1.2616633 1.261513  1.2613624 1.2612123 1.2610632 1.2609149
 1.2607687 1.2606248 1.2604836 1.260346  1.2602125 1.2600834]


TIME OF ONE EPOCH: 30.717259168624878 seconds and 0.5119543194770813 minutes
Epoch 6
	TRAINING: 259.59025007486343 total train Value loss.

	TESTING: 2032.471435546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3244834 1.3236544 1.3184323 1.3148748 1.312742  1.3111392 1.3092042
 1.3064202 1.3027029 1.2982856 1.2935371 1.2888134 1.2843791 1.2803911
 1.2769138 1.2739493 1.2714629 1.2694014 1.2677063 1.2663208 1.2651933
 1.2642775 1.2635341 1.2629298 1.2624364 1.262031  1.261694  1.26141
 1.2611663 1.260953  1.2607619 1.260587  1.2604234 1.2602677 1.2601177
 1.2599711 1.259827  1.2596849 1.2595444 1.2594054 1.2592677 1.259132
 1.2589983 1.2588671 1.2587392 1.2586144 1.2584932 1.2583756]


TIME OF ONE EPOCH: 31.300549507141113 seconds and 0.5216758251190186 minutes
Epoch 7
	TRAINING: 211.6426724344492 total train Value loss.

	TESTING: 2010.29736328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.326968  1.3228807 1.3190657 1.3164909 1.3149304 1.3135995 1.3117403
 1.3089064 1.3050565 1.300453  1.295489  1.2905403 1.2858869 1.2816956
 1.2780367 1.2749144 1.2722926 1.270117  1.2683272 1.2668631 1.2656708
 1.2647027 1.263917  1.2632793 1.2627604 1.262336  1.2619863 1.2616946
 1.2614474 1.2612348 1.261048  1.26088   1.2607263 1.2605822 1.2604456
 1.2603142 1.2601861 1.2600608 1.2599372 1.2598156 1.2596956 1.2595775
 1.2594612 1.2593471 1.2592354 1.2591263 1.2590203 1.2589173]


TIME OF ONE EPOCH: 31.438114404678345 seconds and 0.5239685734113058 minutes
Epoch 8
	TRAINING: 165.8885623216629 total train Value loss.

	TESTING: 1971.70361328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3301531 1.3246179 1.3219062 1.3200401 1.3188497 1.3176539 1.3157891
 1.3128713 1.3088945 1.3041427 1.299024  1.2939247 1.2891334 1.2848209
 1.2810597 1.2778531 1.2751642 1.272936  1.2711056 1.2696114 1.2683976
 1.2674143 1.2666192 1.2659768 1.2654567 1.265034  1.2646886 1.2644032
 1.2641644 1.2639617 1.2637856 1.2636299 1.2634889 1.2633584 1.2632357
 1.2631186 1.2630048 1.2628939 1.2627848 1.2626776 1.2625716 1.2624673
 1.2623641 1.2622627 1.262163  1.2620662 1.2619712 1.261879 ]


TIME OF ONE EPOCH: 31.158091068267822 seconds and 0.5193015178044637 minutes
Epoch 9
	TRAINING: 137.55502369627357 total train Value loss.

	TESTING: 1945.9920654296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3342644 1.3282021 1.3263606 1.3250065 1.3240514 1.322912  1.3210092
 1.3180081 1.3139293 1.3090708 1.3038504 1.2986627 1.2937992 1.2894337
 1.2856368 1.2824107 1.2797155 1.2774917 1.2756739 1.2741979 1.2730066
 1.2720486 1.2712805 1.2706659 1.270174  1.2697798 1.2694621 1.2692046
 1.2689931 1.2688168 1.2686666 1.268536  1.2684193 1.2683126 1.2682129
 1.2681175 1.2680255 1.2679355 1.2678462 1.2677581 1.2676705 1.2675836
 1.2674971 1.267412  1.267328  1.2672452 1.2671645 1.2670854]


TIME OF ONE EPOCH: 30.630112886428833 seconds and 0.5105018814404806 minutes
Epoch 10
	TRAINING: 110.3408232331276 total train Value loss.

	TESTING: 1917.127685546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.3350202 1.3286891 1.3272368 1.3260329 1.3250604 1.323818  1.3217931
 1.3186878 1.3145328 1.3096277 1.304387  1.2992011 1.2943575 1.2900248
 1.2862704 1.2830925 1.2804487 1.2782769 1.2765104 1.2750841 1.2739396
 1.2730258 1.2722989 1.2717222 1.2712659 1.2709041 1.2706165 1.2703868
 1.2702012 1.2700486 1.2699211 1.2698113 1.2697144 1.2696263 1.2695435
 1.2694647 1.2693882 1.2693125 1.269237  1.2691618 1.2690864 1.2690105
 1.2689354 1.2688603 1.268786  1.2687122 1.2686394 1.2685684]


TIME OF ONE EPOCH: 31.36030673980713 seconds and 0.5226717789967855 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 778.5305110689194 and inf%

TIME ELAPSED: 306.29535031318665 seconds OR 5.104922505219777 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 96, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16214 train samples and 83 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 12)
  (Dcell): LSTMCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 101525.23271942139 total train Value loss.

	TESTING: 10494.4560546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.56332827 0.7209885  0.7721591  0.8085465  0.8351814  0.85224694
 0.8612974  0.8643309  0.86316776 0.8592929  0.85384756 0.8476626
 0.8413108  0.83516246 0.82943845 0.8242531  0.81965005 0.8156276
 0.81215554 0.8091898  0.8066787  0.80456954 0.802811   0.8013556
 0.8001598  0.79918516 0.7983979  0.79776835 0.79727143 0.796885
 0.79659057 0.7963726  0.7962174  0.7961138  0.7960523  0.7960251
 0.79602534 0.79604745 0.79608667 0.7961392  0.7962018  0.79627174
 0.7963466  0.796425   0.79650515 0.79658574 0.7966657  0.7967445 ]


TIME OF ONE EPOCH: 29.973531484603882 seconds and 0.49955885807673134 minutes
Epoch 2
	TRAINING: 9711.8550491333 total train Value loss.

	TESTING: 9193.8701171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.6856964  0.8003957  0.8368931  0.86816794 0.89141124 0.90562737
 0.912246   0.9133152  0.9106969  0.9058761  0.8999533  0.89369744
 0.88761103 0.8819959  0.8770101  0.8727132  0.86910164 0.86613387
 0.8637479  0.8618724  0.86043537 0.8593676  0.85860634 0.85809505
 0.8577851  0.8576344  0.85760796 0.8576765  0.8578163  0.8580073
 0.8582339  0.85848385 0.858747   0.8590155  0.85928386 0.8595476
 0.85980344 0.86004883 0.86028236 0.86050326 0.86071074 0.86090493
 0.8610855  0.861253   0.86140776 0.86155045 0.8616813  0.8618013 ]


TIME OF ONE EPOCH: 27.99159264564514 seconds and 0.46652654409408567 minutes
Epoch 3
	TRAINING: 4411.243663787842 total train Value loss.

	TESTING: 7834.57568359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.78920764 0.8466489  0.8777106  0.9096752  0.9344179  0.9504997
 0.95931417 0.9628766  0.9629822  0.96103483 0.95805633 0.9547457
 0.95154303 0.9486973  0.9463234  0.94444966 0.94305176 0.94207877
 0.94146824 0.9411554  0.94107926 0.9411866  0.9414308  0.94177264
 0.94218135 0.94263124 0.94310254 0.94358015 0.94405323 0.9445127
 0.94495326 0.945371   0.9457636  0.9461298  0.9464693  0.9467826
 0.94707036 0.9473334  0.9475733  0.9477914  0.94798946 0.94816864
 0.94833046 0.94847655 0.94860774 0.94872594 0.94883215 0.9489271 ]


TIME OF ONE EPOCH: 27.83552598953247 seconds and 0.4639254331588745 minutes
Epoch 4
	TRAINING: 2610.522451400757 total train Value loss.

	TESTING: 6955.64453125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8576218  0.8639074  0.8912357  0.9211538  0.9444786  0.95951146
 0.9676205  0.97082317 0.970874   0.9690987  0.9664358  0.963513
 0.9607209  0.9582754  0.9562726  0.9547307  0.9536216  0.9528944
 0.9524879  0.9523417  0.9523989  0.95261025 0.9529329  0.953333
 0.95378196 0.95425814 0.954744   0.9552274  0.9556983  0.9561503
 0.9565793  0.9569823  0.9573579  0.9577057  0.9580258  0.9583191
 0.95858705 0.95883054 0.95905155 0.9592514  0.95943165 0.95959413
 0.9597401  0.95987135 0.9599888  0.9600938  0.9601882  0.9602722 ]


TIME OF ONE EPOCH: 27.424297332763672 seconds and 0.45707162221272785 minutes
Epoch 5
	TRAINING: 1795.5946912765503 total train Value loss.

	TESTING: 6399.0009765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8956464  0.87282676 0.8999041  0.92871815 0.9508905  0.9648413
 0.9720549  0.9745622  0.97408086 0.97188884 0.9688857  0.9656737
 0.96263045 0.95996773 0.9577819  0.9560929  0.95487404 0.9540719
 0.95362365 0.95346427 0.9535331  0.953776   0.9541463  0.9546058
 0.95512265 0.95567226 0.9562353  0.9567967  0.9573456  0.9578743
 0.958377   0.95885074 0.9592936  0.9597047  0.9600844  0.9604328
 0.960752   0.96104276 0.9613074  0.9615469  0.96176386 0.9619593
 0.96213573 0.9622944  0.96243685 0.96256477 0.9626794  0.9627819 ]


TIME OF ONE EPOCH: 27.886589288711548 seconds and 0.46477648814519246 minutes
Epoch 6
	TRAINING: 1353.6650762557983 total train Value loss.

	TESTING: 6160.3935546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9129788  0.8784479  0.90565073 0.93366176 0.95484287 0.9679607
 0.97463024 0.9768151  0.97610307 0.9736686  0.9703605  0.9667756
 0.96331203 0.9602113  0.9575982  0.9555149  0.95394814 0.9528533
 0.9521691  0.9518286  0.951766   0.9519211  0.95224124 0.95268095
 0.9532027  0.95377654 0.95437765 0.9549878  0.9555926  0.9561812
 0.9567464  0.9572832  0.9577879  0.9582594  0.9586965  0.95909995
 0.95947045 0.9598095  0.96011853 0.9603995  0.9606539  0.96088433
 0.9610924  0.9612797  0.9614483  0.9615995  0.96173555 0.9618573 ]


TIME OF ONE EPOCH: 26.61193346977234 seconds and 0.44353222449620566 minutes
Epoch 7
	TRAINING: 1082.1634058952332 total train Value loss.

	TESTING: 5969.35302734375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9198457  0.8832717  0.90982616 0.9366896  0.9566355  0.9688619
 0.9750767  0.9771348  0.9764528  0.97405183 0.970682   0.96690226
 0.9631196  0.9596132  0.9565514  0.95401496 0.9520213  0.95054406
 0.9495315  0.94891995 0.9486426  0.94863415 0.94883585 0.949196
 0.9496705  0.9502229  0.9508232  0.95144844 0.9520799  0.9527036
 0.9533093  0.9538897  0.9544401  0.9549571  0.95543957 0.95588624
 0.9562983  0.95667654 0.95702237 0.9573371  0.95762306 0.95788234
 0.95811623 0.9583275  0.9585176  0.9586883  0.95884174 0.9589792 ]


TIME OF ONE EPOCH: 27.232038736343384 seconds and 0.45386731227238974 minutes
Epoch 8
	TRAINING: 892.6043281555176 total train Value loss.

	TESTING: 5796.6220703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.922669   0.88794076 0.9130921  0.93845797 0.9570344  0.9683477
 0.9741203  0.97608906 0.97551805 0.9732892  0.9700468  0.9662854
 0.9623932  0.95866364 0.95529824 0.9524172  0.95007056 0.9482572
 0.9469414  0.9460676  0.9455707  0.94538516 0.94544804 0.9457034
 0.94610196 0.94660246 0.9471707  0.9477789  0.94840556 0.9490332
 0.9496498  0.9502454  0.9508139  0.9513509  0.95185363 0.95232135
 0.9527536  0.95315117 0.953515   0.95384693 0.95414865 0.95442176
 0.954669   0.9548916  0.95509225 0.9552723  0.95543367 0.95557845]


TIME OF ONE EPOCH: 26.539572715759277 seconds and 0.4423262119293213 minutes
Epoch 9
	TRAINING: 751.9158329963684 total train Value loss.

	TESTING: 5640.404296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9242137  0.8920611  0.91556954 0.93938607 0.95669705 0.9671905
 0.9725471  0.97439224 0.9738787  0.9717919  0.96869856 0.9650406
 0.96117795 0.95739913 0.9539192  0.95087934 0.948352   0.94635415
 0.94486237 0.9438283  0.94319063 0.94288415 0.9428454  0.943016
 0.94334495 0.9437885  0.9443105  0.9448811  0.945477   0.9460795
 0.94667506 0.94725347 0.9478071  0.94833124 0.94882274 0.94928056
 0.9497036  0.9500928  0.95044863 0.9507729  0.9510672  0.9513338
 0.95157415 0.9517906  0.95198506 0.9521592  0.95231515 0.95245445]


TIME OF ONE EPOCH: 26.391888856887817 seconds and 0.4398648142814636 minutes
Epoch 10
	TRAINING: 642.4226016998291 total train Value loss.

	TESTING: 5498.4033203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9253207  0.89585966 0.9179503  0.9403753  0.9565807  0.9663498
 0.9713107  0.9729952  0.9724725  0.9704618  0.96747786 0.9639247
 0.9601382  0.9563963  0.9529153  0.94984347 0.9472639  0.9452021
 0.94364184 0.942539   0.9418348  0.9414648  0.9413665  0.9414813
 0.941758   0.94215244 0.94262815 0.94315547 0.9437102  0.94427425
 0.9448336  0.94537735 0.94589853 0.946392   0.94685477 0.9472852
 0.94768286 0.9480476  0.94838107 0.9486842  0.94895905 0.94920707
 0.9494303  0.94963115 0.9498105  0.9499711  0.95011437 0.95024186]


TIME OF ONE EPOCH: 26.82082200050354 seconds and 0.44701370000839236 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 606.170284884043 and inf%

TIME ELAPSED: 275.35775685310364 seconds OR 4.589295947551728 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 96, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16214 train samples and 83 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 24)
  (Dcell): LSTMCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 58673.24971294403 total train Value loss.

	TESTING: 3777.253173828125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.904697   0.74075043 0.7514033  0.74245584 0.7389906  0.7375364
 0.73830277 0.74138296 0.747092   0.7556966  0.7672618  0.7814712
 0.79742265 0.8135283  0.82770765 0.837911   0.8427289  0.8417359
 0.83542466 0.82487625 0.81140274 0.79628295 0.7806118  0.76524323
 0.7507878  0.73764616 0.7260502  0.71610725 0.70783484 0.70119077
 0.6960924  0.6924313  0.69008344 0.6889166  0.68879527 0.68958396
 0.6911506  0.6933693  0.696122   0.6992995  0.7028036  0.7065471
 0.71045446 0.7144605  0.7185114  0.7225627  0.72657835 0.7305299 ]


TIME OF ONE EPOCH: 30.630741119384766 seconds and 0.5105123519897461 minutes
Epoch 2
	TRAINING: 1798.3464465141296 total train Value loss.

	TESTING: 3475.396240234375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8784817  0.75106585 0.7597059  0.7566054  0.7582303  0.7616872
 0.7664648  0.7724505  0.77992976 0.78917044 0.80014575 0.8123518
 0.8247434  0.8358683  0.8442192  0.8486705  0.8487685  0.84474874
 0.83734417 0.8275251  0.81628376 0.80449957 0.7928758  0.78192794
 0.7719997  0.7632949  0.7559085  0.74985766 0.7451047  0.7415761
 0.7391761  0.7377946  0.7373164  0.73762447 0.73860395 0.7401445
 0.74214226 0.7445021  0.74713695 0.74997056 0.75293505 0.755973
 0.7590358  0.7620831  0.7650824  0.7680081  0.77084035 0.7735643 ]


TIME OF ONE EPOCH: 32.186938762664795 seconds and 0.5364489793777466 minutes
Epoch 3
	TRAINING: 939.7318680286407 total train Value loss.

	TESTING: 3344.013427734375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8569232  0.7597692  0.76535106 0.7649059  0.7680864  0.7727774
 0.7783675  0.7848115  0.792378   0.80122626 0.8111657  0.821572
 0.83144426 0.83961046 0.84503436 0.8470931  0.84569746 0.84123063
 0.8343763  0.8259314  0.8166638  0.80722696 0.7981281  0.78972584
 0.7822496  0.7758241  0.7704959  0.7662543  0.76305014 0.76080906
 0.7594416  0.7588502  0.758935   0.7595959  0.7607372  0.7622689
 0.7641073  0.7661768  0.7684104  0.7707493  0.77314276 0.7755493
 0.77793354 0.78026736 0.7825293  0.7847023  0.786775   0.78873914]


TIME OF ONE EPOCH: 33.14329504966736 seconds and 0.5523882508277893 minutes
Epoch 4
	TRAINING: 608.7155635356903 total train Value loss.

	TESTING: 3254.049072265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.84843713 0.77152    0.7755043  0.7764028  0.780088   0.7849356
 0.790435   0.79662466 0.80373985 0.8118306  0.820597   0.82938683
 0.83731264 0.8434565  0.8471034  0.8479086  0.8459391  0.84159404
 0.835467   0.8282093  0.8204283  0.8126326  0.80520946 0.79842883
 0.7924593  0.78738755 0.78323966 0.7799968  0.77761084 0.7760138
 0.77512634 0.7748635  0.7751389  0.7758676  0.7769687  0.7783663
 0.77999157 0.78178257 0.7836849  0.7856516  0.78764284 0.7896258
 0.7915735  0.79346526 0.7952848  0.79702085 0.7986654  0.8002138 ]


TIME OF ONE EPOCH: 33.381685733795166 seconds and 0.5563614288965861 minutes
Epoch 5
	TRAINING: 438.5093947649002 total train Value loss.

	TESTING: 3156.399658203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8460952  0.78288114 0.7857988  0.7871944  0.7908418  0.79541594
 0.80049604 0.806154   0.8125778  0.8197452  0.827316   0.834676
 0.8410728  0.84579164 0.8483263  0.84848326 0.84638536 0.84240013
 0.83702934 0.83080614 0.82422197 0.8176835  0.81150055 0.80588704
 0.8009754  0.79683226 0.7934746  0.7908829  0.78901327 0.78780615
 0.7871918  0.7870969  0.7874464  0.78816736 0.7891905  0.79045177
 0.7918922  0.7934604  0.7951106  0.7968038  0.79850787 0.80019546
 0.8018454  0.80344063 0.8049695  0.8064224  0.8077942  0.8090815 ]


TIME OF ONE EPOCH: 33.47210454940796 seconds and 0.5578684091567994 minutes
Epoch 6
	TRAINING: 337.50367081165314 total train Value loss.

	TESTING: 3098.73828125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.84797597 0.7946967  0.79698664 0.7986115  0.802109   0.80634767
 0.81097656 0.81608284 0.82181627 0.82811177 0.83462226 0.84079105
 0.8459859  0.84964705 0.85141367 0.8511836  0.8491035  0.8455026
 0.8408058  0.8354539  0.82984877 0.82432127 0.8191226  0.8144261
 0.8103383  0.80691093 0.8041563  0.8020545  0.8005671  0.79964083
 0.79921573 0.7992266  0.79960954 0.80030084 0.8012409  0.8023748
 0.8036526  0.8050301  0.8064689  0.80793655 0.8094058  0.81085443
 0.81226486 0.8136238  0.8149211  0.81615025 0.8173068  0.8183889 ]


TIME OF ONE EPOCH: 33.95743703842163 seconds and 0.5659572839736938 minutes
Epoch 7
	TRAINING: 271.0977249145508 total train Value loss.

	TESTING: 3059.25341796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.84995174 0.80378383 0.8054818  0.8070784  0.81036645 0.81433433
 0.81864697 0.823364   0.8285886  0.83422506 0.83993953 0.84523773
 0.8495897  0.8525514  0.85385746 0.8534593  0.8515071  0.84829235
 0.8441784  0.8395364  0.8347032  0.829956   0.8255046  0.82149416
 0.81801367 0.8151069  0.812782   0.81102234 0.80979294 0.80904746
 0.8087329  0.80879295 0.8091708  0.8098118  0.81066376 0.81167865
 0.8128136  0.8140305  0.8152965  0.8165833  0.8178679  0.8191316
 0.82035947 0.82154024 0.82266563 0.82373047 0.824731   0.8256658 ]


TIME OF ONE EPOCH: 33.62599301338196 seconds and 0.5604332168896993 minutes
Epoch 8
	TRAINING: 226.88134253025055 total train Value loss.

	TESTING: 3022.8447265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8523803  0.81111574 0.812197   0.8135618  0.81654984 0.82022536
 0.82424486 0.8286246  0.8334203  0.8385136  0.8435879  0.84820694
 0.8519244  0.8543834  0.8553854  0.8549147  0.8531163  0.85024893
 0.8466259  0.8425648  0.8383529  0.83422655 0.8303651  0.8268929
 0.82388633 0.8213825  0.81938875 0.81788963 0.8168545  0.8162422
 0.8160064  0.81609696 0.8164639  0.8170588  0.8178361  0.81875354
 0.8197735  0.8208625  0.821992   0.8231373  0.82427883 0.82539964
 0.82648724 0.82753193 0.82852685 0.8294671  0.83035004 0.83117425]


TIME OF ONE EPOCH: 34.028998374938965 seconds and 0.5671499729156494 minutes
Epoch 9
	TRAINING: 189.41363847255707 total train Value loss.

	TESTING: 2992.22021484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.85636926 0.8194358  0.82001364 0.8212115  0.82400805 0.8275057
 0.8313362  0.8354723  0.8399315  0.84458286 0.8491312  0.8531916
 0.85638607 0.8584272  0.85916847 0.85861903 0.856921   0.8543074
 0.85105354 0.84743565 0.84370166 0.8400555  0.8366519  0.83359754
 0.8309584  0.8287663  0.82702625 0.8257241  0.8248323  0.8243144
 0.82412785 0.824229   0.8245729  0.8251169  0.82582015 0.8266454
 0.82755953 0.8285329  0.82954055 0.8305607  0.83157593 0.8325721
 0.8335381  0.83446515 0.8353475  0.8361816  0.8369642  0.8376948 ]


TIME OF ONE EPOCH: 34.22841548919678 seconds and 0.5704735914866129 minutes
Epoch 10
	TRAINING: 169.17413759231567 total train Value loss.

	TESTING: 2970.3408203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.85984254 0.8265637  0.8267797  0.8278699  0.83054614 0.8339367
 0.83765113 0.8416214  0.8458314  0.85014    0.8542708  0.8578826
 0.8606546  0.8623555  0.86288106 0.86226153 0.8606366  0.85822093
 0.85526013 0.8519974  0.8486494  0.845394   0.84236515 0.83965516
 0.8373209  0.8353884  0.8338611  0.8327259  0.8319565  0.83151996
 0.831378   0.8314915  0.8318194  0.83232415 0.83296883 0.8337203
 0.83454955 0.83542967 0.83633864 0.83725786 0.83817136 0.83906686
 0.8399347  0.8407675  0.84156    0.84230876 0.843012   0.8436686 ]


TIME OF ONE EPOCH: 34.06263566017151 seconds and 0.5677105943361919 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 731.8918206854518 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 333.3175468444824 seconds OR 5.55529244740804 minutes

End of run




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 96, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16214 train samples and 83 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 48)
  (Dcell): LSTMCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 33079.497111320496 total train Value loss.

	TESTING: 3257.0830078125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1639946 1.219163  1.2068613 1.196066  1.1914579 1.1908677 1.1912146
 1.1902188 1.1868883 1.1812861 1.1740596 1.1660289 1.157924  1.1502774
 1.1434139 1.1374896 1.1325418 1.1285304 1.1253718 1.1229597 1.121182
 1.1199278 1.1190959 1.1185952 1.1183482 1.1182885 1.1183636 1.1185292
 1.118752  1.1190057 1.1192701 1.1195307 1.1197765 1.1200007 1.1201984
 1.1203668 1.1205043 1.120611  1.1206874 1.1207354 1.120756  1.1207526
 1.1207259 1.1206791 1.1206146 1.1205349 1.120442  1.1203384]


TIME OF ONE EPOCH: 39.76289701461792 seconds and 0.662714950243632 minutes
Epoch 2
	TRAINING: 954.1046271324158 total train Value loss.

	TESTING: 2892.13427734375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1577902 1.1854608 1.1743864 1.1691092 1.1699967 1.1741229 1.1783134
 1.180402  1.179538  1.1758856 1.1701527 1.1631981 1.1557904 1.1485076
 1.1417243 1.1356453 1.130352  1.125845  1.1220756 1.1189688 1.1164393
 1.1144    1.1127688 1.1114714 1.1104428 1.1096272 1.1089787 1.1084591
 1.1080382 1.1076916 1.1074002 1.1071496 1.106929  1.1067293 1.106545
 1.106371  1.1062049 1.1060442 1.1058873 1.1057334 1.1055822 1.1054337
 1.1052877 1.1051446 1.1050044 1.1048677 1.1047345 1.1046056]


TIME OF ONE EPOCH: 39.28651690483093 seconds and 0.6547752817471822 minutes
Epoch 3
	TRAINING: 468.77653336524963 total train Value loss.

	TESTING: 2699.7041015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1638112 1.1781518 1.1704572 1.1692402 1.1731646 1.1792558 1.184604
 1.1873767 1.1869861 1.1837456 1.1784196 1.1718688 1.1648445 1.157905
 1.1514088 1.1455535 1.1404179 1.1360043 1.132269  1.1291447 1.1265541
 1.1244187 1.1226656 1.1212282 1.1200486 1.119077  1.118272  1.1175998
 1.1170328 1.116549  1.1161306 1.1157639 1.1154382 1.1151454 1.1148791
 1.1146346 1.1144079 1.1141962 1.1139978 1.1138114 1.1136348 1.1134677
 1.1133097 1.11316   1.1130182 1.1128838 1.1127572 1.1126376]


TIME OF ONE EPOCH: 39.85059094429016 seconds and 0.6641765157381694 minutes
Epoch 4
	TRAINING: 325.5580304861069 total train Value loss.

	TESTING: 2597.336181640625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1687028 1.1759574 1.1713243 1.1727046 1.1780628 1.1845971 1.1897731
 1.1921355 1.1913596 1.1878909 1.1825255 1.1760983 1.1693103 1.1626668
 1.1564846 1.15093   1.1460629 1.1418747 1.1383196 1.1353302 1.1328336
 1.1307565 1.1290317 1.1275986 1.1264042 1.1254045 1.1245621 1.1238464
 1.1232325 1.1227008 1.122235  1.1218232 1.1214553 1.1211237 1.1208225
 1.1205468 1.1202934 1.1200591 1.1198422 1.1196402 1.119452  1.1192769
 1.1191134 1.118961  1.118819  1.1186866 1.1185634 1.1184493]


TIME OF ONE EPOCH: 40.44056701660156 seconds and 0.6740094502766927 minutes
Epoch 5
	TRAINING: 236.06098687648773 total train Value loss.

	TESTING: 2523.2216796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1777456 1.1813285 1.1786962 1.1813694 1.1870708 1.1932099 1.1975976
 1.199099  1.1975987 1.1936374 1.1880212 1.1815476 1.1748611 1.1684104
 1.1624662 1.1571593 1.1525276 1.1485506 1.1451753 1.1423333 1.1399527
 1.1379641 1.136304  1.1349156 1.1337503 1.1327673 1.1319323 1.1312177
 1.1306005 1.1300626 1.1295896 1.1291697 1.1287941 1.1284554 1.1281482
 1.1278683 1.1276116 1.1273757 1.1271584 1.1269573 1.1267717 1.1265998
 1.1264408 1.1262935 1.1261576 1.1260321 1.1259165 1.1258101]


TIME OF ONE EPOCH: 41.32755780220032 seconds and 0.6887926300366719 minutes
Epoch 6
	TRAINING: 180.8167809844017 total train Value loss.

	TESTING: 2477.17626953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1848997 1.1865301 1.1853322 1.1887852 1.1945275 1.2001683 1.2038071
 1.204558  1.2024592 1.1981124 1.1923217 1.1858478 1.1792835 1.1730281
 1.1673104 1.162233  1.1578149 1.1540244 1.150804  1.1480858 1.1457992
 1.1438781 1.1422632 1.1409016 1.139749  1.1387676 1.137926  1.1371988
 1.1365653 1.1360096 1.1355172 1.1350783 1.1346841 1.1343284 1.1340052
 1.1337109 1.1334416 1.1331947 1.1329677 1.1327592 1.1325673 1.1323906
 1.1322284 1.132079  1.131942  1.1318164 1.1317014 1.1315964]


TIME OF ONE EPOCH: 41.078777551651 seconds and 0.6846462925275166 minutes
Epoch 7
	TRAINING: 147.8011446595192 total train Value loss.

	TESTING: 2424.129638671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.1933271 1.194085  1.1939039 1.1978052 1.2034193 1.2085401 1.211509
 1.211635  1.2090663 1.2044411 1.1985521 1.1921214 1.1856952 1.17963
 1.1741214 1.169248  1.1650146 1.1613828 1.1582925 1.1556759 1.1534663
 1.1515999 1.1500212 1.1486812 1.1475384 1.1465585 1.1457119 1.1449757
 1.1443303 1.143761  1.143255  1.1428022 1.142395  1.1420267 1.1416929
 1.1413884 1.1411105 1.1408566 1.1406237 1.1404105 1.1402152 1.1400361
 1.1398722 1.1397222 1.1395854 1.1394603 1.1393466 1.1392437]


TIME OF ONE EPOCH: 40.60016345977783 seconds and 0.6766693909962972 minutes
Epoch 8
	TRAINING: 129.6753587126732 total train Value loss.

	TESTING: 2363.436767578125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.201406  1.201862  1.2023441 1.2064804 1.2119164 1.2166001 1.2190664
 1.2187737 1.2159467 1.2112392 1.20542   1.1991688 1.1929872 1.1871935
 1.1819541 1.1773309 1.1733183 1.1698743 1.1669394 1.1644481 1.1623371
 1.1605469 1.159026  1.1577289 1.1566179 1.15566   1.1548295 1.1541041
 1.153467  1.1529028 1.1524006 1.1519512 1.1515465 1.1511806 1.1508492
 1.1505479 1.1502732 1.1500224 1.1497934 1.149584  1.1493928 1.1492182
 1.1490586 1.1489134 1.1487811 1.1486608 1.1485521 1.1484534]


TIME OF ONE EPOCH: 39.99218773841858 seconds and 0.6665364623069763 minutes
Epoch 9
	TRAINING: 115.2482385635376 total train Value loss.

	TESTING: 2316.316650390625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2042342 1.204493  1.2053922 1.209657  1.214956  1.2193524 1.2215201
 1.2210159 1.2181078 1.213449  1.2077802 1.2017455 1.1958113 1.1902676
 1.1852624 1.1808463 1.1770091 1.1737087 1.1708865 1.1684816 1.1664338
 1.1646882 1.1631969 1.1619178 1.1608154 1.1598605 1.1590278 1.158298
 1.1576539 1.1570822 1.1565725 1.156115  1.1557035 1.1553317 1.1549947
 1.1546886 1.1544101 1.1541568 1.1539258 1.1537151 1.1535234 1.1533487
 1.1531899 1.1530454 1.1529144 1.1527959 1.1526887 1.1525925]


TIME OF ONE EPOCH: 40.86387348175049 seconds and 0.6810645580291748 minutes
Epoch 10
	TRAINING: 110.0674477815628 total train Value loss.

	TESTING: 2296.78515625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.2105402 1.2102312 1.211298  1.2154863 1.2205143 1.2245544 1.2264013
 1.2256866 1.2226992 1.2180771 1.2125285 1.2066612 1.2009132 1.1955526
 1.1907144 1.186442  1.1827238 1.179517  1.1767676 1.1744162 1.1724069
 1.1706878 1.1692138 1.1679451 1.1668489 1.1658969 1.1650656 1.1643362
 1.1636922 1.1631215 1.1626126 1.1621573 1.1617482 1.1613795 1.1610466
 1.1607454 1.160472  1.1602241 1.1599993 1.1597949 1.1596094 1.1594411
 1.159289  1.159151  1.1590265 1.1589142 1.1588134 1.1587226]


TIME OF ONE EPOCH: 40.00002861022949 seconds and 0.6666671435038248 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 739.9420162645209 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 403.6867604255676 seconds OR 6.72811267375946 minutes

End of run




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 192, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16118 train samples and 81 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 12)
  (Dcell): LSTMCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 87610.73166656494 total train Value loss.

	TESTING: 11187.755859375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.56212616 0.6707673  0.6798451  0.6853291  0.69043756 0.6925318
 0.6910763  0.6869029  0.6811408  0.67473793 0.6683506  0.6623746
 0.65701365 0.6523452  0.64837027 0.6450479  0.6423166  0.6401081
 0.6383542  0.63699067 0.6359589  0.63520706 0.6346892  0.6343659
 0.63420224 0.63416886 0.6342404  0.63439476 0.6346139  0.63488185
 0.6351861  0.6355152  0.63585985 0.63621294 0.63656795 0.63691974
 0.6372644  0.63759875 0.6379199  0.6382264  0.63851655 0.6387898
 0.639045   0.6392822  0.63950133 0.6397028  0.6398864  0.6400529 ]


TIME OF ONE EPOCH: 44.51672697067261 seconds and 0.7419454495112101 minutes
Epoch 2
	TRAINING: 7005.724126815796 total train Value loss.

	TESTING: 10228.5 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7138364  0.7764655  0.7656726  0.75799453 0.75116974 0.7427264
 0.7323769  0.72098297 0.7095556  0.6988299  0.68920994 0.6808471
 0.6737347  0.6677821  0.6628621  0.6588385  0.65558094 0.652971
 0.65090483 0.64929223 0.6480569  0.6471338  0.646468   0.6460131
 0.64572996 0.64558613 0.6455535  0.6456092  0.6457336  0.64591026
 0.6461254  0.64636767 0.64662737 0.6468969  0.64716965 0.6474404
 0.6477047  0.6479596  0.6482022  0.6484304  0.64864296 0.64883894
 0.6490175  0.6491787  0.64932215 0.6494486  0.64955795 0.649651  ]


TIME OF ONE EPOCH: 42.15222644805908 seconds and 0.7025371074676514 minutes
Epoch 3
	TRAINING: 3041.76163482666 total train Value loss.

	TESTING: 9420.83203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.82364935 0.83725053 0.82383627 0.81721956 0.81148815 0.8045519
 0.79614896 0.7869733  0.77785695 0.7693985  0.76191485 0.75551003
 0.75015867 0.74576765 0.7422175  0.7393835  0.7371496  0.7354111
 0.734079   0.73307735 0.73234266 0.7318228  0.7314747  0.73126304
 0.73115903 0.73113877 0.7311835  0.7312767  0.731406   0.7315607
 0.7317319  0.73191273 0.73209745 0.7322812  0.73246044 0.73263204
 0.73279375 0.73294383 0.73308104 0.7332044  0.7333134  0.7334075
 0.7334871  0.73355234 0.7336034  0.73364085 0.7336652  0.7336774 ]


TIME OF ONE EPOCH: 41.58610939979553 seconds and 0.6931018233299255 minutes
Epoch 4
	TRAINING: 1812.391242980957 total train Value loss.

	TESTING: 8678.3876953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8851853  0.86105365 0.85066193 0.84765244 0.84568685 0.8426662
 0.8381352  0.83258784 0.8267303  0.82110757 0.8160312  0.81162924
 0.8079143  0.8048359  0.8023162  0.8002707  0.7986178  0.79728544
 0.7962117  0.7953444  0.7946419  0.7940693  0.79359984 0.7932117
 0.79288757 0.79261345 0.7923789  0.7921754  0.791996   0.7918353
 0.7916888  0.79155296 0.7914248  0.7913024  0.7911834  0.7910663
 0.79095    0.7908337  0.7907166  0.7905979  0.79047704 0.7903545
 0.79022974 0.7901028  0.78997374 0.78984267 0.7897099  0.7895756 ]


TIME OF ONE EPOCH: 40.74724745750427 seconds and 0.6791207909584045 minutes
Epoch 5
	TRAINING: 1252.8413391113281 total train Value loss.

	TESTING: 8033.65966796875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.90977466 0.8637745  0.8558166  0.85483384 0.8553155  0.85497934
 0.8531321  0.8500872  0.84644717 0.8427179  0.83921355 0.8360867
 0.8333827  0.83108723 0.8291565  0.8275363  0.8261727  0.82501686
 0.82402694 0.8231685  0.82241374 0.82174057 0.8211321  0.82057506
 0.82005954 0.8195779  0.81912416 0.8186939  0.81828374 0.8178913
 0.81751424 0.8171507  0.81679946 0.8164593  0.81612915 0.81580806
 0.81549585 0.8151913  0.8148943  0.814604   0.81432027 0.814043
 0.8137717  0.81350625 0.8132466  0.81299275 0.8127445  0.8125019 ]


TIME OF ONE EPOCH: 40.62034273147583 seconds and 0.6770057121912638 minutes
Epoch 6
	TRAINING: 937.6843423843384 total train Value loss.

	TESTING: 7553.90625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.92035294 0.866072   0.85995793 0.86023116 0.8621987  0.86350703
 0.8633192  0.8618219  0.8595413  0.8569533  0.8543747  0.8519764
 0.8498295  0.8479449  0.8463036  0.8448728  0.843617   0.8425029
 0.841502   0.84059006 0.8397489  0.8389637  0.8382239  0.8375209
 0.8368489  0.8362038  0.8355827  0.83498305 0.8344034  0.83384234
 0.8332994  0.8327734  0.8322636  0.83176965 0.8312908  0.83082634
 0.830376   0.82993925 0.82951564 0.82910484 0.8287058  0.82831883
 0.82794356 0.8275795  0.8272264  0.8268839  0.82655203 0.82623065]


TIME OF ONE EPOCH: 40.768330335617065 seconds and 0.6794721722602844 minutes
Epoch 7
	TRAINING: 744.3582320213318 total train Value loss.

	TESTING: 7209.619140625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9266358  0.87197363 0.86699957 0.86802745 0.870847   0.8731058
 0.8739     0.8733404  0.8719007  0.87003154 0.86804485 0.86612
 0.86434096 0.8627334  0.86129284 0.8599993  0.8588284  0.8577567
 0.8567635  0.85583204 0.85494894 0.85410446 0.85329175 0.85250556
 0.8517426  0.85100126 0.85027975 0.8495775  0.84889406 0.8482292
 0.84758276 0.84695435 0.8463443  0.8457522  0.8451777  0.8446204
 0.84408015 0.8435566  0.8430493  0.8425581  0.8420821  0.8416213
 0.8411753  0.8407438  0.8403264  0.83992296 0.8395328  0.83915603]


TIME OF ONE EPOCH: 42.327547788619995 seconds and 0.7054591298103332 minutes
Epoch 8
	TRAINING: 615.3762099742889 total train Value loss.

	TESTING: 6925.14794921875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.92945135 0.8780559  0.8736188  0.8749676  0.8781539  0.8808533
 0.882134   0.88206303 0.88107795 0.8796089  0.87795967 0.8763095
 0.87474704 0.87330526 0.87198573 0.87077606 0.8696576  0.8686126
 0.8676248  0.86668146 0.8657721  0.86489046 0.86403096 0.86319107
 0.862369   0.8615643  0.86077625 0.86000526 0.85925186 0.85851645
 0.8577991  0.85710067 0.856421   0.85576    0.85511816 0.8544952
 0.853891   0.85330516 0.8527374  0.8521879  0.85165566 0.8511406
 0.8506426  0.8501611  0.8496957  0.84924614 0.8488122  0.8483935 ]


TIME OF ONE EPOCH: 41.48867154121399 seconds and 0.6914778590202332 minutes
Epoch 9
	TRAINING: 521.6225216388702 total train Value loss.

	TESTING: 6714.35693359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9305165  0.88364977 0.8794905  0.8809549  0.8842623  0.8871313
 0.8886305  0.8888069  0.8880749  0.8868463  0.88541335 0.8839505
 0.8825452  0.8812314  0.8800137  0.8788822  0.87782174 0.876817
 0.8758542  0.874923   0.874015   0.8731254  0.8722504  0.8713885
 0.8705391  0.8697029  0.8688798  0.8680709  0.86727756 0.8665002
 0.86574036 0.8649984  0.8642748  0.8635701  0.8628846  0.86221844
 0.86157155 0.8609439  0.8603353  0.85974586 0.85917485 0.85862225
 0.858088   0.85757136 0.85707223 0.8565903  0.85612524 0.85567653]


TIME OF ONE EPOCH: 40.991673707962036 seconds and 0.6831945617993672 minutes
Epoch 10
	TRAINING: 449.4406626224518 total train Value loss.

	TESTING: 6545.68359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.9312354  0.8889634  0.8849911  0.8864793  0.88976675 0.8926291
 0.8941632  0.8944184  0.8937982  0.892699   0.8914004  0.8900671
 0.88878155 0.88757515 0.8864511  0.8854     0.88440734 0.88345873
 0.8825415  0.88164634 0.8807662  0.8798965  0.8790348  0.8781806
 0.8773336  0.8764945  0.8756651  0.87484664 0.8740405  0.87324846
 0.8724714  0.87171066 0.87096715 0.8702416  0.86953455 0.8688463
 0.868177   0.867527   0.86689603 0.8662841  0.86569154 0.8651175
 0.86456215 0.8640253  0.8635062  0.86300516 0.86252135 0.86205465]


TIME OF ONE EPOCH: 41.8108229637146 seconds and 0.6968470493952433 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 587.9414063912851 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 417.77880668640137 seconds OR 6.9629801114400225 minutes

End of run




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 192, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16118 train samples and 81 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 24)
  (Dcell): LSTMCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 55620.54895591736 total train Value loss.

	TESTING: 4235.41162109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.90855676 0.7433475  0.7532889  0.7439853  0.7396642  0.73691195
 0.7353544  0.7346589  0.73500186 0.7368043  0.7405077  0.7463868
 0.75439906 0.7640839  0.7745686  0.78471935 0.7934212  0.79985833
 0.80366665 0.8049069  0.8039274  0.8012112  0.7972639  0.79255515
 0.78748846 0.78239334 0.7775283  0.7730839  0.7691914  0.7659316
 0.7633431  0.7614308  0.7601745  0.75953496 0.75945944 0.7598869
 0.7607514  0.761985   0.763521   0.76529425 0.76724476 0.7693178
 0.7714646  0.7736439  0.77582085 0.77796793 0.7800635  0.7820923 ]


TIME OF ONE EPOCH: 48.130903244018555 seconds and 0.8021817207336426 minutes
Epoch 2
	TRAINING: 1393.3127312660217 total train Value loss.

	TESTING: 3909.083984375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8642379  0.72748625 0.73070586 0.7212507  0.7169487  0.715748
 0.7169196  0.719708   0.7238104  0.7291993  0.7358746  0.7436731
 0.7521785  0.76073813 0.7685834  0.7750108  0.7795449  0.78200907
 0.78249973 0.7812929  0.7787498  0.77524495 0.77112436 0.76668644
 0.7621759  0.7577855  0.75365967 0.7499006  0.7465737  0.743715
 0.7413358  0.73942935 0.7379742  0.7369398  0.73628885 0.7359799
 0.7359702  0.7362171  0.73667926 0.73731774 0.7380974  0.738986
 0.7399559  0.74098337 0.74204826 0.74313474 0.74422973 0.74532354]


TIME OF ONE EPOCH: 50.10979866981506 seconds and 0.8351633111635844 minutes
Epoch 3
	TRAINING: 742.5297467708588 total train Value loss.

	TESTING: 3833.25 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.82538414 0.7195966  0.71745783 0.70814633 0.7034524  0.7024656
 0.70441025 0.70839083 0.7138219  0.7203295  0.7275682  0.7351164
 0.74247056 0.74910766 0.75457865 0.7585882  0.7610302  0.76197016
 0.7615955  0.76015824 0.75792617 0.75515443 0.75206727 0.7488514
 0.7456575  0.74259984 0.7397618  0.73719966 0.73494685 0.7330184
 0.7314154  0.73012686 0.7291352  0.72841674 0.7279446  0.72769064
 0.7276262  0.7277237  0.7279571  0.7283022  0.72873765 0.72924453
 0.7298067  0.7304102  0.7310434  0.7316975  0.732365   0.7330399 ]


TIME OF ONE EPOCH: 51.74304413795471 seconds and 0.8623840689659119 minutes
Epoch 4
	TRAINING: 494.0010862350464 total train Value loss.

	TESTING: 3810.982177734375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8015564  0.7172509  0.7118742  0.70247126 0.6973886  0.69629556
 0.69840187 0.7026799  0.70832086 0.7147308  0.721419   0.72793543
 0.733873   0.7388999  0.7427952  0.7454661  0.74694103 0.7473406
 0.74684185 0.7456436  0.7439419  0.741915   0.73971546 0.7374683
 0.7352705  0.7331953  0.7312935  0.7295976  0.72812515 0.72688156
 0.7258632  0.72505957 0.72445494 0.7240316  0.7237696  0.7236486
 0.7236491  0.7237519  0.72394    0.7241978  0.72451156 0.7248698
 0.7252622  0.7256808  0.7261185  0.7265705  0.7270321  0.7275003 ]


TIME OF ONE EPOCH: 49.66353940963745 seconds and 0.8277256568272908 minutes
Epoch 5
	TRAINING: 353.6472990512848 total train Value loss.

	TESTING: 3765.183837890625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7868862  0.71690404 0.70968074 0.70023483 0.6949413  0.69373304
 0.69579035 0.69998163 0.705361   0.7112369  0.71709657 0.7225489
 0.7273029  0.7311667  0.73404807 0.73594636 0.7369361  0.7371411
 0.73671204 0.7358043  0.7345643  0.7331209  0.7315821  0.730034
 0.72854245 0.7271553  0.725904   0.7248083  0.7238764  0.72310895
 0.7225004  0.72204083 0.72171754 0.72151625 0.7214221  0.7214198
 0.72149557 0.72163635 0.72183007 0.72206604 0.7223356  0.722631
 0.72294563 0.72327495 0.72361463 0.7239614  0.72431266 0.72466725]


TIME OF ONE EPOCH: 50.683594703674316 seconds and 0.844726578394572 minutes
Epoch 6
	TRAINING: 268.3694384098053 total train Value loss.

	TESTING: 3726.828125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7805066  0.721217   0.71334964 0.70435274 0.6993054  0.6982259
 0.70026547 0.704252   0.70920396 0.71442616 0.7194484  0.72395766
 0.72775817 0.73074996 0.732913   0.73429096 0.73497283 0.7350746
 0.73472244 0.7340388  0.7331352  0.73210675 0.7310306  0.7299671
 0.72896063 0.7280421  0.7272308  0.72653687 0.72596335 0.7255081
 0.7251643  0.7249234  0.72477466 0.7247069  0.7247087  0.72476935
 0.7248787  0.7250275  0.7252078  0.7254124  0.7256357  0.72587276
 0.72611976 0.72637385 0.72663265 0.7268944  0.72715807 0.72742265]


TIME OF ONE EPOCH: 50.703892946243286 seconds and 0.8450648824373881 minutes
Epoch 7
	TRAINING: 214.54936015605927 total train Value loss.

	TESTING: 3692.186767578125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7779822  0.7266956  0.7187824  0.71042776 0.7057996  0.704905
 0.70687306 0.7105436  0.71496594 0.71949524 0.72372603 0.727419
 0.730448   0.7327702  0.7344039  0.7354109  0.73588085 0.7359166
 0.7356226  0.73509634 0.73442346 0.73367506 0.7329069  0.7321619
 0.73146987 0.7308507  0.73031586 0.72987    0.7295135  0.7292421
 0.72904974 0.72892845 0.72887015 0.72886574 0.7289068  0.72898537
 0.72909415 0.7292268  0.72937804 0.72954327 0.7297186  0.7299011
 0.7300887  0.73027956 0.7304725  0.73066705 0.7308622  0.7310583 ]


TIME OF ONE EPOCH: 51.098180532455444 seconds and 0.8516363422075908 minutes
Epoch 8
	TRAINING: 178.49708533287048 total train Value loss.

	TESTING: 3657.4111328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7764212  0.7310556  0.72325456 0.7154729  0.7112148  0.71044004
 0.7122636  0.7155625  0.7194433  0.72332543 0.7268683  0.7298901
 0.73231333 0.73412883 0.7353736  0.73611504 0.73643655 0.73642707
 0.7361733  0.7357531  0.73523355 0.73466843 0.73409927 0.73355657
 0.7330611  0.7326257  0.7322572  0.73195726 0.73172444 0.7315545
 0.7314419  0.7313799  0.73136204 0.73138094 0.73143065 0.73150516
 0.731599   0.7317078  0.731828   0.7319563  0.73209053 0.73222864
 0.73236954 0.7325123  0.7326564  0.7328014  0.73294765 0.7330949 ]


TIME OF ONE EPOCH: 51.04391312599182 seconds and 0.850731885433197 minutes
Epoch 9
	TRAINING: 148.71461653709412 total train Value loss.

	TESTING: 3643.376953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7766212  0.73603475 0.7284814  0.7212592  0.717351   0.71665996
 0.7183032  0.7212143  0.7245723  0.72786474 0.730809   0.7332676
 0.73519427 0.73659915 0.73752683 0.73804355 0.73822373 0.73814535
 0.73787975 0.7374913  0.7370331  0.73654747 0.73606616 0.735612
 0.73519987 0.7348391  0.734533   0.7342825  0.7340849  0.733937
 0.7338337  0.73376906 0.7337382  0.7337354  0.7337557  0.73379475
 0.7338487  0.7339141  0.7339886  0.7340695  0.73415583 0.73424625
 0.7343398  0.734436   0.7345348  0.7346362  0.7347396  0.734846  ]


TIME OF ONE EPOCH: 51.829962968826294 seconds and 0.8638327161471049 minutes
Epoch 10
	TRAINING: 129.4253972172737 total train Value loss.

	TESTING: 3628.222412109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.77620465 0.7395053  0.7323359  0.72570175 0.7221597  0.7215537
 0.72301733 0.7255575  0.72843534 0.7312074  0.73364246 0.7356393
 0.73717254 0.7382633  0.7389581  0.73931825 0.73941004 0.7392985
 0.73904425 0.73869866 0.7383042  0.737894   0.7374923  0.73711574
 0.7367753  0.73647714 0.7362229  0.73601276 0.73584396 0.73571336
 0.73561686 0.73555    0.7355085  0.7354883  0.7354856  0.7354973
 0.73552006 0.7355523  0.7355918  0.7356372  0.7356873  0.73574173
 0.73579997 0.7358613  0.73592645 0.73599505 0.73606735 0.7361434 ]


TIME OF ONE EPOCH: 51.85370588302612 seconds and 0.8642284313837687 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 697.3914654578691 and inf%

TIME ELAPSED: 507.49742007255554 seconds OR 8.458290334542593 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 192, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 16118 train samples and 81 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 48)
  (Dcell): LSTMCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 27752.843636989594 total train Value loss.

	TESTING: 3365.173828125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0522757  1.092195   1.072658   1.0527525  1.0379199  1.0274689
 1.0198458  1.0138085  1.0086659  1.0041164  1.0000362  0.9963632
 0.99305934 0.9901009  0.987474   0.98516715 0.9831662  0.9814515
 0.97999746 0.9787748  0.9777517  0.97689706 0.9761809  0.9755763
 0.97505945 0.97461015 0.9742121  0.9738516  0.97351825 0.9732035
 0.97290134 0.9726075  0.9723185  0.972033   0.97174966 0.97146827
 0.97118884 0.97091216 0.9706386  0.9703694  0.97010547 0.96984786
 0.9695976  0.9693555  0.96912247 0.9688991  0.9686861  0.96848404]


TIME OF ONE EPOCH: 70.76327276229858 seconds and 1.179387879371643 minutes
Epoch 2
	TRAINING: 690.9555289745331 total train Value loss.

	TESTING: 3073.07568359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0622785  1.0781286  1.0582244  1.0408959  1.0288608  1.0212147
 1.016279   1.0126767  1.0096014  1.0066726  1.0037435  1.0007795
 0.9978016  0.99485534 0.9919917  0.98925555 0.9866796  0.98428196
 0.9820698  0.98004043 0.978185   0.97649175 0.9749469  0.9735364
 0.97224706 0.971067   0.9699848  0.9689913  0.9680776  0.9672367
 0.96646196 0.96574783 0.96508944 0.9644824  0.9639233  0.9634086
 0.9629353  0.9625009  0.96210307 0.961739   0.96140724 0.96110576
 0.9608323  0.96058565 0.96036416 0.96016604 0.95998985 0.9598341 ]


TIME OF ONE EPOCH: 71.7919807434082 seconds and 1.1965330123901368 minutes
Epoch 3
	TRAINING: 371.17464113235474 total train Value loss.

	TESTING: 2942.658447265625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0732247  1.0753545  1.0581093  1.0444548  1.0356697  1.0307351
 1.0279794  1.0260748  1.0242739  1.0222621  1.019959   1.0173923
 1.014636   1.011778   1.0089018  1.0060773  1.003357   1.0007755
 0.9983529  0.9960979  0.9940109  0.9920871  0.99031854 0.98869526
 0.98720753 0.9858447  0.9845971  0.9834557  0.9824118  0.98145735
 0.98058546 0.9797897  0.9790636  0.9784018  0.9777998  0.9772527
 0.97675633 0.97630703 0.9759013  0.975536   0.9752078  0.97491425
 0.97465277 0.97442067 0.97421587 0.9740362  0.9738797  0.9737444 ]


TIME OF ONE EPOCH: 71.06068778038025 seconds and 1.1843447963396707 minutes
Epoch 4
	TRAINING: 224.88568234443665 total train Value loss.

	TESTING: 2830.638916015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0747459  1.0699238  1.055767   1.0452541  1.0389501  1.0358489
 1.0344137  1.03345    1.0323097  1.0307481  1.0287383  1.0263509
 1.0236926  1.0208757  1.0180013  1.0151519  1.0123897  1.0097563
 1.0072777  1.0049669  1.002827   1.0008559  0.9990472  0.99739236
 0.995881   0.9945031  0.9932483  0.9921072  0.9910701  0.9901288
 0.9892752  0.9885017  0.98780185 0.98716956 0.9865992  0.98608536
 0.9856234  0.98520964 0.9848397  0.9845097  0.9842169  0.9839581
 0.98373044 0.9835314  0.9833583  0.9832091  0.9830817  0.98297393]


TIME OF ONE EPOCH: 71.36517024040222 seconds and 1.1894195040067037 minutes
Epoch 5
	TRAINING: 163.829077064991 total train Value loss.

	TESTING: 2759.982421875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0695097  1.0609595  1.0495834  1.0415819  1.0371312  1.0352894
 1.0346797  1.0342574  1.033479   1.0321679  1.0303421  1.0281008
 1.0255681  1.0228655  1.0200988  1.0173538  1.014692   1.0121561
 1.0097724  1.0075539  1.0055043  1.0036211  1.0018985  1.0003273
 0.9988978  0.99759936 0.9964225  0.9953562  0.9943918  0.9935204
 0.99273384 0.9920244  0.9913856  0.9908112  0.99029577 0.9898337
 0.98942095 0.989053   0.988726   0.9884365  0.98818123 0.9879575
 0.98776203 0.98759305 0.9874475  0.987324   0.9872198  0.9871336 ]


TIME OF ONE EPOCH: 71.17297840118408 seconds and 1.1862163066864013 minutes
Epoch 6
	TRAINING: 134.61084818840027 total train Value loss.

	TESTING: 2708.252685546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0644559  1.0543599  1.0453205  1.039282   1.036207   1.0352312
 1.0351237  1.0349672  1.0343087  1.0330356  1.0312074  1.0289514
 1.0264059  1.0237002  1.0209427  1.0182176  1.0155858  1.0130887
 1.0107502  1.0085819  1.0065866  1.0047609  1.0030977  1.0015873
 1.0002193  0.99898285 0.9978667  0.9968608  0.9959555  0.9951412
 0.99441    0.99375373 0.99316615 0.9926403  0.99217075 0.9917523
 0.99138063 0.9910514  0.9907604  0.99050444 0.9902807  0.9900858
 0.98991734 0.98977286 0.9896504  0.9895475  0.9894625  0.9893938 ]


TIME OF ONE EPOCH: 71.75190877914429 seconds and 1.1958651463190715 minutes
Epoch 7
	TRAINING: 116.10103040933609 total train Value loss.

	TESTING: 2657.192626953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0593497  1.0486695  1.0414066  1.0368738  1.0348661  1.0345594
 1.034822   1.0348341  1.0342193  1.0329213  1.0310411  1.0287305
 1.0261433  1.023414   1.0206523  1.0179404  1.0153369  1.0128788
 1.0105883  1.0084742  1.0065377  1.004773   1.0031729  1.0017262
 1.0004214  0.99924713 0.998192   0.9972454  0.99639684 0.99563724
 0.99495834 0.99435204 0.9938112  0.9933296  0.99290186 0.99252266
 0.9921873  0.9918919  0.99163264 0.99140626 0.9912092  0.9910395
 0.99089414 0.9907707  0.99066764 0.9905825  0.9905138  0.9904595 ]


TIME OF ONE EPOCH: 71.42560696601868 seconds and 1.1904267827669779 minutes
Epoch 8
	TRAINING: 105.12402772903442 total train Value loss.

	TESTING: 2608.95849609375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.050135   1.0395565  1.0337087  1.0303276  1.0291129  1.0292947
 1.0298392  1.0300082  1.0294796  1.0282304  1.0263829  1.0241027
 1.0215505  1.0188644  1.0161542  1.0135003  1.0109599  1.0085682
 1.0063453  1.004299   1.0024291  1.0007299  0.99919266 0.99780625
 0.99655944 0.9954403  0.9944374  0.99354047 0.9927389  0.99202317
 0.99138564 0.99081814 0.99031377 0.98986614 0.98947006 0.9891204
 0.98881257 0.9885426  0.98830694 0.988102   0.98792547 0.98777395
 0.9876455  0.9875378  0.98744875 0.9873764  0.9873191  0.98727554]


TIME OF ONE EPOCH: 71.80131411552429 seconds and 1.1966885685920716 minutes
Epoch 9
	TRAINING: 112.75664010643959 total train Value loss.

	TESTING: 2600.30078125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0450802  1.0343636  1.0296054  1.02711    1.0264852  1.0270082
 1.0277268  1.0279654  1.0274414  1.0261601  1.0242656  1.0219393
 1.0193508  1.0166427  1.0139246  1.0112771  1.0087533  1.006387
 1.0041955  1.0021847  1.0003527  0.99869317 0.99719566 0.99584895
 0.99464124 0.9935604  0.9925942  0.9917323  0.9909645  0.99028146
 0.98967415 0.98913586 0.9886587  0.98823696 0.98786527 0.98753834
 0.98725176 0.9870017  0.9867845  0.98659694 0.9864361  0.98629946
 0.98618454 0.9860893  0.9860116  0.9859496  0.98590195 0.9858668 ]


TIME OF ONE EPOCH: 71.60155034065247 seconds and 1.1933591723442079 minutes
Epoch 10
	TRAINING: 101.07362508773804 total train Value loss.

	TESTING: 2596.9951171875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [1.0387901  1.0282062  1.0242742  1.0224515  1.0222797  1.023075
 1.0239456  1.0242602  1.0237626  1.0224787  1.0205683  1.0182247
 1.0156255  1.0129164  1.0102079  1.007579   1.0050817  1.0027469
 1.0005904  0.9986165  0.9968223  0.99519986 0.99373895 0.9924274
 0.9912531  0.99020344 0.9892674  0.9884332  0.98769134 0.98703235
 0.9864476  0.98592955 0.9854718  0.98506767 0.98471195 0.9843996
 0.98412657 0.9838889  0.9836827  0.9835053  0.9833538  0.98322546
 0.983118   0.98302925 0.98295766 0.982901   0.98285776 0.98282695]


TIME OF ONE EPOCH: 71.63570046424866 seconds and 1.193928341070811 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 714.0811628490809 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 714.9709103107452 seconds OR 11.91618183851242 minutes

End of run




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 336, 'hs': 12}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 15974 train samples and 78 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 12)
  (Dcell): LSTMCell(13, 12)
  (Wattn_energies): Linear(in_features=24, out_features=12, bias=True)
  (WValue): Linear(in_features=12, out_features=1, bias=True)
  (Wout): Linear(in_features=25, out_features=12, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 84499.70018005371 total train Value loss.

	TESTING: 11544.21875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.48177594 0.5852695  0.6052052  0.62059045 0.6342307  0.6440692
 0.64966077 0.65155417 0.6506162  0.64773744 0.64369696 0.6391027
 0.63438475 0.62982166 0.6255767  0.6217335  0.61832416 0.6153485
 0.61278796 0.61061364 0.608792   0.60728806 0.6060672  0.6050961
 0.60434455 0.60378367 0.6033878  0.6031337  0.60300004 0.6029684
 0.6030221  0.6031463  0.6033282  0.6035564  0.60382074 0.60411257
 0.60442454 0.60474986 0.60508305 0.6054195  0.6057553  0.6060869
 0.6064114  0.60672665 0.60703087 0.6073224  0.60760057 0.60786426]


TIME OF ONE EPOCH: 60.49868702888489 seconds and 1.0083114504814148 minutes
Epoch 2
	TRAINING: 5789.109712600708 total train Value loss.

	TESTING: 10499.5703125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.6144744  0.65394545 0.64116514 0.6365667  0.6351765  0.63322926
 0.6293798  0.6235183  0.6160917  0.6077559  0.59915495 0.5907943
 0.58300483 0.5759633  0.5697347  0.564313   0.55965155 0.55568403
 0.55233705 0.54953736 0.5472155  0.5453079  0.5437565  0.5425104
 0.54152447 0.5407586  0.5401786  0.5397539  0.5394587  0.53927004
 0.5391688  0.53913814 0.53916365 0.5392333  0.53933686 0.5394654
 0.53961176 0.5397696  0.53993386 0.5401005  0.5402659  0.5404277
 0.5405833  0.5407314  0.5408706  0.541      0.5411189  0.54122746]


TIME OF ONE EPOCH: 60.72207427024841 seconds and 1.012034571170807 minutes
Epoch 3
	TRAINING: 2559.2155265808105 total train Value loss.

	TESTING: 9654.48046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.6974877  0.6799179  0.656504   0.6465112  0.64067954 0.63507813
 0.62822235 0.61989814 0.6104961  0.6006243  0.5908637  0.5816409
 0.5732066  0.5656672  0.55903226 0.5532562  0.5482665  0.5439808
 0.5403175  0.5371988  0.5345548  0.53232205 0.5304453  0.52887523
 0.52756894 0.52648884 0.52560204 0.5248797  0.52429724 0.52383286
 0.5234677  0.5231857  0.5229724  0.5228159  0.52270573 0.52263296
 0.5225898  0.5225697  0.5225675  0.5225783  0.52259827 0.5226241
 0.52265316 0.5226835  0.5227133  0.5227412  0.52276593 0.5227871 ]


TIME OF ONE EPOCH: 60.03683161735535 seconds and 1.0006138602892558 minutes
Epoch 4
	TRAINING: 1543.4681091308594 total train Value loss.

	TESTING: 9435.51953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7409008  0.6894523  0.66768754 0.6588911  0.65357465 0.64830786
 0.6417705  0.6337955  0.62478423 0.6153378  0.6060138  0.5972113
 0.58915526 0.5819339  0.5755465  0.56994444 0.56505686 0.56080663
 0.55711854 0.55392325 0.5511579  0.5487673  0.54670274 0.54492134
 0.54338616 0.5420642  0.5409271  0.5399498  0.53911066 0.53839046
 0.53777266 0.5372425  0.5367875  0.5363965  0.53606004 0.5357695
 0.53551793 0.53529876 0.535107   0.53493774 0.53478724 0.53465205
 0.5345292  0.5344164  0.53431183 0.5342135  0.5341204  0.534031  ]


TIME OF ONE EPOCH: 58.6849582195282 seconds and 0.9780826369921366 minutes
Epoch 5
	TRAINING: 1057.8896431922913 total train Value loss.

	TESTING: 9080.4765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7586907  0.69202536 0.6743177  0.66788256 0.6641643  0.6600822
 0.65449154 0.6473195  0.63901484 0.630199   0.6214348  0.6131204
 0.6054792  0.5985998  0.592484   0.58708745 0.58234453 0.5781845
 0.5745384  0.5713431  0.5685422  0.5660858  0.56393033 0.56203777
 0.560375   0.55891305 0.5576264  0.55649304 0.5554934  0.55461067
 0.5538296  0.55313724 0.55252194 0.5519739  0.5514838  0.5510444
 0.5506487  0.5502909  0.5499657  0.54966897 0.5493964  0.54914504
 0.548912   0.5486947  0.5484909  0.54829913 0.54811764 0.54794526]


TIME OF ONE EPOCH: 58.03874230384827 seconds and 0.9673123717308044 minutes
Epoch 6
	TRAINING: 807.5132765769958 total train Value loss.

	TESTING: 8760.904296875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7653109  0.69623137 0.68245935 0.6784638  0.6765243  0.67383564
 0.66943526 0.66334844 0.65606356 0.6482049  0.64032483 0.63280916
 0.6258744  0.6196073  0.61401355 0.6090541  0.60467136 0.6008024
 0.59738636 0.5943674  0.59169614 0.58932924 0.5872288  0.5853617
 0.58370006 0.58221817 0.5808946  0.57971025 0.5786483  0.5776942
 0.5768349  0.57605934 0.57535696 0.5747194  0.5741389  0.5736085
 0.5731225  0.5726752  0.5722625  0.57188    0.5715246  0.57119286
 0.5708821  0.57059026 0.57031536 0.57005537 0.5698091  0.5695751 ]


TIME OF ONE EPOCH: 59.1609992980957 seconds and 0.9860166549682617 minutes
Epoch 7
	TRAINING: 646.7007529735565 total train Value loss.

	TESTING: 8435.3359375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7686756  0.7029694  0.69218695 0.69014704 0.6896719  0.6881751
 0.6848487  0.6797976  0.6735306  0.66665924 0.65971166 0.65305305
 0.6468874  0.6412981  0.63629276 0.63183856 0.6278852  0.6243775
 0.62126225 0.6184913  0.61602175 0.6138161  0.61184204 0.61007154
 0.60848    0.60704654 0.6057522  0.6045815  0.6035196  0.6025542
 0.60167444 0.6008708  0.6001343  0.59945786 0.59883463 0.5982588
 0.59772515 0.5972294  0.59676725 0.5963354  0.59593046 0.59555006
 0.5951917  0.59485346 0.59453326 0.5942296  0.59394103 0.59366655]


TIME OF ONE EPOCH: 58.69675278663635 seconds and 0.9782792131106058 minutes
Epoch 8
	TRAINING: 531.7809824943542 total train Value loss.

	TESTING: 7937.0546875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.77208567 0.7119833  0.70336044 0.70276916 0.7034048  0.70285344
 0.700428   0.6962906  0.69095576 0.68501055 0.6789516  0.6731185
 0.6677004  0.6627759  0.65835404 0.6544069  0.6508914  0.6477593
 0.6449652  0.6424668  0.64022756 0.6382154  0.63640285 0.634766
 0.63328373 0.6319386  0.6307148  0.6295986  0.62857807 0.62764263
 0.62678325 0.62599134 0.6252599  0.62458265 0.6239538  0.6233684
 0.62282205 0.62231064 0.6218312  0.6213803  0.6209557  0.6205547
 0.62017536 0.6198157  0.6194744  0.6191499  0.61884105 0.6185466 ]


TIME OF ONE EPOCH: 59.81527662277222 seconds and 0.9969212770462036 minutes
Epoch 9
	TRAINING: 444.903272151947 total train Value loss.

	TESTING: 7663.7509765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7774301  0.72319585 0.7163101  0.71695125 0.71860397 0.7189611
 0.7174173  0.71417516 0.70974815 0.70469904 0.69949466 0.69445246
 0.68975055 0.68546385 0.68160444 0.6781506  0.6750655  0.67230844
 0.66984004 0.66762424 0.66563    0.6638297  0.6621999  0.66072035
 0.65937334 0.65814364 0.6570184  0.65598583 0.6550359  0.6541597
 0.6533497  0.6525986  0.6519006  0.6512503  0.65064275 0.65007406
 0.64954025 0.6490383  0.64856505 0.64811814 0.6476954  0.64729464
 0.64691436 0.64655274 0.6462085  0.6458805  0.6455678  0.64526916]


TIME OF ONE EPOCH: 59.316927433013916 seconds and 0.9886154572168986 minutes
Epoch 10
	TRAINING: 377.68620800971985 total train Value loss.

	TESTING: 7391.263671875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7842187  0.735313   0.72968996 0.73119473 0.73358756 0.7346376
 0.7337925  0.7312793  0.72760415 0.72330403 0.71881866 0.7144453
 0.71035165 0.7066101  0.7032351  0.7002094  0.69750214 0.69507825
 0.69290364 0.6909474  0.6891818  0.6875838  0.6861323  0.68481046
 0.68360263 0.682496   0.6814793  0.6805426  0.67967737 0.6788759
 0.6781316  0.67743874 0.67679197 0.6761868  0.67561936 0.67508596
 0.6745833  0.6741089  0.6736603  0.6732351  0.67283183 0.67244834
 0.67208344 0.67173594 0.6714044  0.6710879  0.67078567 0.6704967 ]


TIME OF ONE EPOCH: 58.8443922996521 seconds and 0.9807398716608683 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 599.5864134405414 and inf%
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
TIME ELAPSED: 595.7772643566132 seconds OR 9.92962107261022 minutes

End of run




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 336, 'hs': 24}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 15974 train samples and 78 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 24)
  (Dcell): LSTMCell(25, 24)
  (Wattn_energies): Linear(in_features=48, out_features=24, bias=True)
  (WValue): Linear(in_features=24, out_features=1, bias=True)
  (Wout): Linear(in_features=49, out_features=24, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 53432.30604553223 total train Value loss.

	TESTING: 3944.38623046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8328367  0.6553436  0.6704576  0.6617725  0.6590709  0.6578298
 0.65768147 0.6577397  0.65766484 0.65754664 0.65773106 0.6586483
 0.660696   0.66414875 0.66907907 0.675297   0.68233746 0.6895168
 0.69606304 0.70128363 0.7047084  0.7061601  0.70573395 0.70372164
 0.700519   0.69654685 0.6921967  0.6878003  0.6836184  0.679839
 0.676586   0.6739274  0.67188746 0.67045605 0.6695988  0.66926277
 0.66938555 0.66989785 0.67072964 0.6718129  0.67308354 0.67448527
 0.67596865 0.6774921  0.6790231  0.6805354  0.682011   0.683437  ]


TIME OF ONE EPOCH: 83.07835149765015 seconds and 1.3846391916275025 minutes
Epoch 2
	TRAINING: 1190.942349433899 total train Value loss.

	TESTING: 3716.41748046875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7939032  0.6537441  0.66220605 0.6564547  0.6553478  0.65580493
 0.6569443  0.65791726 0.6584597  0.65872216 0.65905046 0.6598245
 0.66136354 0.66386974 0.66738886 0.67179036 0.6767753  0.68192035
 0.68675584 0.69085556 0.6939131  0.6957824  0.6964766  0.69613403
 0.6949698  0.69322973 0.69115394 0.6889534  0.6867992  0.68481815
 0.6830951  0.681679   0.6805885  0.6798191  0.6793504  0.6791497
 0.6791788  0.6793964  0.6797623  0.68023795 0.68079007 0.6813892
 0.6820122  0.6826403  0.68326014 0.6838625  0.6844414  0.6849941 ]


TIME OF ONE EPOCH: 83.8367350101471 seconds and 1.3972789168357849 minutes
Epoch 3
	TRAINING: 629.0720000267029 total train Value loss.

	TESTING: 3695.3037109375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7701677  0.66394633 0.66844827 0.6652024  0.66510063 0.66607
 0.6671484  0.66771096 0.66769713 0.6673879  0.66717005 0.6673918
 0.6682965  0.66999894 0.67248005 0.6755952  0.6791013  0.682698
 0.686082   0.68899596 0.6912635  0.69280565 0.69363475 0.6938332
 0.69352716 0.69286126 0.6919779  0.6910037  0.69004166 0.689169
 0.688438   0.6878781  0.68749976 0.68730015 0.6872643  0.6873717
 0.6875972  0.68791443 0.6882987  0.68872577 0.6891756  0.68963134
 0.6900796  0.6905106  0.690918   0.6912979  0.6916494  0.6919721 ]


TIME OF ONE EPOCH: 84.1391212940216 seconds and 1.4023186882336935 minutes
Epoch 4
	TRAINING: 409.29815101623535 total train Value loss.

	TESTING: 3647.495361328125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.75602955 0.67616093 0.6786182  0.67688113 0.6771317  0.67788416
 0.6783156  0.6780522  0.6772198  0.67619264 0.67536765 0.67504674
 0.6754022  0.6764785  0.6782083  0.6804384  0.6829602  0.6855467
 0.6879867  0.690113   0.6918193  0.6930627  0.6938566  0.69425595
 0.6943415  0.6942031  0.693929   0.6935966  0.69326925 0.69299346
 0.6928006  0.69270694 0.6927178  0.692829   0.69302976 0.6933056
 0.69363916 0.69401336 0.6944114  0.69481844 0.6952218  0.69561136
 0.69597936 0.69632083 0.69663304 0.69691485 0.6971671  0.69739115]


TIME OF ONE EPOCH: 83.97112798690796 seconds and 1.3995187997817993 minutes
Epoch 5
	TRAINING: 293.8941652774811 total train Value loss.

	TESTING: 3610.5849609375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.74666923 0.6852128  0.68657494 0.68546695 0.6855666  0.68574965
 0.68538105 0.68428665 0.68271226 0.68107134 0.6797416  0.67897415
 0.6788809  0.67945623 0.68060464 0.6821737  0.68398315 0.6858539
 0.6876308  0.68919826 0.69048667 0.6914711  0.69216394 0.69260377
 0.6928449  0.6929462  0.69296503 0.6929518  0.6929457  0.6929763
 0.6930623  0.6932127  0.6934288  0.6937063  0.6940366  0.69440806
 0.6948085  0.6952254  0.6956469  0.69606274 0.6964641  0.6968446
 0.6971991  0.6975249  0.69782054 0.6980859  0.6983226  0.69853234]


TIME OF ONE EPOCH: 83.90728688240051 seconds and 1.398454781373342 minutes
Epoch 6
	TRAINING: 224.264275431633 total train Value loss.

	TESTING: 3581.4521484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7413493  0.69263506 0.6934355  0.6925745  0.69239396 0.692021
 0.69098914 0.6892605  0.6871468  0.6850678  0.683372   0.6822668
 0.6818213  0.6819968  0.6826853  0.6837398  0.68500316 0.6863299
 0.6876011  0.6887323  0.6896761  0.6904168  0.69096595 0.6913521
 0.6916132  0.6917901  0.6919222  0.6920423  0.6921768  0.69234407
 0.6925552  0.6928146  0.69312125 0.6934709  0.69385564 0.6942662
 0.694693   0.6951262  0.6955568  0.6959771  0.6963805  0.6967624
 0.697119   0.69744843 0.69775015 0.69802386 0.698271   0.69849324]


TIME OF ONE EPOCH: 84.4625358581543 seconds and 1.4077089309692383 minutes
Epoch 7
	TRAINING: 183.30646163225174 total train Value loss.

	TESTING: 3562.99365234375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.73886657 0.69912195 0.6996136  0.69880724 0.69831294 0.6974546
 0.695904   0.6937129  0.69122165 0.68883735 0.6868778  0.6855152
 0.6847896  0.6846443  0.6849664  0.68561816 0.68646085 0.6873731
 0.68826014 0.68905693 0.6897295  0.69026744 0.69068074 0.69099075
 0.69122535 0.69141424 0.6915838  0.6917574  0.69195175 0.69217896
 0.6924447  0.6927509  0.6930949  0.6934717  0.69387484 0.69429606
 0.69472724 0.6951607  0.69558895 0.69600594 0.6964067  0.6967874
 0.6971452  0.69747853 0.6977869  0.6980704  0.69833016 0.69856733]


TIME OF ONE EPOCH: 83.57757139205933 seconds and 1.3929595232009888 minutes
Epoch 8
	TRAINING: 150.96423602104187 total train Value loss.

	TESTING: 3549.371337890625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.7383248  0.7053279  0.70566094 0.70487547 0.70413786 0.7029244
 0.7010128  0.69851434 0.69577795 0.6931922  0.69104797 0.68949276
 0.68854827 0.68814987 0.68818533 0.68852687 0.6890512  0.6896538
 0.6902559  0.69080603 0.69127697 0.6916616  0.6919672  0.6922103
 0.692412   0.6925929  0.6927725  0.69296646 0.69318604 0.6934382
 0.69372594 0.6940489  0.69440377 0.69478554 0.6951882  0.6956044
 0.69602704 0.69645035 0.6968675  0.69727415 0.69766563 0.69803923
 0.69839245 0.69872403 0.6990337  0.6993215  0.69958836 0.6998353 ]


TIME OF ONE EPOCH: 83.73117661476135 seconds and 1.3955196102460226 minutes
Epoch 9
	TRAINING: 128.0335955619812 total train Value loss.

	TESTING: 3530.197509765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.73814666 0.71007454 0.71026456 0.7094374  0.70848435 0.70699614
 0.70482486 0.70211494 0.69921064 0.6964794  0.6941883  0.6924675
 0.6913295  0.69070804 0.6904963  0.69057614 0.69083804 0.69119024
 0.69156563 0.6919207  0.6922328  0.6924955  0.6927142  0.69290066
 0.6930701  0.69323766 0.693417   0.6936184  0.6938493  0.6941133
 0.69441146 0.6947417  0.6951005  0.6954827  0.6958825  0.6962937
 0.69671017 0.6971262  0.69753677 0.69793755 0.69832486 0.6986963
 0.69905007 0.6993847  0.6997001  0.69999605 0.70027363 0.70053303]


TIME OF ONE EPOCH: 83.55716323852539 seconds and 1.3926193873087565 minutes
Epoch 10
	TRAINING: 107.15811210870743 total train Value loss.

	TESTING: 3511.2021484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.73889667 0.7146928  0.7147891  0.71394694 0.7128617  0.71120846
 0.7088931  0.7060795  0.70310086 0.7003019  0.6979291  0.69609934
 0.69482046 0.6940281  0.6936228  0.6934969  0.6935517  0.69370675
 0.69390327 0.6941038  0.69428825 0.69445086 0.69459426 0.6947276
 0.6948613  0.6950065  0.6951724  0.69536644 0.6955922  0.6958517
 0.6961443  0.6964669  0.6968161  0.69718635 0.69757235 0.69796854
 0.69836944 0.6987701  0.6991655  0.6995526  0.69992787 0.7002895
 0.7006355  0.70096487 0.70127726 0.70157284 0.70185155 0.70211476]


TIME OF ONE EPOCH: 83.38318967819214 seconds and 1.389719827969869 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 675.0743995079628 and inf%

TIME ELAPSED: 838.5816962718964 seconds OR 13.976361604531606 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)




{'cell_type': 'lstm', 'attention_model': ['BA'], 'window_source_size': 336, 'hs': 48}
Transforming data to 0 mean and unit var
Generating training and test data...
Created 15974 train samples and 78 test samples
MODEL ARCHITECTURE IS: 
S2S_BA_Model(
  (Ecell): LSTMCell(44, 48)
  (Dcell): LSTMCell(49, 48)
  (Wattn_energies): Linear(in_features=96, out_features=48, bias=True)
  (WValue): Linear(in_features=48, out_features=1, bias=True)
  (Wout): Linear(in_features=97, out_features=48, bias=True)
)

Model parameters are on cuda: True

Starting training...
Epoch 1
	TRAINING: 27956.172542095184 total train Value loss.

	TESTING: 4062.77001953125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.77188027 0.8180163  0.8124745  0.81079626 0.8151213  0.8230726
 0.83144087 0.8375383  0.83995116 0.8385264  0.8339266  0.82714057
 0.81914055 0.8107123  0.8024098  0.79457915 0.7874056  0.7809623
 0.7752503  0.7702282  0.7658319  0.76198906 0.75862616 0.7556742
 0.7530716  0.7507639  0.74870443 0.7468545  0.7451822  0.7436606
 0.74226886 0.7409892  0.73980826 0.7387148  0.7377     0.7367567
 0.73587924 0.7350631  0.73430413 0.7335991  0.73294514 0.7323398
 0.7317807  0.7312649  0.730791   0.7303564  0.7299593  0.72959733]


TIME OF ONE EPOCH: 132.32346296310425 seconds and 2.205391049385071 minutes
Epoch 2
	TRAINING: 665.714898109436 total train Value loss.

	TESTING: 3938.17333984375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8058463  0.8300454  0.8249137  0.825301   0.8303318  0.83766955
 0.84462404 0.8490659  0.8500049  0.8475245  0.84235126 0.8354185
 0.827586   0.81951886 0.8116707  0.8043165  0.7975964  0.7915587
 0.7861918  0.7814508  0.7772742  0.77359426 0.77034503 0.7674661
 0.7649039  0.7626124  0.7605529  0.75869304 0.75700617 0.7554706
 0.7540683  0.7527846  0.7516077  0.75052726 0.7495351  0.74862427
 0.7477885  0.74702233 0.74632186 0.745682   0.745099   0.7445696
 0.7440904  0.74365795 0.7432689  0.7429206  0.7426103  0.74233466]


TIME OF ONE EPOCH: 132.17162823677063 seconds and 2.2028604706128436 minutes
Epoch 3
	TRAINING: 347.51750671863556 total train Value loss.

	TESTING: 3716.92041015625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.82191783 0.8339666  0.8303695  0.83209544 0.8371772  0.84343684
 0.84861785 0.8511152  0.85034996 0.8466138  0.84066826 0.83338094
 0.8255094  0.81762034 0.81008697 0.8031243  0.79683006 0.79122275
 0.7862719  0.78192025 0.7780993  0.7747382  0.7717717  0.7691408
 0.7667955  0.7646938  0.76280034 0.761087   0.75953025 0.7581117
 0.75681573 0.75562954 0.75454354 0.7535486  0.75263757 0.7518041
 0.7510427  0.75034845 0.7497169  0.7491439  0.7486259  0.74815893
 0.74774003 0.74736553 0.74703234 0.7467375  0.7464782  0.74625176]


TIME OF ONE EPOCH: 131.9457712173462 seconds and 2.19909618695577 minutes
Epoch 4
	TRAINING: 221.09814584255219 total train Value loss.

	TESTING: 3542.66357421875 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8375527  0.8432341  0.840769   0.8429813  0.8475926  0.8525787
 0.85601246 0.8566935  0.85435563 0.8494412  0.8427265  0.83502287
 0.8270082  0.8191722  0.81182617 0.80513597 0.79916394 0.79390204
 0.7893009  0.7852899  0.7817921  0.77873224 0.7760423  0.77366316
 0.77154547 0.7696485  0.7679393  0.7663916  0.76498413 0.76370007
 0.7625261  0.76145065 0.7604653  0.75956243 0.75873584 0.7579798
 0.7572896  0.75666136 0.7560903  0.7555736  0.75510746 0.75468856
 0.75431377 0.7539804  0.75368506 0.7534251  0.753198   0.75300103]


TIME OF ONE EPOCH: 131.89618182182312 seconds and 2.198269697030385 minutes
Epoch 5
	TRAINING: 172.66093850135803 total train Value loss.

	TESTING: 3444.43017578125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8475638  0.8495465  0.84767026 0.84988487 0.8538543  0.8576716
 0.8596591  0.858918   0.8554038  0.8496498  0.84242684 0.8344912
 0.82645416 0.8187448  0.8116258  0.80522645 0.7995811  0.79466176
 0.7904044  0.78672826 0.78354967 0.78078926 0.77837723 0.7762536
 0.7743692  0.7726845  0.77116776 0.7697942  0.76854414 0.76740247
 0.76635695 0.7653984  0.76451886 0.76371205 0.7629726  0.76229584
 0.76167834 0.7611158  0.7606052  0.7601439  0.7597283  0.7593554
 0.759023   0.7587284  0.7584687  0.75824124 0.758044   0.75787425]


TIME OF ONE EPOCH: 132.61168932914734 seconds and 2.2101948221524554 minutes
Epoch 6
	TRAINING: 141.92867159843445 total train Value loss.

	TESTING: 3377.0283203125 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.85644376 0.8563505  0.8546798  0.8566516  0.859956   0.8627859
 0.86366194 0.8619085  0.8576249  0.85138863 0.8439446  0.83599377
 0.8280892  0.82061076 0.8137828  0.8077078  0.8024008  0.79782015
 0.7938935  0.7905337  0.78765327 0.7851711  0.7830158  0.781128
 0.77945876 0.7779691  0.7766289  0.77541476 0.77430785 0.77329504
 0.7723651  0.77151006 0.77072316 0.76999915 0.76933414 0.76872414
 0.76816595 0.76765704 0.7671943  0.7667755  0.7663981  0.7660597
 0.765758   0.7654908  0.7652553  0.76504993 0.76487184 0.7647197 ]


TIME OF ONE EPOCH: 132.60699558258057 seconds and 2.2101165930430096 minutes
Epoch 7
	TRAINING: 116.61022537946701 total train Value loss.

	TESTING: 3305.273681640625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8621029  0.86058027 0.8588358  0.86039346 0.862989   0.86491823
 0.86486894 0.8623242  0.8574694  0.85089284 0.8433054  0.8353597
 0.82756215 0.8202559  0.8136391  0.80779505 0.80272585 0.7983823
 0.7946853  0.79154533 0.7888724  0.78658396 0.7846085  0.78288597
 0.78136814 0.7800165  0.77880186 0.7777013  0.7766974  0.77577746
 0.7749315  0.7741522  0.773434   0.7727721  0.77216315 0.7716041
 0.77109224 0.7706254  0.77020097 0.76981723 0.7694717  0.76916254
 0.7688876  0.76864487 0.768432   0.768247   0.7680878  0.7679528 ]


TIME OF ONE EPOCH: 131.01470232009888 seconds and 2.183578372001648 minutes
Epoch 8
	TRAINING: 104.06018468737602 total train Value loss.

	TESTING: 3249.66259765625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.8659934  0.86374617 0.86201036 0.86330664 0.8654146  0.86671543
 0.8660344  0.8629776  0.8577896  0.8510597  0.84346664 0.8356201
 0.82798845 0.8208848  0.8144855  0.8088604  0.80400413 0.79986227
 0.7963546  0.79339033 0.79087985 0.7887411  0.7869031  0.7853068
 0.7839047  0.7826589  0.78154045 0.7805278  0.7796039  0.7787569
 0.7779775  0.77725905 0.77659595 0.7759847  0.77542204 0.7749054
 0.7744324  0.7740011  0.7736096  0.77325577 0.7729381  0.7726545
 0.77240276 0.7721816  0.77198845 0.77182186 0.7716794  0.77155966]


TIME OF ONE EPOCH: 131.10437059402466 seconds and 2.1850728432337445 minutes
Epoch 9
	TRAINING: 91.22350081801414 total train Value loss.

	TESTING: 3206.36181640625 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.867858   0.8649974  0.8631597  0.8641275  0.86574143 0.86647487
 0.86527354 0.86183596 0.8564418  0.84966785 0.84215695 0.8344785
 0.82706445 0.8201999  0.81404287 0.80865127 0.8040132  0.80007213
 0.7967474  0.79394877 0.7915887  0.7895866  0.7878728  0.7863896
 0.78509027 0.7839386  0.78290606 0.78197205 0.7811201  0.78033876
 0.7796193  0.7789555  0.7783429  0.77777743 0.77725667 0.7767783
 0.77634007 0.7759407  0.7755781  0.77525085 0.7749569  0.77469516
 0.7744634  0.7742598  0.7740829  0.7739307  0.7738014  0.7736933 ]


TIME OF ONE EPOCH: 131.75793647766113 seconds and 2.195965607961019 minutes
Epoch 10
	TRAINING: 68.49725943803787 total train Value loss.

	TESTING: 3179.771484375 total test Value loss
	TESTING:

	Sample of prediction:
		 TARGET: [1.7223109 1.7224796 1.7226483 1.722817  1.7229855 1.7231542 1.723329
 1.7234975 1.7236662 1.7238349 1.7240036 1.7241722 1.7243408 1.7245095
 1.7246782 1.7248528 1.7250215 1.7251902 1.7253588 1.7255274 1.7256961
 1.7258648 1.7260394 1.7262081 1.7263768 1.7265455 1.7267141 1.7268827
 1.7270514 1.72722   1.7273887 1.7275634 1.7277321 1.7279007 1.7280694
 1.728238  1.7284067 1.7285753 1.72875   1.7289187 1.7290874 1.729256
 1.7294246 1.7295933 1.729762  1.7299306 1.7300993 1.730274 ]
		   PRED: [0.87132066 0.8686504  0.8668318  0.86763376 0.86895823 0.86935484
 0.8678596  0.86422956 0.8587604  0.8520132  0.8446033  0.8370714
 0.82982635 0.82313573 0.8171464  0.81191057 0.807413   0.8035973
 0.80038357 0.7976833  0.79541034 0.7934856  0.79184103 0.7904197
 0.78917617 0.7880749  0.78708774 0.7861944  0.7853792  0.7846312
 0.783942   0.7833056  0.7827176  0.7821746  0.7816743  0.7812146
 0.7807936  0.7804095  0.7800612  0.7797469  0.7794647  0.77921355
 0.7789912  0.7787965  0.7786275  0.77848244 0.77835935 0.7782567 ]


TIME OF ONE EPOCH: 131.93505239486694 seconds and 2.198917539914449 minutes

	ACTUAL ACC. RESULTS: MAE, MAPE: 657.3734934554141 and inf%

TIME ELAPSED: 1320.9016666412354 seconds OR 22.01502777735392 minutes

End of run
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:809: RuntimeWarning: divide by zero encountered in divide
  mape3 = (sum(abs((Value_actual - preds_unnorm)/Value_actual))) / \
/home/philip/src/ds5220-team-2/s2s-attention-energy-forecasting/all_S2S_models.py:813: RuntimeWarning: divide by zero encountered in divide
  mape_s = (abs((Value_actual - preds_unnorm)/Value_actual))
/home/philip/mambaforge/envs/ds5220/lib/python3.10/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)



